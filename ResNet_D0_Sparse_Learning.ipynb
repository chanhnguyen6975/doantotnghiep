{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyN63+HA/wUxK5RhcU1ZQPov"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfiGmXG8-aGB","executionInfo":{"status":"ok","timestamp":1670144365268,"user_tz":-420,"elapsed":17546,"user":{"displayName":"Chánh Nguyễn Trung","userId":"17789627222872787657"}},"outputId":"6ab758bb-537a-40d3-d4ef-edc9b956f76c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!python '/content/drive/MyDrive/Projects/sparse_learning-d0-resnet50/mnist_cifar/main.py' --data cifar --model wrn-28-2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-_1OPy3-kl1","executionInfo":{"status":"ok","timestamp":1670049801422,"user_tz":-420,"elapsed":3258468,"user":{"displayName":"Chánh Nguyễn Trung","userId":"17789627222872787657"}},"outputId":"d8953903-8e0c-4863-a087-8555e24c1b16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","[25,    24] loss: 2.1080286502838135, time: 13.222491264343262\n","[25,    25] loss: 1.4216251373291016, time: 13.771894454956055\n","[25,    26] loss: 1.8922878503799438, time: 14.315819025039673\n","[25,    27] loss: 1.963416576385498, time: 14.908314228057861\n","[25,    28] loss: 1.8783552646636963, time: 15.498753547668457\n","[25,    29] loss: 2.109666585922241, time: 16.11371111869812\n","[25,    30] loss: 1.5538209676742554, time: 16.67638874053955\n","[25,    31] loss: 2.2299106121063232, time: 17.250526189804077\n","[25,    32] loss: 2.1978421211242676, time: 17.812047004699707\n","[25,    33] loss: 1.776639699935913, time: 18.361668348312378\n","[25,    34] loss: 2.038649320602417, time: 18.89602017402649\n","[25,    35] loss: 1.6187013387680054, time: 19.428104162216187\n","[25,    36] loss: 1.999939203262329, time: 19.973527431488037\n","[25,    37] loss: 1.6866412162780762, time: 20.515758991241455\n","[25,    38] loss: 1.6517645120620728, time: 21.080209493637085\n","[25,    39] loss: 2.136375904083252, time: 21.637632369995117\n","[25,    40] loss: 2.1602883338928223, time: 22.218549013137817\n","[25,    41] loss: 1.653782844543457, time: 22.730789184570312\n","[25,    42] loss: 1.8477445840835571, time: 23.273638248443604\n","[25,    43] loss: 1.7204344272613525, time: 23.85217571258545\n","[25,    44] loss: 1.6539530754089355, time: 24.415790796279907\n","[25,    45] loss: 2.213829755783081, time: 24.97713303565979\n","[25,    46] loss: 2.601598024368286, time: 25.528175115585327\n","[25,    47] loss: 2.1349620819091797, time: 26.08896040916443\n","[25,    48] loss: 2.2142374515533447, time: 26.64657735824585\n","[25,    49] loss: 2.074599504470825, time: 27.196576356887817\n","[25,    50] loss: 2.0348005294799805, time: 27.364198207855225\n","\n","Evaluation: Average loss: 2.8023, Accuracy: 280/947 (29.567%)\n","\n","************************************************************\n","Total removed parameters: 1433960.0\n","Take 40.63145421310914 % of active parameters\n","Total redistribution parameters: 2091349.0\n","Take: 145.84430528048202 % of removed parameters\n","Pruning rate: 0.4275089283436705\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 33.22 seconds.\n","\n","Total nonzero parameters:  2805068\n","Take 11.890923913836003 %\n","------------------------------------------------------------\n","[26,     1] loss: 2.219503879547119, time: 0.5645818710327148\n","[26,     2] loss: 2.0509397983551025, time: 1.1212432384490967\n","[26,     3] loss: 1.9346102476119995, time: 1.6631250381469727\n","[26,     4] loss: 1.7942578792572021, time: 2.236339807510376\n","[26,     5] loss: 2.094588279724121, time: 2.8040521144866943\n","[26,     6] loss: 1.4537758827209473, time: 3.3565192222595215\n","[26,     7] loss: 2.1355221271514893, time: 3.8956921100616455\n","[26,     8] loss: 2.168424367904663, time: 4.4458794593811035\n","[26,     9] loss: 1.8920987844467163, time: 5.017257452011108\n","[26,    10] loss: 1.7216891050338745, time: 5.573728799819946\n","[26,    11] loss: 2.0122268199920654, time: 6.159265995025635\n","[26,    12] loss: 1.815409779548645, time: 6.709578990936279\n","[26,    13] loss: 2.0581328868865967, time: 7.262636661529541\n","[26,    14] loss: 1.7199338674545288, time: 7.819323301315308\n","[26,    15] loss: 1.9609233140945435, time: 8.38826060295105\n","[26,    16] loss: 1.9796556234359741, time: 8.957674741744995\n","[26,    17] loss: 1.9200613498687744, time: 9.513588666915894\n","[26,    18] loss: 2.2502284049987793, time: 10.06905198097229\n","[26,    19] loss: 1.9706027507781982, time: 10.624316215515137\n","[26,    20] loss: 1.7116502523422241, time: 11.183547973632812\n","[26,    21] loss: 1.7961361408233643, time: 11.728583812713623\n","[26,    22] loss: 2.1168482303619385, time: 12.2799391746521\n","[26,    23] loss: 2.009124755859375, time: 12.819474458694458\n","[26,    24] loss: 1.9889323711395264, time: 13.35449504852295\n","[26,    25] loss: 2.202709197998047, time: 13.903324365615845\n","[26,    26] loss: 1.8080772161483765, time: 14.441272735595703\n","[26,    27] loss: 2.001727342605591, time: 15.006804704666138\n","[26,    28] loss: 1.319756269454956, time: 15.57483696937561\n","[26,    29] loss: 1.9689972400665283, time: 16.137319564819336\n","[26,    30] loss: 1.8597588539123535, time: 16.694891691207886\n","[26,    31] loss: 1.7980760335922241, time: 17.239789724349976\n","[26,    32] loss: 1.7842577695846558, time: 17.789594173431396\n","[26,    33] loss: 2.157613754272461, time: 18.340373277664185\n","[26,    34] loss: 1.9622024297714233, time: 18.901671648025513\n","[26,    35] loss: 1.846970558166504, time: 19.429940462112427\n","[26,    36] loss: 1.9179807901382446, time: 19.99687933921814\n","[26,    37] loss: 1.8510735034942627, time: 20.554996252059937\n","[26,    38] loss: 1.640984296798706, time: 21.112813711166382\n","[26,    39] loss: 2.047830581665039, time: 21.652149200439453\n","[26,    40] loss: 2.015347719192505, time: 22.228482484817505\n","[26,    41] loss: 1.9020228385925293, time: 22.77964472770691\n","[26,    42] loss: 1.6865097284317017, time: 23.33976674079895\n","[26,    43] loss: 1.8569626808166504, time: 23.909884452819824\n","[26,    44] loss: 1.831054925918579, time: 24.449477910995483\n","[26,    45] loss: 1.759543776512146, time: 24.979551315307617\n","[26,    46] loss: 1.9396072626113892, time: 25.531728744506836\n","[26,    47] loss: 2.091571569442749, time: 26.076253414154053\n","[26,    48] loss: 1.8193458318710327, time: 26.62358045578003\n","[26,    49] loss: 2.131859540939331, time: 27.16786241531372\n","[26,    50] loss: 1.978008508682251, time: 27.34409213066101\n","\n","Evaluation: Average loss: 1.5233, Accuracy: 515/947 (54.382%)\n","\n","************************************************************\n","Total removed parameters: 1420021.0\n","Take 40.28075269430283 % of active parameters\n","Total redistribution parameters: 2104049.0\n","Take: 148.17027353820825 % of removed parameters\n","Pruning rate: 0.4219254087173506\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.81 seconds.\n","\n","Total nonzero parameters:  2812471\n","Take 11.922305865979098 %\n","------------------------------------------------------------\n","[27,     1] loss: 2.0581815242767334, time: 0.5623974800109863\n","[27,     2] loss: 1.8103420734405518, time: 1.1273252964019775\n","[27,     3] loss: 1.9506430625915527, time: 1.7004725933074951\n","[27,     4] loss: 1.8821985721588135, time: 2.231715440750122\n","[27,     5] loss: 1.9217162132263184, time: 2.767792224884033\n","[27,     6] loss: 2.277984857559204, time: 3.327327251434326\n","[27,     7] loss: 2.4970459938049316, time: 3.907980442047119\n","[27,     8] loss: 1.8237957954406738, time: 4.460029125213623\n","[27,     9] loss: 2.1318788528442383, time: 5.014365196228027\n","[27,    10] loss: 1.9201018810272217, time: 5.576884984970093\n","[27,    11] loss: 1.9500064849853516, time: 6.116086959838867\n","[27,    12] loss: 1.9512369632720947, time: 6.660700559616089\n","[27,    13] loss: 1.716148018836975, time: 7.206923246383667\n","[27,    14] loss: 1.8347280025482178, time: 7.73737359046936\n","[27,    15] loss: 2.1978399753570557, time: 8.304584503173828\n","[27,    16] loss: 1.9100236892700195, time: 8.880881071090698\n","[27,    17] loss: 1.9000141620635986, time: 9.42902159690857\n","[27,    18] loss: 1.8854635953903198, time: 9.97287392616272\n","[27,    19] loss: 1.8482000827789307, time: 10.525865316390991\n","[27,    20] loss: 2.103956937789917, time: 11.103516578674316\n","[27,    21] loss: 1.9304708242416382, time: 11.644805669784546\n","[27,    22] loss: 1.8784379959106445, time: 12.194394826889038\n","[27,    23] loss: 1.9036431312561035, time: 12.763939619064331\n","[27,    24] loss: 1.8127367496490479, time: 13.295903444290161\n","[27,    25] loss: 1.8753750324249268, time: 13.849264144897461\n","[27,    26] loss: 1.9437358379364014, time: 14.412713527679443\n","[27,    27] loss: 1.9126404523849487, time: 14.963382720947266\n","[27,    28] loss: 1.5553390979766846, time: 15.51516580581665\n","[27,    29] loss: 2.120087146759033, time: 16.073296785354614\n","[27,    30] loss: 1.75113046169281, time: 16.633996963500977\n","[27,    31] loss: 2.2072792053222656, time: 17.173091411590576\n","[27,    32] loss: 1.6272079944610596, time: 17.720383882522583\n","[27,    33] loss: 1.8444874286651611, time: 18.270283460617065\n","[27,    34] loss: 1.6134203672409058, time: 18.826499700546265\n","[27,    35] loss: 2.055792808532715, time: 19.358405113220215\n","[27,    36] loss: 1.723600149154663, time: 19.932235956192017\n","[27,    37] loss: 2.0065386295318604, time: 20.49553346633911\n","[27,    38] loss: 1.8571524620056152, time: 21.06020498275757\n","[27,    39] loss: 1.7603569030761719, time: 21.611375093460083\n","[27,    40] loss: 1.9162157773971558, time: 22.165026903152466\n","[27,    41] loss: 1.8659530878067017, time: 22.70340657234192\n","[27,    42] loss: 2.028872489929199, time: 23.257739067077637\n","[27,    43] loss: 1.9477380514144897, time: 23.82503890991211\n","[27,    44] loss: 1.6004128456115723, time: 24.375678777694702\n","[27,    45] loss: 1.7948981523513794, time: 24.92404532432556\n","[27,    46] loss: 2.2417163848876953, time: 25.48069190979004\n","[27,    47] loss: 1.722224235534668, time: 26.048162698745728\n","[27,    48] loss: 1.9095593690872192, time: 26.615817308425903\n","[27,    49] loss: 1.6970274448394775, time: 27.164342403411865\n","[27,    50] loss: 2.5578420162200928, time: 27.34077262878418\n","\n","Evaluation: Average loss: 1.3193, Accuracy: 576/947 (60.824%)\n","\n","************************************************************\n","Total removed parameters: 1418105.0\n","Take 40.24054573263301 % of active parameters\n","Total redistribution parameters: 2110033.0\n","Take: 148.7924377955088 % of removed parameters\n","Pruning rate: 0.41617468666760427\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.79 seconds.\n","\n","Total nonzero parameters:  2807114\n","Take 11.89959708337332 %\n","------------------------------------------------------------\n","[28,     1] loss: 1.6965888738632202, time: 0.5951652526855469\n","[28,     2] loss: 1.6875779628753662, time: 1.157973289489746\n","[28,     3] loss: 1.7901723384857178, time: 1.705122709274292\n","[28,     4] loss: 1.5264338254928589, time: 2.2593095302581787\n","[28,     5] loss: 1.9903243780136108, time: 2.7913708686828613\n","[28,     6] loss: 1.986372709274292, time: 3.3114089965820312\n","[28,     7] loss: 1.8596885204315186, time: 3.838348150253296\n","[28,     8] loss: 1.7158985137939453, time: 4.374387264251709\n","[28,     9] loss: 2.093756675720215, time: 4.9143967628479\n","[28,    10] loss: 1.3446775674819946, time: 5.442659616470337\n","[28,    11] loss: 1.6900098323822021, time: 5.988900423049927\n","[28,    12] loss: 1.7209244966506958, time: 6.545172691345215\n","[28,    13] loss: 1.704443335533142, time: 7.095923185348511\n","[28,    14] loss: 1.5691254138946533, time: 7.6491804122924805\n","[28,    15] loss: 2.0351250171661377, time: 8.215326070785522\n","[28,    16] loss: 2.2382986545562744, time: 8.745912551879883\n","[28,    17] loss: 1.8249781131744385, time: 9.29598879814148\n","[28,    18] loss: 1.5933600664138794, time: 9.841639518737793\n","[28,    19] loss: 1.9859087467193604, time: 10.415362358093262\n","[28,    20] loss: 1.7559969425201416, time: 10.963772773742676\n","[28,    21] loss: 1.643888235092163, time: 11.500013828277588\n","[28,    22] loss: 1.8032498359680176, time: 12.016857385635376\n","[28,    23] loss: 1.7613325119018555, time: 12.560977458953857\n","[28,    24] loss: 1.867282509803772, time: 13.115122318267822\n","[28,    25] loss: 1.5324511528015137, time: 13.671061277389526\n","[28,    26] loss: 1.8521023988723755, time: 14.210638999938965\n","[28,    27] loss: 2.124499559402466, time: 14.758940935134888\n","[28,    28] loss: 1.6597484350204468, time: 15.311379194259644\n","[28,    29] loss: 1.7666152715682983, time: 15.86734652519226\n","[28,    30] loss: 1.8700059652328491, time: 16.417187452316284\n","[28,    31] loss: 1.7956724166870117, time: 16.95773434638977\n","[28,    32] loss: 1.7463101148605347, time: 17.49170422554016\n","[28,    33] loss: 1.7876688241958618, time: 18.06503438949585\n","[28,    34] loss: 1.9447869062423706, time: 18.641513347625732\n","[28,    35] loss: 1.7110300064086914, time: 19.19987392425537\n","[28,    36] loss: 1.9002459049224854, time: 19.7519371509552\n","[28,    37] loss: 1.48671555519104, time: 20.292872667312622\n","[28,    38] loss: 1.7924304008483887, time: 20.847216844558716\n","[28,    39] loss: 2.0466907024383545, time: 21.395410776138306\n","[28,    40] loss: 1.7661818265914917, time: 21.924640417099\n","[28,    41] loss: 2.0747101306915283, time: 22.467787265777588\n","[28,    42] loss: 1.9775111675262451, time: 23.018047332763672\n","[28,    43] loss: 1.7348482608795166, time: 23.569236993789673\n","[28,    44] loss: 1.7840690612792969, time: 24.111260652542114\n","[28,    45] loss: 1.728493094444275, time: 24.6564838886261\n","[28,    46] loss: 1.7751202583312988, time: 25.192655324935913\n","[28,    47] loss: 1.6277978420257568, time: 25.74511456489563\n","[28,    48] loss: 1.7875233888626099, time: 26.27741813659668\n","[28,    49] loss: 1.8740429878234863, time: 26.82102394104004\n","[28,    50] loss: 1.4301984310150146, time: 26.988977193832397\n","\n","Evaluation: Average loss: 1.9780, Accuracy: 488/947 (51.531%)\n","\n","************************************************************\n","Total removed parameters: 1380261.0\n","Take 39.12151395438614 % of active parameters\n","Total redistribution parameters: 2146921.0\n","Take: 155.54456729560567 % of removed parameters\n","Pruning rate: 0.4102624374628011\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.36 seconds.\n","\n","Total nonzero parameters:  2818844\n","Take 11.949321559752967 %\n","------------------------------------------------------------\n","[29,     1] loss: 1.9668275117874146, time: 0.5430636405944824\n","[29,     2] loss: 1.9169044494628906, time: 1.0941205024719238\n","[29,     3] loss: 1.9509015083312988, time: 1.628263235092163\n","[29,     4] loss: 2.069654941558838, time: 2.1701321601867676\n","[29,     5] loss: 1.8120126724243164, time: 2.705538034439087\n","[29,     6] loss: 2.0383007526397705, time: 3.270353078842163\n","[29,     7] loss: 1.6496978998184204, time: 3.826321840286255\n","[29,     8] loss: 1.7909780740737915, time: 4.387904405593872\n","[29,     9] loss: 1.6399321556091309, time: 4.923128366470337\n","[29,    10] loss: 1.6072239875793457, time: 5.474031925201416\n","[29,    11] loss: 2.036916494369507, time: 6.02281379699707\n","[29,    12] loss: 1.8621777296066284, time: 6.538539409637451\n","[29,    13] loss: 1.4249101877212524, time: 7.063628435134888\n","[29,    14] loss: 2.213686943054199, time: 7.606377124786377\n","[29,    15] loss: 1.541696310043335, time: 8.147465467453003\n","[29,    16] loss: 1.6891220808029175, time: 8.713759422302246\n","[29,    17] loss: 1.769623041152954, time: 9.258353233337402\n","[29,    18] loss: 1.9602693319320679, time: 9.797026634216309\n","[29,    19] loss: 1.8843375444412231, time: 10.327142238616943\n","[29,    20] loss: 1.6123460531234741, time: 10.861611604690552\n","[29,    21] loss: 1.8535754680633545, time: 11.403544425964355\n","[29,    22] loss: 1.7097020149230957, time: 11.960473775863647\n","[29,    23] loss: 1.7563896179199219, time: 12.53086256980896\n","[29,    24] loss: 1.6393117904663086, time: 13.082969427108765\n","[29,    25] loss: 1.596779227256775, time: 13.620822191238403\n","[29,    26] loss: 1.9686720371246338, time: 14.165822505950928\n","[29,    27] loss: 1.5209496021270752, time: 14.705819129943848\n","[29,    28] loss: 2.0936362743377686, time: 15.241750478744507\n","[29,    29] loss: 1.9060999155044556, time: 15.792547225952148\n","[29,    30] loss: 1.495596170425415, time: 16.342764616012573\n","[29,    31] loss: 2.0850493907928467, time: 16.90657615661621\n","[29,    32] loss: 1.6125445365905762, time: 17.451003074645996\n","[29,    33] loss: 1.7003371715545654, time: 17.994253396987915\n","[29,    34] loss: 1.9226175546646118, time: 18.584712505340576\n","[29,    35] loss: 1.6221717596054077, time: 19.145533561706543\n","[29,    36] loss: 1.5890274047851562, time: 19.68728470802307\n","[29,    37] loss: 1.887382984161377, time: 20.247880220413208\n","[29,    38] loss: 2.105628252029419, time: 20.816327810287476\n","[29,    39] loss: 1.761703372001648, time: 21.37602686882019\n","[29,    40] loss: 1.4416534900665283, time: 21.91047739982605\n","[29,    41] loss: 1.9897637367248535, time: 22.44715976715088\n","[29,    42] loss: 1.6398648023605347, time: 22.990015745162964\n","[29,    43] loss: 1.964331865310669, time: 23.52701163291931\n","[29,    44] loss: 1.7560310363769531, time: 24.076037168502808\n","[29,    45] loss: 1.7970514297485352, time: 24.626943111419678\n","[29,    46] loss: 2.3730289936065674, time: 25.16710662841797\n","[29,    47] loss: 1.6415520906448364, time: 25.707249641418457\n","[29,    48] loss: 1.9956682920455933, time: 26.255096435546875\n","[29,    49] loss: 1.7500927448272705, time: 26.81785774230957\n","[29,    50] loss: 1.9754761457443237, time: 26.999829292297363\n","\n","Evaluation: Average loss: 1.4238, Accuracy: 530/947 (55.966%)\n","\n","************************************************************\n","Total removed parameters: 1378639.0\n","Take 39.086131648437764 % of active parameters\n","Total redistribution parameters: 2147215.0\n","Take: 155.7488943806174 % of removed parameters\n","Pruning rate: 0.4041944957791121\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.45 seconds.\n","\n","Total nonzero parameters:  2833874\n","Take 12.01303501925732 %\n","------------------------------------------------------------\n","[30,     1] loss: 1.4133933782577515, time: 0.5426392555236816\n","[30,     2] loss: 1.4612730741500854, time: 1.0993385314941406\n","[30,     3] loss: 1.5485767126083374, time: 1.6604843139648438\n","[30,     4] loss: 1.8395873308181763, time: 2.209296703338623\n","[30,     5] loss: 1.4822534322738647, time: 2.7582809925079346\n","[30,     6] loss: 1.3865026235580444, time: 3.297011613845825\n","[30,     7] loss: 1.6907716989517212, time: 3.8382108211517334\n","[30,     8] loss: 1.8412114381790161, time: 4.428788661956787\n","[30,     9] loss: 1.6837178468704224, time: 4.996631383895874\n","[30,    10] loss: 2.1679489612579346, time: 5.546050310134888\n","[30,    11] loss: 1.3700474500656128, time: 6.08649754524231\n","[30,    12] loss: 1.876692295074463, time: 6.6110334396362305\n","[30,    13] loss: 1.707590103149414, time: 7.1675965785980225\n","[30,    14] loss: 2.1647486686706543, time: 7.722731113433838\n","[30,    15] loss: 1.9246002435684204, time: 8.251455068588257\n","[30,    16] loss: 1.992355465888977, time: 8.82054615020752\n","[30,    17] loss: 1.5692065954208374, time: 9.35499382019043\n","[30,    18] loss: 1.5904524326324463, time: 9.884159326553345\n","[30,    19] loss: 1.6655211448669434, time: 10.448155164718628\n","[30,    20] loss: 1.6350133419036865, time: 10.982357263565063\n","[30,    21] loss: 1.8183573484420776, time: 11.508719444274902\n","[30,    22] loss: 2.0476858615875244, time: 12.042717695236206\n","[30,    23] loss: 1.7762870788574219, time: 12.589948415756226\n","[30,    24] loss: 1.7627848386764526, time: 13.106292486190796\n","[30,    25] loss: 1.5363579988479614, time: 13.633830070495605\n","[30,    26] loss: 1.7512632608413696, time: 14.18268370628357\n","[30,    27] loss: 1.6847972869873047, time: 14.715585708618164\n","[30,    28] loss: 1.919958472251892, time: 15.245803594589233\n","[30,    29] loss: 1.7942806482315063, time: 15.768333673477173\n","[30,    30] loss: 1.7661844491958618, time: 16.321386337280273\n","[30,    31] loss: 1.6493563652038574, time: 16.88559341430664\n","[30,    32] loss: 1.9588897228240967, time: 17.422207593917847\n","[30,    33] loss: 1.882683515548706, time: 17.96432375907898\n","[30,    34] loss: 1.570278286933899, time: 18.496448040008545\n","[30,    35] loss: 1.8008754253387451, time: 19.05158805847168\n","[30,    36] loss: 1.6258788108825684, time: 19.602869510650635\n","[30,    37] loss: 1.920341968536377, time: 20.158641815185547\n","[30,    38] loss: 1.7174553871154785, time: 20.722025394439697\n","[30,    39] loss: 1.4831722974777222, time: 21.27873682975769\n","[30,    40] loss: 1.7007805109024048, time: 21.841493606567383\n","[30,    41] loss: 1.6699398756027222, time: 22.413512706756592\n","[30,    42] loss: 1.6429375410079956, time: 22.973366260528564\n","[30,    43] loss: 1.5433440208435059, time: 23.516185760498047\n","[30,    44] loss: 1.4096487760543823, time: 24.05361008644104\n","[30,    45] loss: 1.7504252195358276, time: 24.607499837875366\n","[30,    46] loss: 1.6762629747390747, time: 25.180410623550415\n","[30,    47] loss: 1.9045135974884033, time: 25.7113618850708\n","[30,    48] loss: 1.581921100616455, time: 26.255460739135742\n","[30,    49] loss: 1.8804166316986084, time: 26.796258687973022\n","[30,    50] loss: 1.9435248374938965, time: 26.971418619155884\n","\n","Evaluation: Average loss: 1.4638, Accuracy: 520/947 (54.910%)\n","\n","************************************************************\n","Total removed parameters: 1337670.0\n","Take 37.938893669448596 % of active parameters\n","Total redistribution parameters: 2185292.0\n","Take: 163.36555353712052 % of removed parameters\n","Pruning rate: 0.39797684994238736\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.43 seconds.\n","\n","Total nonzero parameters:  2866443\n","Take 12.151097804526598 %\n","------------------------------------------------------------\n","[31,     1] loss: 1.7486525774002075, time: 0.549494743347168\n","[31,     2] loss: 1.720232605934143, time: 1.1122722625732422\n","[31,     3] loss: 2.0812039375305176, time: 1.6743464469909668\n","[31,     4] loss: 1.856569528579712, time: 2.2506706714630127\n","[31,     5] loss: 1.6626309156417847, time: 2.7911641597747803\n","[31,     6] loss: 1.794590950012207, time: 3.320584297180176\n","[31,     7] loss: 2.1236958503723145, time: 3.880305051803589\n","[31,     8] loss: 1.4817631244659424, time: 4.438860654830933\n","[31,     9] loss: 1.8941640853881836, time: 5.018464088439941\n","[31,    10] loss: 2.0803604125976562, time: 5.5546324253082275\n","[31,    11] loss: 1.7862247228622437, time: 6.099754571914673\n","[31,    12] loss: 1.823953628540039, time: 6.6299238204956055\n","[31,    13] loss: 1.973621129989624, time: 7.168635368347168\n","[31,    14] loss: 1.99721360206604, time: 7.721306085586548\n","[31,    15] loss: 1.7615677118301392, time: 8.288721799850464\n","[31,    16] loss: 1.544356346130371, time: 8.84113335609436\n","[31,    17] loss: 1.4809895753860474, time: 9.377211332321167\n","[31,    18] loss: 1.5450127124786377, time: 9.93978238105774\n","[31,    19] loss: 2.056142568588257, time: 10.48691177368164\n","[31,    20] loss: 1.6936269998550415, time: 11.024331092834473\n","[31,    21] loss: 1.8898046016693115, time: 11.565884590148926\n","[31,    22] loss: 1.3807445764541626, time: 12.137082815170288\n","[31,    23] loss: 1.6617108583450317, time: 12.685946226119995\n","[31,    24] loss: 1.5918585062026978, time: 13.241698503494263\n","[31,    25] loss: 2.014711856842041, time: 13.831690788269043\n","[31,    26] loss: 1.6953881978988647, time: 14.40094804763794\n","[31,    27] loss: 1.5010069608688354, time: 14.953288316726685\n","[31,    28] loss: 1.7932106256484985, time: 15.50785517692566\n","[31,    29] loss: 2.026559591293335, time: 16.06510066986084\n","[31,    30] loss: 1.6509065628051758, time: 16.606560468673706\n","[31,    31] loss: 2.058814287185669, time: 17.15540838241577\n","[31,    32] loss: 1.758988380432129, time: 17.709620714187622\n","[31,    33] loss: 1.6310272216796875, time: 18.265138387680054\n","[31,    34] loss: 1.4218848943710327, time: 18.806113719940186\n","[31,    35] loss: 1.4093035459518433, time: 19.348906755447388\n","[31,    36] loss: 2.017529010772705, time: 19.914517164230347\n","[31,    37] loss: 1.948193907737732, time: 20.505929231643677\n","[31,    38] loss: 1.793009638786316, time: 21.06461453437805\n","[31,    39] loss: 1.6448378562927246, time: 21.616795301437378\n","[31,    40] loss: 1.493924617767334, time: 22.180699825286865\n","[31,    41] loss: 1.6859300136566162, time: 22.74043297767639\n","[31,    42] loss: 2.0105574131011963, time: 23.318754196166992\n","[31,    43] loss: 1.6022765636444092, time: 23.89614176750183\n","[31,    44] loss: 1.7911629676818848, time: 24.454177141189575\n","[31,    45] loss: 1.6987807750701904, time: 25.021000862121582\n","[31,    46] loss: 2.0221145153045654, time: 25.601746797561646\n","[31,    47] loss: 1.698481798171997, time: 26.182278156280518\n","[31,    48] loss: 1.5027036666870117, time: 26.739229917526245\n","[31,    49] loss: 1.7890211343765259, time: 27.30420970916748\n","[31,    50] loss: 2.1240289211273193, time: 27.488219022750854\n","\n","Evaluation: Average loss: 1.4381, Accuracy: 534/947 (56.389%)\n","\n","************************************************************\n","Total removed parameters: 1334184.0\n","Take 37.87108688654604 % of active parameters\n","Total redistribution parameters: 2192441.0\n","Take: 164.32823358697152 % of removed parameters\n","Pruning rate: 0.39161563601840244\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.\n","\n","Total nonzero parameters:  2864587\n","Take 12.143230061290398 %\n","------------------------------------------------------------\n","[32,     1] loss: 1.3252228498458862, time: 0.5424976348876953\n","[32,     2] loss: 1.7320162057876587, time: 1.1194396018981934\n","[32,     3] loss: 2.080411911010742, time: 1.6864986419677734\n","[32,     4] loss: 1.5809059143066406, time: 2.242452621459961\n","[32,     5] loss: 1.7710740566253662, time: 2.7910966873168945\n","[32,     6] loss: 1.5917072296142578, time: 3.333453893661499\n","[32,     7] loss: 1.8104183673858643, time: 3.8870139122009277\n","[32,     8] loss: 1.982283592224121, time: 4.46456241607666\n","[32,     9] loss: 2.1888184547424316, time: 5.0136401653289795\n","[32,    10] loss: 1.9057409763336182, time: 5.545047760009766\n","[32,    11] loss: 1.8907493352890015, time: 6.07871150970459\n","[32,    12] loss: 2.245023250579834, time: 6.689579486846924\n","[32,    13] loss: 1.8915972709655762, time: 7.243745565414429\n","[32,    14] loss: 1.9733052253723145, time: 7.822644233703613\n","[32,    15] loss: 1.4519829750061035, time: 8.367853164672852\n","[32,    16] loss: 1.8346953392028809, time: 8.92280912399292\n","[32,    17] loss: 1.9222195148468018, time: 9.468110084533691\n","[32,    18] loss: 1.724509835243225, time: 10.016202211380005\n","[32,    19] loss: 1.8767452239990234, time: 10.589832782745361\n","[32,    20] loss: 1.5913832187652588, time: 11.129649639129639\n","[32,    21] loss: 1.6496917009353638, time: 11.683430433273315\n","[32,    22] loss: 1.748144507408142, time: 12.239070892333984\n","[32,    23] loss: 1.8707464933395386, time: 12.810786485671997\n","[32,    24] loss: 1.7880418300628662, time: 13.373249769210815\n","[32,    25] loss: 1.6908375024795532, time: 13.910470247268677\n","[32,    26] loss: 1.2357304096221924, time: 14.435103416442871\n","[32,    27] loss: 1.4697529077529907, time: 14.986668586730957\n","[32,    28] loss: 1.6529160737991333, time: 15.530998706817627\n","[32,    29] loss: 1.362838625907898, time: 16.05549168586731\n","[32,    30] loss: 1.4374312162399292, time: 16.618966579437256\n","[32,    31] loss: 1.5200517177581787, time: 17.1895649433136\n","[32,    32] loss: 1.844674825668335, time: 17.76181960105896\n","[32,    33] loss: 1.5702362060546875, time: 18.336287260055542\n","[32,    34] loss: 1.6318119764328003, time: 18.91292428970337\n","[32,    35] loss: 1.8245307207107544, time: 19.467634201049805\n","[32,    36] loss: 1.5106793642044067, time: 20.025943994522095\n","[32,    37] loss: 1.581568717956543, time: 20.56954312324524\n","[32,    38] loss: 1.5922465324401855, time: 21.117255210876465\n","[32,    39] loss: 1.4642497301101685, time: 21.67091155052185\n","[32,    40] loss: 1.4346305131912231, time: 22.229305744171143\n","[32,    41] loss: 1.2483654022216797, time: 22.784592628479004\n","[32,    42] loss: 1.3855350017547607, time: 23.34000325202942\n","[32,    43] loss: 1.947077751159668, time: 23.92598557472229\n","[32,    44] loss: 1.7434406280517578, time: 24.482421398162842\n","[32,    45] loss: 1.6361390352249146, time: 25.016401529312134\n","[32,    46] loss: 1.7201697826385498, time: 25.570419311523438\n","[32,    47] loss: 1.9672797918319702, time: 26.142096996307373\n","[32,    48] loss: 1.4905412197113037, time: 26.721332550048828\n","[32,    49] loss: 1.5021542310714722, time: 27.27829623222351\n","[32,    50] loss: 1.4364354610443115, time: 27.468327283859253\n","\n","Evaluation: Average loss: 1.2040, Accuracy: 622/947 (65.681%)\n","\n","************************************************************\n","Total removed parameters: 1309601.0\n","Take 37.134682593130826 % of active parameters\n","Total redistribution parameters: 2218814.0\n","Take: 169.42671851961018 % of removed parameters\n","Pruning rate: 0.3851171317573019\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.93 seconds.\n","\n","Total nonzero parameters:  2878455\n","Take 12.202017703100536 %\n","------------------------------------------------------------\n","[33,     1] loss: 1.7664663791656494, time: 0.5616433620452881\n","[33,     2] loss: 1.8750755786895752, time: 1.1138834953308105\n","[33,     3] loss: 1.5630580186843872, time: 1.6456074714660645\n","[33,     4] loss: 1.4798765182495117, time: 2.1894052028656006\n","[33,     5] loss: 1.9027711153030396, time: 2.7187492847442627\n","[33,     6] loss: 1.6248070001602173, time: 3.2678110599517822\n","[33,     7] loss: 1.6423052549362183, time: 3.824690580368042\n","[33,     8] loss: 1.458204746246338, time: 4.381988525390625\n","[33,     9] loss: 1.4183311462402344, time: 4.938592195510864\n","[33,    10] loss: 1.4237366914749146, time: 5.497025728225708\n","[33,    11] loss: 1.604933738708496, time: 6.042070627212524\n","[33,    12] loss: 2.0247879028320312, time: 6.619190216064453\n","[33,    13] loss: 1.5851349830627441, time: 7.168976306915283\n","[33,    14] loss: 1.5339082479476929, time: 7.71600866317749\n","[33,    15] loss: 1.7239863872528076, time: 8.262237548828125\n","[33,    16] loss: 1.7242214679718018, time: 8.818831205368042\n","[33,    17] loss: 1.400660753250122, time: 9.36635136604309\n","[33,    18] loss: 1.7047615051269531, time: 9.931929588317871\n","[33,    19] loss: 2.050736427307129, time: 10.48194670677185\n","[33,    20] loss: 1.8233485221862793, time: 11.034382343292236\n","[33,    21] loss: 1.108691930770874, time: 11.571873426437378\n","[33,    22] loss: 1.5326770544052124, time: 12.115613460540771\n","[33,    23] loss: 1.8710846900939941, time: 12.655807971954346\n","[33,    24] loss: 2.100944757461548, time: 13.218093395233154\n","[33,    25] loss: 1.82581627368927, time: 13.782631397247314\n","[33,    26] loss: 1.427406907081604, time: 14.346092462539673\n","[33,    27] loss: 1.7641083002090454, time: 14.910988330841064\n","[33,    28] loss: 1.793491005897522, time: 15.440784215927124\n","[33,    29] loss: 1.5384286642074585, time: 15.971655130386353\n","[33,    30] loss: 1.6384871006011963, time: 16.524465799331665\n","[33,    31] loss: 1.5651676654815674, time: 17.080850839614868\n","[33,    32] loss: 2.0720317363739014, time: 17.646641492843628\n","[33,    33] loss: 1.6086292266845703, time: 18.21248507499695\n","[33,    34] loss: 1.5648363828659058, time: 18.788499355316162\n","[33,    35] loss: 1.4447077512741089, time: 19.353744506835938\n","[33,    36] loss: 1.7980114221572876, time: 19.915679216384888\n","[33,    37] loss: 1.371689796447754, time: 20.45860743522644\n","[33,    38] loss: 1.356844425201416, time: 21.009379625320435\n","[33,    39] loss: 1.2238138914108276, time: 21.550728797912598\n","[33,    40] loss: 1.5976556539535522, time: 22.084612369537354\n","[33,    41] loss: 1.39458167552948, time: 22.615636348724365\n","[33,    42] loss: 1.5855917930603027, time: 23.150301933288574\n","[33,    43] loss: 1.2930006980895996, time: 23.687403202056885\n","[33,    44] loss: 1.628962516784668, time: 24.23059868812561\n","[33,    45] loss: 1.8200840950012207, time: 24.778624296188354\n","[33,    46] loss: 1.5954371690750122, time: 25.30979084968567\n","[33,    47] loss: 1.8541452884674072, time: 25.85782217979431\n","[33,    48] loss: 1.336794376373291, time: 26.406420707702637\n","[33,    49] loss: 1.4003373384475708, time: 26.945708751678467\n","[33,    50] loss: 2.364781141281128, time: 27.116694688796997\n","\n","Evaluation: Average loss: 1.1276, Accuracy: 621/947 (65.576%)\n","\n","************************************************************\n","Total removed parameters: 1291634.0\n","Take 36.60663499049857 % of active parameters\n","Total redistribution parameters: 2236115.0\n","Take: 173.12295898064002 % of removed parameters\n","Pruning rate: 0.378487750398217\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.50 seconds.\n","\n","Total nonzero parameters:  2888271\n","Take 12.243628569267848 %\n","------------------------------------------------------------\n","[34,     1] loss: 1.791229009628296, time: 0.5477809906005859\n","[34,     2] loss: 1.356287956237793, time: 1.1087627410888672\n","[34,     3] loss: 1.5586868524551392, time: 1.6868846416473389\n","[34,     4] loss: 1.712706208229065, time: 2.2439279556274414\n","[34,     5] loss: 1.7979875802993774, time: 2.7982327938079834\n","[34,     6] loss: 1.901531457901001, time: 3.3403236865997314\n","[34,     7] loss: 1.960383415222168, time: 3.8996224403381348\n","[34,     8] loss: 1.95018470287323, time: 4.437167644500732\n","[34,     9] loss: 1.7091834545135498, time: 4.985035419464111\n","[34,    10] loss: 1.393818974494934, time: 5.50245213508606\n","[34,    11] loss: 1.586536169052124, time: 6.043401002883911\n","[34,    12] loss: 1.7170400619506836, time: 6.570259094238281\n","[34,    13] loss: 1.4490485191345215, time: 7.104126691818237\n","[34,    14] loss: 1.6092063188552856, time: 7.669286727905273\n","[34,    15] loss: 1.551312804222107, time: 8.239642143249512\n","[34,    16] loss: 1.436079978942871, time: 8.781177043914795\n","[34,    17] loss: 1.6903148889541626, time: 9.330045461654663\n","[34,    18] loss: 1.4456602334976196, time: 9.870532274246216\n","[34,    19] loss: 1.7735602855682373, time: 10.428548574447632\n","[34,    20] loss: 1.9137462377548218, time: 10.999418020248413\n","[34,    21] loss: 1.369840145111084, time: 11.55380916595459\n","[34,    22] loss: 1.7104685306549072, time: 12.127012491226196\n","[34,    23] loss: 1.3272031545639038, time: 12.704991102218628\n","[34,    24] loss: 1.7900002002716064, time: 13.28922414779663\n","[34,    25] loss: 2.084564208984375, time: 13.875010013580322\n","[34,    26] loss: 1.8498950004577637, time: 14.433708190917969\n","[34,    27] loss: 1.424519658088684, time: 14.97325849533081\n","[34,    28] loss: 1.1817761659622192, time: 15.527752161026001\n","[34,    29] loss: 1.7654681205749512, time: 16.08040189743042\n","[34,    30] loss: 1.5788999795913696, time: 16.622924327850342\n","[34,    31] loss: 1.4842842817306519, time: 17.17214846611023\n","[34,    32] loss: 1.5436367988586426, time: 17.731897592544556\n","[34,    33] loss: 1.4693411588668823, time: 18.27449870109558\n","[34,    34] loss: 1.236199140548706, time: 18.823578357696533\n","[34,    35] loss: 1.5457124710083008, time: 19.363605737686157\n","[34,    36] loss: 1.284993290901184, time: 19.93861413002014\n","[34,    37] loss: 1.7493987083435059, time: 20.496058225631714\n","[34,    38] loss: 1.562206745147705, time: 21.064970016479492\n","[34,    39] loss: 1.5161594152450562, time: 21.601344347000122\n","[34,    40] loss: 1.3428699970245361, time: 22.15299677848816\n","[34,    41] loss: 1.5560288429260254, time: 22.69664216041565\n","[34,    42] loss: 1.3804954290390015, time: 23.25043225288391\n","[34,    43] loss: 1.5608657598495483, time: 23.795732975006104\n","[34,    44] loss: 1.526062250137329, time: 24.343347549438477\n","[34,    45] loss: 1.7160850763320923, time: 24.899872303009033\n","[34,    46] loss: 1.4740618467330933, time: 25.435967206954956\n","[34,    47] loss: 1.659505844116211, time: 25.970974922180176\n","[34,    48] loss: 1.407071590423584, time: 26.50903630256653\n","[34,    49] loss: 1.7309750318527222, time: 27.066434621810913\n","[34,    50] loss: 2.0153279304504395, time: 27.239472150802612\n","\n","Evaluation: Average loss: 1.7909, Accuracy: 478/947 (50.475%)\n","\n","************************************************************\n","Total removed parameters: 1259198.0\n","Take 35.69409274866211 % of active parameters\n","Total redistribution parameters: 2261583.0\n","Take: 179.60503431549287 % of removed parameters\n","Pruning rate: 0.37173403434017466\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.63 seconds.\n","\n","Total nonzero parameters:  2901270\n","Take 12.298732445521813 %\n","------------------------------------------------------------\n","[35,     1] loss: 1.5152058601379395, time: 0.5294222831726074\n","[35,     2] loss: 1.743852972984314, time: 1.0895748138427734\n","[35,     3] loss: 1.668154239654541, time: 1.6372947692871094\n","[35,     4] loss: 1.8106379508972168, time: 2.1700456142425537\n","[35,     5] loss: 1.6839991807937622, time: 2.7228453159332275\n","[35,     6] loss: 1.8532536029815674, time: 3.2527384757995605\n","[35,     7] loss: 1.6939395666122437, time: 3.800941228866577\n","[35,     8] loss: 1.4890161752700806, time: 4.34039044380188\n","[35,     9] loss: 1.6546319723129272, time: 4.893129110336304\n","[35,    10] loss: 2.0021607875823975, time: 5.456166505813599\n","[35,    11] loss: 1.6887056827545166, time: 6.0265326499938965\n","[35,    12] loss: 1.365154504776001, time: 6.56205940246582\n","[35,    13] loss: 1.5409454107284546, time: 7.102962017059326\n","[35,    14] loss: 1.4312294721603394, time: 7.64393162727356\n","[35,    15] loss: 1.41719651222229, time: 8.19149899482727\n","[35,    16] loss: 1.6844192743301392, time: 8.740261793136597\n","[35,    17] loss: 1.468306064605713, time: 9.278923749923706\n","[35,    18] loss: 1.6796464920043945, time: 9.83271861076355\n","[35,    19] loss: 1.4699560403823853, time: 10.377476453781128\n","[35,    20] loss: 1.5543943643569946, time: 10.953852891921997\n","[35,    21] loss: 1.383599042892456, time: 11.498701810836792\n","[35,    22] loss: 1.322313904762268, time: 12.045589208602905\n","[35,    23] loss: 1.6233800649642944, time: 12.621487379074097\n","[35,    24] loss: 1.6588232517242432, time: 13.22089409828186\n","[35,    25] loss: 1.4813750982284546, time: 13.792075634002686\n","[35,    26] loss: 1.4632568359375, time: 14.347302675247192\n","[35,    27] loss: 1.5476961135864258, time: 14.884531736373901\n","[35,    28] loss: 1.3136820793151855, time: 15.426571369171143\n","[35,    29] loss: 1.516953468322754, time: 15.973279237747192\n","[35,    30] loss: 1.2921149730682373, time: 16.52241039276123\n","[35,    31] loss: 1.763870120048523, time: 17.060280323028564\n","[35,    32] loss: 1.6003187894821167, time: 17.622303009033203\n","[35,    33] loss: 1.723625898361206, time: 18.181634664535522\n","[35,    34] loss: 1.5857322216033936, time: 18.753239631652832\n","[35,    35] loss: 1.5732706785202026, time: 19.314002513885498\n","[35,    36] loss: 1.850901484489441, time: 19.885645151138306\n","[35,    37] loss: 1.5769404172897339, time: 20.440802812576294\n","[35,    38] loss: 2.260040283203125, time: 21.00858163833618\n","[35,    39] loss: 1.8388288021087646, time: 21.56206178665161\n","[35,    40] loss: 1.6742610931396484, time: 22.134780645370483\n","[35,    41] loss: 1.4121392965316772, time: 22.70407462120056\n","[35,    42] loss: 1.536812663078308, time: 23.25207257270813\n","[35,    43] loss: 1.4881445169448853, time: 23.824484825134277\n","[35,    44] loss: 1.284263253211975, time: 24.38115406036377\n","[35,    45] loss: 1.724317193031311, time: 24.93225598335266\n","[35,    46] loss: 1.4424210786819458, time: 25.4654061794281\n","[35,    47] loss: 1.4748871326446533, time: 26.01454734802246\n","[35,    48] loss: 1.7606170177459717, time: 26.551990270614624\n","[35,    49] loss: 1.5094555616378784, time: 27.078720092773438\n","[35,    50] loss: 2.558964490890503, time: 27.257283926010132\n","\n","Evaluation: Average loss: 1.4807, Accuracy: 540/947 (57.022%)\n","\n","************************************************************\n","Total removed parameters: 1232816.0\n","Take 35.015412773472704 % of active parameters\n","Total redistribution parameters: 2292214.0\n","Take: 185.9331806206279 % of removed parameters\n","Pruning rate: 0.3648626486855376\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.70 seconds.\n","\n","Total nonzero parameters:  2911504\n","Take 12.34211524955159 %\n","------------------------------------------------------------\n","[36,     1] loss: 1.3249696493148804, time: 0.5731914043426514\n","[36,     2] loss: 1.4230440855026245, time: 1.1327319145202637\n","[36,     3] loss: 1.8093311786651611, time: 1.6775517463684082\n","[36,     4] loss: 1.6332557201385498, time: 2.224976062774658\n","[36,     5] loss: 1.8500953912734985, time: 2.7710556983947754\n","[36,     6] loss: 1.822381615638733, time: 3.310429096221924\n","[36,     7] loss: 1.6463549137115479, time: 3.855469226837158\n","[36,     8] loss: 1.791894793510437, time: 4.403211355209351\n","[36,     9] loss: 1.430655837059021, time: 4.9393274784088135\n","[36,    10] loss: 1.4084298610687256, time: 5.476511478424072\n","[36,    11] loss: 1.5950301885604858, time: 6.018505096435547\n","[36,    12] loss: 1.652793526649475, time: 6.56802773475647\n","[36,    13] loss: 1.4624850749969482, time: 7.109030246734619\n","[36,    14] loss: 1.619516372680664, time: 7.671344041824341\n","[36,    15] loss: 1.729764461517334, time: 8.216008186340332\n","[36,    16] loss: 1.5196077823638916, time: 8.772221088409424\n","[36,    17] loss: 1.342759609222412, time: 9.321683406829834\n","[36,    18] loss: 2.0268802642822266, time: 9.874623775482178\n","[36,    19] loss: 1.551955223083496, time: 10.432248830795288\n","[36,    20] loss: 1.1652871370315552, time: 10.991825103759766\n","[36,    21] loss: 1.663741111755371, time: 11.541884422302246\n","[36,    22] loss: 1.7274278402328491, time: 12.091763973236084\n","[36,    23] loss: 1.370171070098877, time: 12.628896713256836\n","[36,    24] loss: 1.8717068433761597, time: 13.163686990737915\n","[36,    25] loss: 1.2133897542953491, time: 13.715104341506958\n","[36,    26] loss: 1.537121057510376, time: 14.25812029838562\n","[36,    27] loss: 1.3998911380767822, time: 14.80882215499878\n","[36,    28] loss: 1.653009295463562, time: 15.366251707077026\n","[36,    29] loss: 1.3607689142227173, time: 15.90459942817688\n","[36,    30] loss: 1.4955137968063354, time: 16.455147743225098\n","[36,    31] loss: 1.4680113792419434, time: 17.01747179031372\n","[36,    32] loss: 1.5176010131835938, time: 17.569541215896606\n","[36,    33] loss: 1.4311168193817139, time: 18.094698667526245\n","[36,    34] loss: 1.4555546045303345, time: 18.6356463432312\n","[36,    35] loss: 1.6892796754837036, time: 19.178577184677124\n","[36,    36] loss: 1.667685866355896, time: 19.72746968269348\n","[36,    37] loss: 1.5684603452682495, time: 20.272802352905273\n","[36,    38] loss: 1.7614022493362427, time: 20.83659839630127\n","[36,    39] loss: 1.4979530572891235, time: 21.36646604537964\n","[36,    40] loss: 1.4139947891235352, time: 21.924885034561157\n","[36,    41] loss: 1.6158558130264282, time: 22.452011108398438\n","[36,    42] loss: 1.3625432252883911, time: 22.984479427337646\n","[36,    43] loss: 1.7827688455581665, time: 23.53712558746338\n","[36,    44] loss: 1.3917181491851807, time: 24.10025405883789\n","[36,    45] loss: 1.6060600280761719, time: 24.66670823097229\n","[36,    46] loss: 1.5626187324523926, time: 25.200897932052612\n","[36,    47] loss: 1.5509140491485596, time: 25.759048461914062\n","[36,    48] loss: 1.4320402145385742, time: 26.29309630393982\n","[36,    49] loss: 1.6948260068893433, time: 26.83715796470642\n","[36,    50] loss: 1.52503502368927, time: 27.018513679504395\n","\n","Evaluation: Average loss: 2.5503, Accuracy: 448/947 (47.307%)\n","\n","************************************************************\n","Total removed parameters: 1223918.0\n","Take 34.72078251816296 % of active parameters\n","Total redistribution parameters: 2304506.0\n","Take: 188.28924813590453 % of removed parameters\n","Pruning rate: 0.35788037466235534\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.77 seconds.\n","\n","Total nonzero parameters:  2921184\n","Take 12.383149600050732 %\n","------------------------------------------------------------\n","[37,     1] loss: 1.499021291732788, time: 0.5685806274414062\n","[37,     2] loss: 1.3946377038955688, time: 1.1167042255401611\n","[37,     3] loss: 2.0080597400665283, time: 1.6450347900390625\n","[37,     4] loss: 1.4214277267456055, time: 2.1789350509643555\n","[37,     5] loss: 1.271069884300232, time: 2.7176661491394043\n","[37,     6] loss: 1.5080379247665405, time: 3.257460594177246\n","[37,     7] loss: 1.8469089269638062, time: 3.823413610458374\n","[37,     8] loss: 1.6160789728164673, time: 4.360350847244263\n","[37,     9] loss: 1.4219379425048828, time: 4.904351234436035\n","[37,    10] loss: 1.6324548721313477, time: 5.484456539154053\n","[37,    11] loss: 1.2954628467559814, time: 6.009347438812256\n","[37,    12] loss: 1.7804670333862305, time: 6.5650506019592285\n","[37,    13] loss: 1.4309930801391602, time: 7.115132570266724\n","[37,    14] loss: 1.607280969619751, time: 7.669407844543457\n","[37,    15] loss: 1.3448275327682495, time: 8.217787027359009\n","[37,    16] loss: 1.301261305809021, time: 8.769168138504028\n","[37,    17] loss: 1.5453670024871826, time: 9.321085929870605\n","[37,    18] loss: 1.2714669704437256, time: 9.882604122161865\n","[37,    19] loss: 1.5259580612182617, time: 10.439319610595703\n","[37,    20] loss: 1.4882256984710693, time: 11.004240274429321\n","[37,    21] loss: 2.0058460235595703, time: 11.59334921836853\n","[37,    22] loss: 1.86724054813385, time: 12.177248239517212\n","[37,    23] loss: 1.6543930768966675, time: 12.756160497665405\n","[37,    24] loss: 1.6018561124801636, time: 13.308510065078735\n","[37,    25] loss: 1.7404561042785645, time: 13.877898693084717\n","[37,    26] loss: 1.5846112966537476, time: 14.443795919418335\n","[37,    27] loss: 1.549171805381775, time: 15.017077684402466\n","[37,    28] loss: 1.5607991218566895, time: 15.54504942893982\n","[37,    29] loss: 1.4220445156097412, time: 16.087576866149902\n","[37,    30] loss: 1.441817283630371, time: 16.655308961868286\n","[37,    31] loss: 1.633862018585205, time: 17.215643167495728\n","[37,    32] loss: 1.4349884986877441, time: 17.761985301971436\n","[37,    33] loss: 1.3594298362731934, time: 18.295639991760254\n","[37,    34] loss: 1.8956117630004883, time: 18.867326259613037\n","[37,    35] loss: 1.47113037109375, time: 19.42553949356079\n","[37,    36] loss: 1.6322702169418335, time: 19.976851224899292\n","[37,    37] loss: 1.2943382263183594, time: 20.49844741821289\n","[37,    38] loss: 1.332048773765564, time: 21.046858072280884\n","[37,    39] loss: 1.454836368560791, time: 21.579905033111572\n","[37,    40] loss: 1.3514400720596313, time: 22.131053686141968\n","[37,    41] loss: 1.2129873037338257, time: 22.668437242507935\n","[37,    42] loss: 1.7366987466812134, time: 23.217195749282837\n","[37,    43] loss: 1.526822805404663, time: 23.775782585144043\n","[37,    44] loss: 1.6427417993545532, time: 24.328372955322266\n","[37,    45] loss: 1.5618618726730347, time: 24.90610098838806\n","[37,    46] loss: 1.6001757383346558, time: 25.468108415603638\n","[37,    47] loss: 1.3644239902496338, time: 26.04306650161743\n","[37,    48] loss: 1.3304400444030762, time: 26.59779167175293\n","[37,    49] loss: 1.6452186107635498, time: 27.157960176467896\n","[37,    50] loss: 1.194096565246582, time: 27.33066725730896\n","\n","Evaluation: Average loss: 1.9062, Accuracy: 489/947 (51.637%)\n","\n","************************************************************\n","Total removed parameters: 1182644.0\n","Take 33.517627133247025 % of active parameters\n","Total redistribution parameters: 2344321.0\n","Take: 198.22710807309724 % of removed parameters\n","Pruning rate: 0.3507941029321081\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.80 seconds.\n","\n","Total nonzero parameters:  2940303\n","Take 12.464196681372337 %\n","------------------------------------------------------------\n","[38,     1] loss: 1.65487539768219, time: 0.575798511505127\n","[38,     2] loss: 1.4910390377044678, time: 1.156381607055664\n","[38,     3] loss: 1.8960657119750977, time: 1.7133214473724365\n","[38,     4] loss: 1.4705373048782349, time: 2.2521283626556396\n","[38,     5] loss: 1.8180358409881592, time: 2.800165891647339\n","[38,     6] loss: 1.5587517023086548, time: 3.3341221809387207\n","[38,     7] loss: 1.702293038368225, time: 3.88647198677063\n","[38,     8] loss: 1.528850793838501, time: 4.426539421081543\n","[38,     9] loss: 1.567731261253357, time: 4.969218730926514\n","[38,    10] loss: 1.2033220529556274, time: 5.505855321884155\n","[38,    11] loss: 1.3345409631729126, time: 6.0394532680511475\n","[38,    12] loss: 1.4269546270370483, time: 6.580053806304932\n","[38,    13] loss: 1.5810514688491821, time: 7.1284565925598145\n","[38,    14] loss: 1.4087932109832764, time: 7.676107406616211\n","[38,    15] loss: 1.1699920892715454, time: 8.225278377532959\n","[38,    16] loss: 1.8014994859695435, time: 8.759178161621094\n","[38,    17] loss: 1.4557673931121826, time: 9.311496496200562\n","[38,    18] loss: 1.3815642595291138, time: 9.84725546836853\n","[38,    19] loss: 1.120856523513794, time: 10.383949995040894\n","[38,    20] loss: 1.2781368494033813, time: 10.93247365951538\n","[38,    21] loss: 1.1302318572998047, time: 11.467548847198486\n","[38,    22] loss: 1.4488519430160522, time: 12.008583307266235\n","[38,    23] loss: 1.2470107078552246, time: 12.542433261871338\n","[38,    24] loss: 1.4468475580215454, time: 13.09888768196106\n","[38,    25] loss: 1.2892500162124634, time: 13.650235891342163\n","[38,    26] loss: 1.3622783422470093, time: 14.202736377716064\n","[38,    27] loss: 1.7807667255401611, time: 14.778177261352539\n","[38,    28] loss: 1.4923202991485596, time: 15.336875438690186\n","[38,    29] loss: 1.603804349899292, time: 15.890821933746338\n","[38,    30] loss: 1.6931049823760986, time: 16.449890851974487\n","[38,    31] loss: 1.765119194984436, time: 16.992428064346313\n","[38,    32] loss: 1.3649003505706787, time: 17.53820514678955\n","[38,    33] loss: 1.261009693145752, time: 18.076671600341797\n","[38,    34] loss: 1.1754733324050903, time: 18.615593194961548\n","[38,    35] loss: 1.4909019470214844, time: 19.158814191818237\n","[38,    36] loss: 1.622515082359314, time: 19.695231676101685\n","[38,    37] loss: 1.6030817031860352, time: 20.243237018585205\n","[38,    38] loss: 1.4804565906524658, time: 20.787713766098022\n","[38,    39] loss: 1.3260892629623413, time: 21.329761266708374\n","[38,    40] loss: 1.3646442890167236, time: 21.8899884223938\n","[38,    41] loss: 1.3012208938598633, time: 22.450358629226685\n","[38,    42] loss: 1.3260704278945923, time: 22.977553844451904\n","[38,    43] loss: 1.4171186685562134, time: 23.500524520874023\n","[38,    44] loss: 1.6710011959075928, time: 24.038882970809937\n","[38,    45] loss: 1.2987765073776245, time: 24.589634895324707\n","[38,    46] loss: 1.3636021614074707, time: 25.157058715820312\n","[38,    47] loss: 1.165740966796875, time: 25.71784496307373\n","[38,    48] loss: 1.865490198135376, time: 26.266427040100098\n","[38,    49] loss: 1.4656875133514404, time: 26.82730221748352\n","[38,    50] loss: 1.5320297479629517, time: 27.004605293273926\n","\n","Evaluation: Average loss: 1.1660, Accuracy: 618/947 (65.259%)\n","\n","************************************************************\n","Total removed parameters: 1172424.0\n","Take 33.24172482573544 % of active parameters\n","Total redistribution parameters: 2354441.0\n","Take: 200.81821934726685 % of removed parameters\n","Pruning rate: 0.34361082678945765\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.42 seconds.\n","\n","Total nonzero parameters:  2957712\n","Take 12.537994925983867 %\n","------------------------------------------------------------\n","[39,     1] loss: 1.567154049873352, time: 0.5629348754882812\n","[39,     2] loss: 1.293602705001831, time: 1.1156895160675049\n","[39,     3] loss: 1.7500983476638794, time: 1.6593365669250488\n","[39,     4] loss: 1.2505898475646973, time: 2.217487335205078\n","[39,     5] loss: 1.2080610990524292, time: 2.7522451877593994\n","[39,     6] loss: 1.3205050230026245, time: 3.3045358657836914\n","[39,     7] loss: 1.5276576280593872, time: 3.860339879989624\n","[39,     8] loss: 1.7090519666671753, time: 4.413082838058472\n","[39,     9] loss: 1.1984014511108398, time: 4.956334829330444\n","[39,    10] loss: 1.9158419370651245, time: 5.490206956863403\n","[39,    11] loss: 1.2882235050201416, time: 6.037767171859741\n","[39,    12] loss: 1.3454378843307495, time: 6.595556020736694\n","[39,    13] loss: 1.6780530214309692, time: 7.150605916976929\n","[39,    14] loss: 1.3152414560317993, time: 7.70292067527771\n","[39,    15] loss: 1.6865320205688477, time: 8.257633447647095\n","[39,    16] loss: 1.5653724670410156, time: 8.80571961402893\n","[39,    17] loss: 1.3804948329925537, time: 9.34021782875061\n","[39,    18] loss: 1.2861038446426392, time: 9.899245738983154\n","[39,    19] loss: 1.3247325420379639, time: 10.456921339035034\n","[39,    20] loss: 1.8148142099380493, time: 10.98808240890503\n","[39,    21] loss: 1.361285924911499, time: 11.521468162536621\n","[39,    22] loss: 1.318695306777954, time: 12.066268920898438\n","[39,    23] loss: 1.2750808000564575, time: 12.608715057373047\n","[39,    24] loss: 1.55244779586792, time: 13.16098141670227\n","[39,    25] loss: 1.4484879970550537, time: 13.679630517959595\n","[39,    26] loss: 1.8426991701126099, time: 14.22815990447998\n","[39,    27] loss: 1.4184999465942383, time: 14.774276971817017\n","[39,    28] loss: 1.4068557024002075, time: 15.343073606491089\n","[39,    29] loss: 1.2314746379852295, time: 15.888649940490723\n","[39,    30] loss: 1.2289972305297852, time: 16.42025852203369\n","[39,    31] loss: 1.775191307067871, time: 16.95971703529358\n","[39,    32] loss: 1.2813208103179932, time: 17.496560096740723\n","[39,    33] loss: 1.2607555389404297, time: 18.045374631881714\n","[39,    34] loss: 1.7294080257415771, time: 18.57547640800476\n","[39,    35] loss: 1.318987250328064, time: 19.130390644073486\n","[39,    36] loss: 1.5584783554077148, time: 19.71127414703369\n","[39,    37] loss: 1.713704228401184, time: 20.261444807052612\n","[39,    38] loss: 1.3359172344207764, time: 20.791122674942017\n","[39,    39] loss: 1.2480885982513428, time: 21.34254217147827\n","[39,    40] loss: 1.4039411544799805, time: 21.877705574035645\n","[39,    41] loss: 1.2416894435882568, time: 22.434924364089966\n","[39,    42] loss: 1.1839215755462646, time: 22.951618671417236\n","[39,    43] loss: 1.4512710571289062, time: 23.493375539779663\n","[39,    44] loss: 1.3301335573196411, time: 24.047582864761353\n","[39,    45] loss: 1.5492751598358154, time: 24.5913348197937\n","[39,    46] loss: 1.5540680885314941, time: 25.13895320892334\n","[39,    47] loss: 2.0621817111968994, time: 25.7048978805542\n","[39,    48] loss: 1.2705299854278564, time: 26.24070143699646\n","[39,    49] loss: 1.6360477209091187, time: 26.78079581260681\n","[39,    50] loss: 1.5356740951538086, time: 26.95013976097107\n","\n","Evaluation: Average loss: 1.0848, Accuracy: 640/947 (67.582%)\n","\n","************************************************************\n","Total removed parameters: 1144493.0\n","Take 32.45071756361528 % of active parameters\n","Total redistribution parameters: 2381747.0\n","Take: 208.1049862253417 % of removed parameters\n","Pruning rate: 0.33633763526070937\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.38 seconds.\n","\n","Total nonzero parameters:  2977229\n","Take 12.620729163452026 %\n","------------------------------------------------------------\n","[40,     1] loss: 1.6143137216567993, time: 0.5361158847808838\n","[40,     2] loss: 1.4939194917678833, time: 1.1015548706054688\n","[40,     3] loss: 1.1599410772323608, time: 1.6582365036010742\n","[40,     4] loss: 1.4948430061340332, time: 2.209475040435791\n","[40,     5] loss: 1.5227363109588623, time: 2.739121198654175\n","[40,     6] loss: 1.54985773563385, time: 3.2978479862213135\n","[40,     7] loss: 1.3837677240371704, time: 3.8481757640838623\n","[40,     8] loss: 1.4504823684692383, time: 4.367058515548706\n","[40,     9] loss: 1.6349225044250488, time: 4.89701771736145\n","[40,    10] loss: 1.8339927196502686, time: 5.445082187652588\n","[40,    11] loss: 1.539312720298767, time: 5.986684083938599\n","[40,    12] loss: 1.1895813941955566, time: 6.53518009185791\n","[40,    13] loss: 1.7862871885299683, time: 7.075774431228638\n","[40,    14] loss: 1.264456033706665, time: 7.606461048126221\n","[40,    15] loss: 1.636869192123413, time: 8.154288053512573\n","[40,    16] loss: 1.485090732574463, time: 8.719247579574585\n","[40,    17] loss: 2.182737350463867, time: 9.2903733253479\n","[40,    18] loss: 1.2975982427597046, time: 9.845296621322632\n","[40,    19] loss: 1.3742772340774536, time: 10.409675359725952\n","[40,    20] loss: 1.1047919988632202, time: 10.9684579372406\n","[40,    21] loss: 1.5401021242141724, time: 11.508643865585327\n","[40,    22] loss: 1.6735117435455322, time: 12.068920135498047\n","[40,    23] loss: 2.118561029434204, time: 12.627972602844238\n","[40,    24] loss: 1.0231472253799438, time: 13.174569845199585\n","[40,    25] loss: 1.1878607273101807, time: 13.724385976791382\n","[40,    26] loss: 1.2833950519561768, time: 14.261151552200317\n","[40,    27] loss: 1.256547451019287, time: 14.816066980361938\n","[40,    28] loss: 1.2753962278366089, time: 15.404756784439087\n","[40,    29] loss: 1.4997707605361938, time: 15.916885375976562\n","[40,    30] loss: 1.3670231103897095, time: 16.459474563598633\n","[40,    31] loss: 1.7592380046844482, time: 17.015204429626465\n","[40,    32] loss: 1.7070707082748413, time: 17.558770656585693\n","[40,    33] loss: 1.2413058280944824, time: 18.082430362701416\n","[40,    34] loss: 1.7719544172286987, time: 18.632034063339233\n","[40,    35] loss: 1.2932064533233643, time: 19.17788553237915\n","[40,    36] loss: 1.3317376375198364, time: 19.7185320854187\n","[40,    37] loss: 1.6069778203964233, time: 20.254448652267456\n","[40,    38] loss: 1.5149784088134766, time: 20.79130268096924\n","[40,    39] loss: 1.4668710231781006, time: 21.32655930519104\n","[40,    40] loss: 1.3966188430786133, time: 21.876242876052856\n","[40,    41] loss: 1.1414579153060913, time: 22.417741537094116\n","[40,    42] loss: 1.4947116374969482, time: 22.955646991729736\n","[40,    43] loss: 1.4771232604980469, time: 23.490703582763672\n","[40,    44] loss: 1.4186530113220215, time: 24.037949323654175\n","[40,    45] loss: 1.3042246103286743, time: 24.5878849029541\n","[40,    46] loss: 1.3761504888534546, time: 25.12608051300049\n","[40,    47] loss: 1.2267955541610718, time: 25.69140076637268\n","[40,    48] loss: 1.805118441581726, time: 26.233118295669556\n","[40,    49] loss: 1.723980188369751, time: 26.766468048095703\n","[40,    50] loss: 1.5759284496307373, time: 26.935216903686523\n","\n","Evaluation: Average loss: 1.5380, Accuracy: 562/947 (59.345%)\n","\n","************************************************************\n","Total removed parameters: 1122406.0\n","Take 31.83010799038069 % of active parameters\n","Total redistribution parameters: 2401666.0\n","Take: 213.97480056236336 % of removed parameters\n","Pruning rate: 0.3289817061077994\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.27 seconds.\n","\n","Total nonzero parameters:  2982648\n","Take 12.643700769377114 %\n","------------------------------------------------------------\n","[41,     1] loss: 1.167781949043274, time: 0.5465469360351562\n","[41,     2] loss: 1.201581597328186, time: 1.0878841876983643\n","[41,     3] loss: 1.1692501306533813, time: 1.6270630359649658\n","[41,     4] loss: 1.5138393640518188, time: 2.1591219902038574\n","[41,     5] loss: 1.4936387538909912, time: 2.6840779781341553\n","[41,     6] loss: 1.2940309047698975, time: 3.2282803058624268\n","[41,     7] loss: 1.2500972747802734, time: 3.766613483428955\n","[41,     8] loss: 1.6524579524993896, time: 4.31517767906189\n","[41,     9] loss: 1.399943232536316, time: 4.848586082458496\n","[41,    10] loss: 1.6703684329986572, time: 5.3915441036224365\n","[41,    11] loss: 1.321890115737915, time: 5.942972660064697\n","[41,    12] loss: 1.3687888383865356, time: 6.4790003299713135\n","[41,    13] loss: 1.3873687982559204, time: 7.0105273723602295\n","[41,    14] loss: 1.5392465591430664, time: 7.552963733673096\n","[41,    15] loss: 1.3270037174224854, time: 8.085200786590576\n","[41,    16] loss: 1.313751220703125, time: 8.620534658432007\n","[41,    17] loss: 1.6863317489624023, time: 9.153911590576172\n","[41,    18] loss: 1.268110752105713, time: 9.692325830459595\n","[41,    19] loss: 1.4906623363494873, time: 10.23272705078125\n","[41,    20] loss: 1.5862419605255127, time: 10.793161630630493\n","[41,    21] loss: 1.316591739654541, time: 11.334453344345093\n","[41,    22] loss: 1.5935598611831665, time: 11.885368824005127\n","[41,    23] loss: 1.201196551322937, time: 12.441781997680664\n","[41,    24] loss: 1.6113418340682983, time: 12.97373652458191\n","[41,    25] loss: 1.2082856893539429, time: 13.511885643005371\n","[41,    26] loss: 1.4544084072113037, time: 14.04388952255249\n","[41,    27] loss: 1.5214554071426392, time: 14.584540367126465\n","[41,    28] loss: 1.246036410331726, time: 15.122118711471558\n","[41,    29] loss: 1.4343613386154175, time: 15.653252601623535\n","[41,    30] loss: 1.3697876930236816, time: 16.188141584396362\n","[41,    31] loss: 1.6999696493148804, time: 16.741564989089966\n","[41,    32] loss: 1.4751640558242798, time: 17.295165061950684\n","[41,    33] loss: 1.4471964836120605, time: 17.828940868377686\n","[41,    34] loss: 1.534367322921753, time: 18.353925466537476\n","[41,    35] loss: 1.523480772972107, time: 18.875193119049072\n","[41,    36] loss: 1.2910494804382324, time: 19.396981239318848\n","[41,    37] loss: 1.4543628692626953, time: 19.939960956573486\n","[41,    38] loss: 1.1058443784713745, time: 20.47402262687683\n","[41,    39] loss: 1.4791555404663086, time: 21.030989408493042\n","[41,    40] loss: 1.4904905557632446, time: 21.564461708068848\n","[41,    41] loss: 1.3509846925735474, time: 22.13795566558838\n","[41,    42] loss: 1.1469398736953735, time: 22.677369832992554\n","[41,    43] loss: 1.4320086240768433, time: 23.238104343414307\n","[41,    44] loss: 1.5321710109710693, time: 23.80100965499878\n","[41,    45] loss: 1.4857172966003418, time: 24.328380823135376\n","[41,    46] loss: 1.5690406560897827, time: 24.85954976081848\n","[41,    47] loss: 1.4257911443710327, time: 25.390968084335327\n","[41,    48] loss: 1.5325806140899658, time: 25.939920663833618\n","[41,    49] loss: 1.2936407327651978, time: 26.470218181610107\n","[41,    50] loss: 1.5623281002044678, time: 26.64403748512268\n","\n","Evaluation: Average loss: 1.6627, Accuracy: 528/947 (55.755%)\n","\n","************************************************************\n","Total removed parameters: 1077885.0\n","Take 30.58635010862434 % of active parameters\n","Total redistribution parameters: 2444983.0\n","Take: 226.831526554317 % of removed parameters\n","Pruning rate: 0.32155029874470925\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.06 seconds.\n","\n","Total nonzero parameters:  2988829\n","Take 12.669902558678272 %\n","------------------------------------------------------------\n","[42,     1] loss: 1.4023054838180542, time: 0.5513505935668945\n","[42,     2] loss: 1.4810993671417236, time: 1.0895962715148926\n","[42,     3] loss: 1.6201530694961548, time: 1.6338837146759033\n","[42,     4] loss: 1.4099210500717163, time: 2.190641164779663\n","[42,     5] loss: 1.5271810293197632, time: 2.744903564453125\n","[42,     6] loss: 1.337622046470642, time: 3.2837696075439453\n","[42,     7] loss: 1.6016122102737427, time: 3.8198931217193604\n","[42,     8] loss: 1.3068761825561523, time: 4.360279321670532\n","[42,     9] loss: 1.57630455493927, time: 4.91415810585022\n","[42,    10] loss: 1.1199522018432617, time: 5.4363343715667725\n","[42,    11] loss: 1.4589449167251587, time: 5.979260683059692\n","[42,    12] loss: 1.5582976341247559, time: 6.51736855506897\n","[42,    13] loss: 1.3203558921813965, time: 7.062408447265625\n","[42,    14] loss: 1.1038085222244263, time: 7.599987030029297\n","[42,    15] loss: 1.4773290157318115, time: 8.144184589385986\n","[42,    16] loss: 1.4762678146362305, time: 8.68854308128357\n","[42,    17] loss: 1.2441320419311523, time: 9.22626781463623\n","[42,    18] loss: 1.345550298690796, time: 9.785977840423584\n","[42,    19] loss: 1.2272579669952393, time: 10.346093893051147\n","[42,    20] loss: 1.3969078063964844, time: 10.890344381332397\n","[42,    21] loss: 1.4570449590682983, time: 11.436707735061646\n","[42,    22] loss: 1.2722009420394897, time: 11.972917079925537\n","[42,    23] loss: 1.2435475587844849, time: 12.519281148910522\n","[42,    24] loss: 1.5883921384811401, time: 13.077365159988403\n","[42,    25] loss: 1.2861237525939941, time: 13.627059936523438\n","[42,    26] loss: 1.441412329673767, time: 14.17575192451477\n","[42,    27] loss: 1.412964940071106, time: 14.71382999420166\n","[42,    28] loss: 1.2292817831039429, time: 15.252068519592285\n","[42,    29] loss: 1.7352592945098877, time: 15.805015325546265\n","[42,    30] loss: 1.3147670030593872, time: 16.349215745925903\n","[42,    31] loss: 1.3919072151184082, time: 16.898013591766357\n","[42,    32] loss: 1.384972333908081, time: 17.44996666908264\n","[42,    33] loss: 1.7385830879211426, time: 18.013060569763184\n","[42,    34] loss: 1.0929845571517944, time: 18.59010934829712\n","[42,    35] loss: 1.5065526962280273, time: 19.156355142593384\n","[42,    36] loss: 1.1757197380065918, time: 19.73077940940857\n","[42,    37] loss: 1.595677375793457, time: 20.303227424621582\n","[42,    38] loss: 1.6019506454467773, time: 20.860913276672363\n","[42,    39] loss: 1.342862606048584, time: 21.413355350494385\n","[42,    40] loss: 1.130460500717163, time: 21.973612070083618\n","[42,    41] loss: 1.4889732599258423, time: 22.513289213180542\n","[42,    42] loss: 1.6354917287826538, time: 23.060481548309326\n","[42,    43] loss: 1.15690279006958, time: 23.587260484695435\n","[42,    44] loss: 1.9595247507095337, time: 24.15773582458496\n","[42,    45] loss: 1.445512294769287, time: 24.716033935546875\n","[42,    46] loss: 1.4388818740844727, time: 25.275504112243652\n","[42,    47] loss: 1.2180371284484863, time: 25.834760189056396\n","[42,    48] loss: 1.5765423774719238, time: 26.374995231628418\n","[42,    49] loss: 1.4427517652511597, time: 26.925256729125977\n","[42,    50] loss: 1.2694485187530518, time: 27.09966015815735\n","\n","Evaluation: Average loss: 1.0805, Accuracy: 637/947 (67.265%)\n","\n","************************************************************\n","Total removed parameters: 1067739.0\n","Take 30.308799534924386 % of active parameters\n","Total redistribution parameters: 2456527.0\n","Take: 230.06811589723705 % of removed parameters\n","Pruning rate: 0.31405074707330144\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.41 seconds.\n","\n","Total nonzero parameters:  3002174\n","Take 12.726473158617434 %\n","------------------------------------------------------------\n","[43,     1] loss: 1.3434442281723022, time: 0.5524153709411621\n","[43,     2] loss: 2.012917995452881, time: 1.1148648262023926\n","[43,     3] loss: 1.3582719564437866, time: 1.6615231037139893\n","[43,     4] loss: 1.3653820753097534, time: 2.20538592338562\n","[43,     5] loss: 1.3545622825622559, time: 2.7314624786376953\n","[43,     6] loss: 1.6145222187042236, time: 3.254779577255249\n","[43,     7] loss: 1.2405911684036255, time: 3.806088924407959\n","[43,     8] loss: 1.5086532831192017, time: 4.35164999961853\n","[43,     9] loss: 1.6117703914642334, time: 4.910975456237793\n","[43,    10] loss: 1.3598647117614746, time: 5.44258713722229\n","[43,    11] loss: 1.6793859004974365, time: 5.971730947494507\n","[43,    12] loss: 1.6887816190719604, time: 6.514634370803833\n","[43,    13] loss: 1.4647226333618164, time: 7.063107013702393\n","[43,    14] loss: 1.3337692022323608, time: 7.620678424835205\n","[43,    15] loss: 1.267698884010315, time: 8.16534686088562\n","[43,    16] loss: 1.4704668521881104, time: 8.709563255310059\n","[43,    17] loss: 1.7526355981826782, time: 9.264060497283936\n","[43,    18] loss: 1.237209439277649, time: 9.826431512832642\n","[43,    19] loss: 1.6487884521484375, time: 10.375364780426025\n","[43,    20] loss: 1.4455757141113281, time: 10.917502164840698\n","[43,    21] loss: 1.2655524015426636, time: 11.460421085357666\n","[43,    22] loss: 1.3631725311279297, time: 11.99837064743042\n","[43,    23] loss: 1.1760921478271484, time: 12.54383897781372\n","[43,    24] loss: 1.092088222503662, time: 13.085723400115967\n","[43,    25] loss: 1.5592032670974731, time: 13.628350973129272\n","[43,    26] loss: 1.3491023778915405, time: 14.163741111755371\n","[43,    27] loss: 1.3762110471725464, time: 14.685698986053467\n","[43,    28] loss: 1.4737766981124878, time: 15.25482439994812\n","[43,    29] loss: 1.684233546257019, time: 15.806763887405396\n","[43,    30] loss: 1.0859856605529785, time: 16.35696268081665\n","[43,    31] loss: 1.3177977800369263, time: 16.913137197494507\n","[43,    32] loss: 1.5940877199172974, time: 17.449449062347412\n","[43,    33] loss: 1.2824643850326538, time: 17.99697732925415\n","[43,    34] loss: 1.3918498754501343, time: 18.544477462768555\n","[43,    35] loss: 1.3427283763885498, time: 19.094688653945923\n","[43,    36] loss: 1.2839953899383545, time: 19.6329026222229\n","[43,    37] loss: 1.2531553506851196, time: 20.16541314125061\n","[43,    38] loss: 1.3248827457427979, time: 20.697993755340576\n","[43,    39] loss: 1.4566736221313477, time: 21.254312753677368\n","[43,    40] loss: 1.3115766048431396, time: 21.783350944519043\n","[43,    41] loss: 1.5565965175628662, time: 22.323601007461548\n","[43,    42] loss: 1.423621416091919, time: 22.876628398895264\n","[43,    43] loss: 1.5934768915176392, time: 23.424107551574707\n","[43,    44] loss: 1.4650405645370483, time: 23.958088874816895\n","[43,    45] loss: 1.4167789220809937, time: 24.485599994659424\n","[43,    46] loss: 1.0908840894699097, time: 24.993016242980957\n","[43,    47] loss: 1.377403736114502, time: 25.5383083820343\n","[43,    48] loss: 1.2798939943313599, time: 26.088701009750366\n","[43,    49] loss: 0.9395608901977539, time: 26.620580434799194\n","[43,    50] loss: 1.2302573919296265, time: 26.802350521087646\n","\n","Evaluation: Average loss: 1.1992, Accuracy: 614/947 (64.836%)\n","\n","************************************************************\n","Total removed parameters: 1045296.0\n","Take 29.659963237735177 % of active parameters\n","Total redistribution parameters: 2481825.0\n","Take: 237.42796298847406 % of removed parameters\n","Pruning rate: 0.30649045224564425\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.11 seconds.\n","\n","Total nonzero parameters:  3021122\n","Take 12.80679535626803 %\n","------------------------------------------------------------\n","[44,     1] loss: 1.5247037410736084, time: 0.5403115749359131\n","[44,     2] loss: 1.2284008264541626, time: 1.0727043151855469\n","[44,     3] loss: 1.1508395671844482, time: 1.6166086196899414\n","[44,     4] loss: 1.6477258205413818, time: 2.1729342937469482\n","[44,     5] loss: 1.4173307418823242, time: 2.724682331085205\n","[44,     6] loss: 1.536996603012085, time: 3.2544078826904297\n","[44,     7] loss: 1.288630485534668, time: 3.79209041595459\n","[44,     8] loss: 1.3024592399597168, time: 4.322070837020874\n","[44,     9] loss: 1.5913121700286865, time: 4.868484735488892\n","[44,    10] loss: 1.2887187004089355, time: 5.438400030136108\n","[44,    11] loss: 1.273950219154358, time: 5.994495868682861\n","[44,    12] loss: 1.3128776550292969, time: 6.53628396987915\n","[44,    13] loss: 1.3849351406097412, time: 7.080378293991089\n","[44,    14] loss: 1.4343293905258179, time: 7.626742124557495\n","[44,    15] loss: 1.22174870967865, time: 8.18393850326538\n","[44,    16] loss: 1.3560545444488525, time: 8.714077472686768\n","[44,    17] loss: 1.3315268754959106, time: 9.271832466125488\n","[44,    18] loss: 1.7314634323120117, time: 9.789189577102661\n","[44,    19] loss: 1.3247159719467163, time: 10.33118200302124\n","[44,    20] loss: 1.3628274202346802, time: 10.879132270812988\n","[44,    21] loss: 1.3148428201675415, time: 11.429301023483276\n","[44,    22] loss: 1.4103572368621826, time: 11.972614765167236\n","[44,    23] loss: 1.0731343030929565, time: 12.515568494796753\n","[44,    24] loss: 1.5333904027938843, time: 13.066990852355957\n","[44,    25] loss: 1.4797143936157227, time: 13.59481430053711\n","[44,    26] loss: 1.4973398447036743, time: 14.128729820251465\n","[44,    27] loss: 1.6020582914352417, time: 14.655521869659424\n","[44,    28] loss: 1.3230793476104736, time: 15.190667867660522\n","[44,    29] loss: 1.2807486057281494, time: 15.734925746917725\n","[44,    30] loss: 1.2643036842346191, time: 16.309900760650635\n","[44,    31] loss: 1.5264077186584473, time: 16.868391275405884\n","[44,    32] loss: 1.3946222066879272, time: 17.420866012573242\n","[44,    33] loss: 1.29460608959198, time: 17.9707510471344\n","[44,    34] loss: 1.204511046409607, time: 18.502136707305908\n","[44,    35] loss: 1.6771645545959473, time: 19.0460467338562\n","[44,    36] loss: 1.2481261491775513, time: 19.570642232894897\n","[44,    37] loss: 1.5889173746109009, time: 20.09693193435669\n","[44,    38] loss: 1.3963226079940796, time: 20.63352060317993\n","[44,    39] loss: 1.3726328611373901, time: 21.173436164855957\n","[44,    40] loss: 1.3616186380386353, time: 21.717347383499146\n","[44,    41] loss: 1.3067108392715454, time: 22.251925468444824\n","[44,    42] loss: 1.6826660633087158, time: 22.809231758117676\n","[44,    43] loss: 1.4000216722488403, time: 23.348257780075073\n","[44,    44] loss: 1.3344268798828125, time: 23.871107578277588\n","[44,    45] loss: 1.6069979667663574, time: 24.43507719039917\n","[44,    46] loss: 1.3457483053207397, time: 25.011274576187134\n","[44,    47] loss: 1.1724603176116943, time: 25.58390736579895\n","[44,    48] loss: 1.4193024635314941, time: 26.128086805343628\n","[44,    49] loss: 1.4295240640640259, time: 26.6641845703125\n","[44,    50] loss: 2.114326000213623, time: 26.83142924308777\n","\n","Evaluation: Average loss: 1.0423, Accuracy: 644/947 (68.004%)\n","\n","************************************************************\n","Total removed parameters: 1020258.0\n","Take 28.926084475128583 % of active parameters\n","Total redistribution parameters: 2506999.0\n","Take: 245.72206245871143 % of removed parameters\n","Pruning rate: 0.29887687535996693\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.28 seconds.\n","\n","Total nonzero parameters:  3028486\n","Take 12.838011984065107 %\n","------------------------------------------------------------\n","[45,     1] loss: 1.2623186111450195, time: 0.5444440841674805\n","[45,     2] loss: 1.360322117805481, time: 1.1044995784759521\n","[45,     3] loss: 1.2366087436676025, time: 1.6172845363616943\n","[45,     4] loss: 1.1547755002975464, time: 2.1655397415161133\n","[45,     5] loss: 1.2842788696289062, time: 2.722560167312622\n","[45,     6] loss: 1.2124583721160889, time: 3.255800485610962\n","[45,     7] loss: 1.2568786144256592, time: 3.8162379264831543\n","[45,     8] loss: 1.223435401916504, time: 4.39453125\n","[45,     9] loss: 1.384649634361267, time: 4.934735536575317\n","[45,    10] loss: 1.5057734251022339, time: 5.4841413497924805\n","[45,    11] loss: 1.403476595878601, time: 6.014860153198242\n","[45,    12] loss: 1.7054084539413452, time: 6.547001123428345\n","[45,    13] loss: 1.5470433235168457, time: 7.118158340454102\n","[45,    14] loss: 1.2778359651565552, time: 7.6716835498809814\n","[45,    15] loss: 1.601686954498291, time: 8.203804731369019\n","[45,    16] loss: 1.3068674802780151, time: 8.750016450881958\n","[45,    17] loss: 1.2657248973846436, time: 9.326808214187622\n","[45,    18] loss: 1.1037378311157227, time: 9.890435457229614\n","[45,    19] loss: 1.487744927406311, time: 10.455188512802124\n","[45,    20] loss: 1.3665868043899536, time: 10.98905348777771\n","[45,    21] loss: 1.4888367652893066, time: 11.547404050827026\n","[45,    22] loss: 1.1544885635375977, time: 12.093496799468994\n","[45,    23] loss: 1.3857016563415527, time: 12.648480653762817\n","[45,    24] loss: 1.322542667388916, time: 13.178518533706665\n","[45,    25] loss: 1.4364488124847412, time: 13.721084594726562\n","[45,    26] loss: 1.387231469154358, time: 14.260467052459717\n","[45,    27] loss: 0.9861759543418884, time: 14.800965309143066\n","[45,    28] loss: 1.3425407409667969, time: 15.350184679031372\n","[45,    29] loss: 1.1897650957107544, time: 15.888427972793579\n","[45,    30] loss: 1.1887152194976807, time: 16.43225908279419\n","[45,    31] loss: 1.2271728515625, time: 16.98729109764099\n","[45,    32] loss: 1.432222604751587, time: 17.537940979003906\n","[45,    33] loss: 1.4227339029312134, time: 18.08835005760193\n","[45,    34] loss: 1.6620267629623413, time: 18.633558750152588\n","[45,    35] loss: 1.2631142139434814, time: 19.171876192092896\n","[45,    36] loss: 1.4053473472595215, time: 19.710636377334595\n","[45,    37] loss: 1.4781770706176758, time: 20.24480676651001\n","[45,    38] loss: 1.3754922151565552, time: 20.773536443710327\n","[45,    39] loss: 1.3453469276428223, time: 21.285022258758545\n","[45,    40] loss: 1.254503846168518, time: 21.819129467010498\n","[45,    41] loss: 1.5878738164901733, time: 22.35430121421814\n","[45,    42] loss: 1.5794212818145752, time: 22.91008973121643\n","[45,    43] loss: 1.2274882793426514, time: 23.462602376937866\n","[45,    44] loss: 1.5770246982574463, time: 24.00794816017151\n","[45,    45] loss: 1.1697198152542114, time: 24.545978784561157\n","[45,    46] loss: 1.0019333362579346, time: 25.099953651428223\n","[45,    47] loss: 1.291516900062561, time: 25.635122776031494\n","[45,    48] loss: 1.3980302810668945, time: 26.184447288513184\n","[45,    49] loss: 1.408345341682434, time: 26.7197904586792\n","[45,    50] loss: 1.484916090965271, time: 26.899303197860718\n","\n","Evaluation: Average loss: 1.4719, Accuracy: 561/947 (59.240%)\n","\n","************************************************************\n","Total removed parameters: 994239.0\n","Take 28.187313824878654 % of active parameters\n","Total redistribution parameters: 2531399.0\n","Take: 254.60668913611315 % of removed parameters\n","Pruning rate: 0.29121753009745704\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.33 seconds.\n","\n","Total nonzero parameters:  3040594\n","Take 12.8893388348754 %\n","------------------------------------------------------------\n","[46,     1] loss: 1.3764231204986572, time: 0.52840256690979\n","[46,     2] loss: 1.6431469917297363, time: 1.0795345306396484\n","[46,     3] loss: 1.1698644161224365, time: 1.6287543773651123\n","[46,     4] loss: 1.6167715787887573, time: 2.1615004539489746\n","[46,     5] loss: 1.5058523416519165, time: 2.6897823810577393\n","[46,     6] loss: 1.4084086418151855, time: 3.2307968139648438\n","[46,     7] loss: 1.191847324371338, time: 3.774216890335083\n","[46,     8] loss: 1.2435998916625977, time: 4.337842702865601\n","[46,     9] loss: 1.1845661401748657, time: 4.910823822021484\n","[46,    10] loss: 1.1170741319656372, time: 5.455595970153809\n","[46,    11] loss: 1.3513203859329224, time: 6.010513782501221\n","[46,    12] loss: 1.6429927349090576, time: 6.538591384887695\n","[46,    13] loss: 1.3492610454559326, time: 7.094845533370972\n","[46,    14] loss: 1.2213014364242554, time: 7.637031316757202\n","[46,    15] loss: 1.4161250591278076, time: 8.196200132369995\n","[46,    16] loss: 1.0717151165008545, time: 8.748229265213013\n","[46,    17] loss: 1.1607050895690918, time: 9.287194967269897\n","[46,    18] loss: 1.418421745300293, time: 9.84960126876831\n","[46,    19] loss: 1.4832128286361694, time: 10.413082122802734\n","[46,    20] loss: 1.642039179801941, time: 10.959980964660645\n","[46,    21] loss: 1.6706162691116333, time: 11.514773607254028\n","[46,    22] loss: 0.7341747879981995, time: 12.061388731002808\n","[46,    23] loss: 1.348662257194519, time: 12.624898672103882\n","[46,    24] loss: 1.2926512956619263, time: 13.180012226104736\n","[46,    25] loss: 1.250331163406372, time: 13.71583890914917\n","[46,    26] loss: 1.2138766050338745, time: 14.255911111831665\n","[46,    27] loss: 1.3195074796676636, time: 14.808093786239624\n","[46,    28] loss: 1.1979939937591553, time: 15.361210107803345\n","[46,    29] loss: 1.2851028442382812, time: 15.890185117721558\n","[46,    30] loss: 1.2662590742111206, time: 16.43778920173645\n","[46,    31] loss: 1.6797114610671997, time: 16.992844581604004\n","[46,    32] loss: 1.5109316110610962, time: 17.53184199333191\n","[46,    33] loss: 1.0521303415298462, time: 18.086336612701416\n","[46,    34] loss: 1.2416456937789917, time: 18.634084701538086\n","[46,    35] loss: 1.2908049821853638, time: 19.163885831832886\n","[46,    36] loss: 1.532959222793579, time: 19.70267343521118\n","[46,    37] loss: 1.4250541925430298, time: 20.267613172531128\n","[46,    38] loss: 1.5602684020996094, time: 20.816678762435913\n","[46,    39] loss: 1.284533977508545, time: 21.34888005256653\n","[46,    40] loss: 1.3674393892288208, time: 21.910946369171143\n","[46,    41] loss: 1.598946213722229, time: 22.482434034347534\n","[46,    42] loss: 1.2059483528137207, time: 23.027328729629517\n","[46,    43] loss: 1.5079984664916992, time: 23.562782287597656\n","[46,    44] loss: 1.2377599477767944, time: 24.099080085754395\n","[46,    45] loss: 1.2856264114379883, time: 24.646568298339844\n","[46,    46] loss: 1.0886226892471313, time: 25.166264057159424\n","[46,    47] loss: 1.2110272645950317, time: 25.70047640800476\n","[46,    48] loss: 1.6133102178573608, time: 26.245869636535645\n","[46,    49] loss: 1.4051045179367065, time: 26.783069849014282\n","[46,    50] loss: 1.0810092687606812, time: 26.959757089614868\n","\n","Evaluation: Average loss: 1.2617, Accuracy: 608/947 (64.203%)\n","\n","************************************************************\n","Total removed parameters: 967588.0\n","Take 27.44433773404984 % of active parameters\n","Total redistribution parameters: 2558301.0\n","Take: 264.3998271991798 % of removed parameters\n","Pruning rate: 0.2835199753071652\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.33 seconds.\n","\n","Total nonzero parameters:  3055486\n","Take 12.952467300539992 %\n","------------------------------------------------------------\n","[47,     1] loss: 1.184963583946228, time: 0.5690407752990723\n","[47,     2] loss: 1.4285540580749512, time: 1.1301376819610596\n","[47,     3] loss: 1.5463776588439941, time: 1.6818788051605225\n","[47,     4] loss: 1.2078006267547607, time: 2.247408151626587\n","[47,     5] loss: 1.1732996702194214, time: 2.7904157638549805\n","[47,     6] loss: 1.281761646270752, time: 3.337567090988159\n","[47,     7] loss: 1.4227344989776611, time: 3.8970282077789307\n","[47,     8] loss: 1.3467525243759155, time: 4.399770736694336\n","[47,     9] loss: 1.3750759363174438, time: 4.948818206787109\n","[47,    10] loss: 1.5639450550079346, time: 5.4982590675354\n","[47,    11] loss: 1.2643041610717773, time: 6.03971004486084\n","[47,    12] loss: 1.4475691318511963, time: 6.578181266784668\n","[47,    13] loss: 0.9690837264060974, time: 7.106987237930298\n","[47,    14] loss: 1.354610800743103, time: 7.665423631668091\n","[47,    15] loss: 1.3021632432937622, time: 8.225013256072998\n","[47,    16] loss: 1.4077903032302856, time: 8.773459196090698\n","[47,    17] loss: 1.2200205326080322, time: 9.312173843383789\n","[47,    18] loss: 1.4609090089797974, time: 9.85636854171753\n","[47,    19] loss: 1.4344840049743652, time: 10.395799160003662\n","[47,    20] loss: 1.4592084884643555, time: 10.948429584503174\n","[47,    21] loss: 1.4531515836715698, time: 11.505860567092896\n","[47,    22] loss: 1.6811494827270508, time: 12.045679807662964\n","[47,    23] loss: 1.1648437976837158, time: 12.579989433288574\n","[47,    24] loss: 1.2730185985565186, time: 13.154444456100464\n","[47,    25] loss: 1.4719524383544922, time: 13.690744876861572\n","[47,    26] loss: 1.00729501247406, time: 14.222938060760498\n","[47,    27] loss: 1.348564863204956, time: 14.749949932098389\n","[47,    28] loss: 1.4290122985839844, time: 15.286952018737793\n","[47,    29] loss: 1.4960386753082275, time: 15.811300277709961\n","[47,    30] loss: 1.766286849975586, time: 16.35442352294922\n","[47,    31] loss: 1.0012516975402832, time: 16.87450933456421\n","[47,    32] loss: 1.319185495376587, time: 17.424699068069458\n","[47,    33] loss: 1.2163573503494263, time: 17.943772315979004\n","[47,    34] loss: 1.2241218090057373, time: 18.475318670272827\n","[47,    35] loss: 1.2284976243972778, time: 19.008285522460938\n","[47,    36] loss: 1.284264326095581, time: 19.537940502166748\n","[47,    37] loss: 1.1238700151443481, time: 20.073925733566284\n","[47,    38] loss: 1.2785942554473877, time: 20.61295485496521\n","[47,    39] loss: 1.4050720930099487, time: 21.171573162078857\n","[47,    40] loss: 1.1364496946334839, time: 21.71801447868347\n","[47,    41] loss: 1.1197303533554077, time: 22.243369340896606\n","[47,    42] loss: 1.130344271659851, time: 22.795243501663208\n","[47,    43] loss: 1.0528650283813477, time: 23.34885287284851\n","[47,    44] loss: 1.4575083255767822, time: 23.90575671195984\n","[47,    45] loss: 1.4980356693267822, time: 24.455440044403076\n","[47,    46] loss: 0.9285421371459961, time: 24.999042510986328\n","[47,    47] loss: 1.5366506576538086, time: 25.54415202140808\n","[47,    48] loss: 1.1504677534103394, time: 26.08019518852234\n","[47,    49] loss: 1.2715646028518677, time: 26.618983030319214\n","[47,    50] loss: 1.9297176599502563, time: 26.78769540786743\n","\n","Evaluation: Average loss: 1.0318, Accuracy: 651/947 (68.743%)\n","\n","************************************************************\n","Total removed parameters: 941377.0\n","Take 26.698997047269497 % of active parameters\n","Total redistribution parameters: 2585329.0\n","Take: 274.6326923219921 % of removed parameters\n","Pruning rate: 0.27579180754633215\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.19 seconds.\n","\n","Total nonzero parameters:  3060818\n","Take 12.975070106000883 %\n","------------------------------------------------------------\n","[48,     1] loss: 1.1084328889846802, time: 0.5720343589782715\n","[48,     2] loss: 1.2377259731292725, time: 1.1180784702301025\n","[48,     3] loss: 1.3415411710739136, time: 1.6392064094543457\n","[48,     4] loss: 1.4840553998947144, time: 2.17942476272583\n","[48,     5] loss: 1.4408022165298462, time: 2.698183298110962\n","[48,     6] loss: 1.464296817779541, time: 3.240553379058838\n","[48,     7] loss: 1.400424599647522, time: 3.8003110885620117\n","[48,     8] loss: 1.333802580833435, time: 4.338480234146118\n","[48,     9] loss: 1.5335257053375244, time: 4.881825685501099\n","[48,    10] loss: 1.3648099899291992, time: 5.418157339096069\n","[48,    11] loss: 1.3041865825653076, time: 5.9659857749938965\n","[48,    12] loss: 1.3678735494613647, time: 6.511884689331055\n","[48,    13] loss: 1.0638527870178223, time: 7.078569412231445\n","[48,    14] loss: 1.3314456939697266, time: 7.643529415130615\n","[48,    15] loss: 1.3164584636688232, time: 8.191906690597534\n","[48,    16] loss: 1.337925672531128, time: 8.729619979858398\n","[48,    17] loss: 1.1945940256118774, time: 9.261600255966187\n","[48,    18] loss: 1.414094090461731, time: 9.802573204040527\n","[48,    19] loss: 1.0098484754562378, time: 10.357711791992188\n","[48,    20] loss: 1.3749723434448242, time: 10.882780075073242\n","[48,    21] loss: 1.632854700088501, time: 11.422619342803955\n","[48,    22] loss: 1.5266307592391968, time: 11.949223756790161\n","[48,    23] loss: 1.0802314281463623, time: 12.463484764099121\n","[48,    24] loss: 1.3546744585037231, time: 12.979914665222168\n","[48,    25] loss: 1.1715222597122192, time: 13.513615846633911\n","[48,    26] loss: 1.1807081699371338, time: 14.049832820892334\n","[48,    27] loss: 1.430492639541626, time: 14.59203028678894\n","[48,    28] loss: 1.3978315591812134, time: 15.137429475784302\n","[48,    29] loss: 1.3804460763931274, time: 15.68213415145874\n","[48,    30] loss: 1.2931195497512817, time: 16.235703945159912\n","[48,    31] loss: 1.175451397895813, time: 16.800362586975098\n","[48,    32] loss: 1.0745368003845215, time: 17.362293243408203\n","[48,    33] loss: 1.274914264678955, time: 17.90726590156555\n","[48,    34] loss: 1.1833628416061401, time: 18.461297035217285\n","[48,    35] loss: 1.3033844232559204, time: 18.989813089370728\n","[48,    36] loss: 1.6256417036056519, time: 19.529701948165894\n","[48,    37] loss: 1.4353877305984497, time: 20.063682317733765\n","[48,    38] loss: 1.383183240890503, time: 20.593559980392456\n","[48,    39] loss: 1.5124144554138184, time: 21.12806725502014\n","[48,    40] loss: 1.299378514289856, time: 21.681522607803345\n","[48,    41] loss: 1.2818849086761475, time: 22.221834421157837\n","[48,    42] loss: 1.146248698234558, time: 22.7606680393219\n","[48,    43] loss: 0.7602118849754333, time: 23.29469919204712\n","[48,    44] loss: 1.3606226444244385, time: 23.87500810623169\n","[48,    45] loss: 1.1763689517974854, time: 24.440759897232056\n","[48,    46] loss: 1.1922004222869873, time: 24.976431369781494\n","[48,    47] loss: 1.1847478151321411, time: 25.519674062728882\n","[48,    48] loss: 0.9445234537124634, time: 26.052515983581543\n","[48,    49] loss: 1.4256457090377808, time: 26.573217391967773\n","[48,    50] loss: 1.8491557836532593, time: 26.739495515823364\n","\n","Evaluation: Average loss: 1.1715, Accuracy: 633/947 (66.843%)\n","\n","************************************************************\n","Total removed parameters: 917568.0\n","Take 26.017706040707676 % of active parameters\n","Total redistribution parameters: 2607672.0\n","Take: 284.1938690102532 % of removed parameters\n","Pruning rate: 0.268040653583505\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.12 seconds.\n","\n","Total nonzero parameters:  3072191\n","Take 13.023281228751582 %\n","------------------------------------------------------------\n","[49,     1] loss: 1.774422526359558, time: 0.563570499420166\n","[49,     2] loss: 1.4535472393035889, time: 1.1469659805297852\n","[49,     3] loss: 1.4223613739013672, time: 1.749049186706543\n","[49,     4] loss: 1.2030524015426636, time: 2.356283664703369\n","[49,     5] loss: 1.3715847730636597, time: 2.946277618408203\n","[49,     6] loss: 1.4720312356948853, time: 3.5246970653533936\n","[49,     7] loss: 1.5980654954910278, time: 4.110966920852661\n","[49,     8] loss: 1.2097938060760498, time: 4.66475248336792\n","[49,     9] loss: 1.0083560943603516, time: 5.234455585479736\n","[49,    10] loss: 1.1602460145950317, time: 5.781229496002197\n","[49,    11] loss: 1.2658313512802124, time: 6.328901052474976\n","[49,    12] loss: 1.549788475036621, time: 6.859081506729126\n","[49,    13] loss: 1.0413076877593994, time: 7.4013636112213135\n","[49,    14] loss: 1.068199634552002, time: 7.953946352005005\n","[49,    15] loss: 1.3933264017105103, time: 8.495765209197998\n","[49,    16] loss: 1.3743497133255005, time: 9.027863025665283\n","[49,    17] loss: 1.3353508710861206, time: 9.56405520439148\n","[49,    18] loss: 1.2381291389465332, time: 10.094414234161377\n","[49,    19] loss: 1.24466073513031, time: 10.628245830535889\n","[49,    20] loss: 1.4371298551559448, time: 11.153071880340576\n","[49,    21] loss: 1.700628399848938, time: 11.70717477798462\n","[49,    22] loss: 1.2662521600723267, time: 12.23684811592102\n","[49,    23] loss: 1.3825244903564453, time: 12.7796790599823\n","[49,    24] loss: 1.0416702032089233, time: 13.309828758239746\n","[49,    25] loss: 1.4129393100738525, time: 13.851294994354248\n","[49,    26] loss: 1.3514068126678467, time: 14.382808208465576\n","[49,    27] loss: 1.0131900310516357, time: 14.917361497879028\n","[49,    28] loss: 0.9115645885467529, time: 15.475784063339233\n","[49,    29] loss: 1.2199457883834839, time: 16.00885796546936\n","[49,    30] loss: 1.553857684135437, time: 16.574774742126465\n","[49,    31] loss: 1.795607328414917, time: 17.134825229644775\n","[49,    32] loss: 1.0932035446166992, time: 17.69924020767212\n","[49,    33] loss: 1.3995507955551147, time: 18.24763035774231\n","[49,    34] loss: 1.3619590997695923, time: 18.810253143310547\n","[49,    35] loss: 1.043474555015564, time: 19.361448049545288\n","[49,    36] loss: 1.4181840419769287, time: 19.89118456840515\n","[49,    37] loss: 1.1382945775985718, time: 20.433316946029663\n","[49,    38] loss: 0.9470880031585693, time: 20.979083776474\n","[49,    39] loss: 1.319517970085144, time: 21.5441472530365\n","[49,    40] loss: 1.088808536529541, time: 22.0672926902771\n","[49,    41] loss: 1.1904239654541016, time: 22.597546577453613\n","[49,    42] loss: 1.2843091487884521, time: 23.14135456085205\n","[49,    43] loss: 1.4177348613739014, time: 23.684346199035645\n","[49,    44] loss: 1.0279152393341064, time: 24.217442750930786\n","[49,    45] loss: 1.198216438293457, time: 24.757072925567627\n","[49,    46] loss: 1.0849519968032837, time: 25.292096853256226\n","[49,    47] loss: 1.55865478515625, time: 25.840964317321777\n","[49,    48] loss: 1.1264594793319702, time: 26.38546919822693\n","[49,    49] loss: 1.2597558498382568, time: 26.93540668487549\n","[49,    50] loss: 1.0814051628112793, time: 27.11348032951355\n","\n","Evaluation: Average loss: 0.9489, Accuracy: 657/947 (69.377%)\n","\n","************************************************************\n","Total removed parameters: 888411.0\n","Take 25.20143309391701 % of active parameters\n","Total redistribution parameters: 2637655.0\n","Take: 296.8958061077587 % of removed parameters\n","Pruning rate: 0.2602741628718366\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 33.06 seconds.\n","\n","Total nonzero parameters:  3089025\n","Take 13.094641999030776 %\n","------------------------------------------------------------\n","[50,     1] loss: 1.0041249990463257, time: 0.533010721206665\n","[50,     2] loss: 0.9563754796981812, time: 1.071481466293335\n","[50,     3] loss: 1.5180927515029907, time: 1.6213335990905762\n","[50,     4] loss: 1.4963276386260986, time: 2.1771695613861084\n","[50,     5] loss: 1.1994688510894775, time: 2.723728895187378\n","[50,     6] loss: 1.3209820985794067, time: 3.2715792655944824\n","[50,     7] loss: 1.3847206830978394, time: 3.8117074966430664\n","[50,     8] loss: 1.0598777532577515, time: 4.340978145599365\n","[50,     9] loss: 1.0339335203170776, time: 4.907199859619141\n","[50,    10] loss: 1.0513479709625244, time: 5.459536790847778\n","[50,    11] loss: 1.2589077949523926, time: 5.994019269943237\n","[50,    12] loss: 1.1647100448608398, time: 6.510129690170288\n","[50,    13] loss: 1.2793760299682617, time: 7.053497791290283\n","[50,    14] loss: 1.2221603393554688, time: 7.571056127548218\n","[50,    15] loss: 1.2033753395080566, time: 8.111029148101807\n","[50,    16] loss: 1.005041241645813, time: 8.645636320114136\n","[50,    17] loss: 1.3052897453308105, time: 9.19208550453186\n","[50,    18] loss: 1.2294824123382568, time: 9.710486650466919\n","[50,    19] loss: 1.3315471410751343, time: 10.27127981185913\n","[50,    20] loss: 1.200757622718811, time: 10.802313089370728\n","[50,    21] loss: 1.1906254291534424, time: 11.336149215698242\n","[50,    22] loss: 1.0870786905288696, time: 11.86929988861084\n","[50,    23] loss: 1.038995385169983, time: 12.397209644317627\n","[50,    24] loss: 0.7928628325462341, time: 12.91857647895813\n","[50,    25] loss: 1.2275846004486084, time: 13.46012282371521\n","[50,    26] loss: 1.3507634401321411, time: 13.993235111236572\n","[50,    27] loss: 1.2272428274154663, time: 14.543022394180298\n","[50,    28] loss: 1.435599446296692, time: 15.103013753890991\n","[50,    29] loss: 1.2003123760223389, time: 15.632750749588013\n","[50,    30] loss: 1.5913329124450684, time: 16.19290542602539\n","[50,    31] loss: 1.5444618463516235, time: 16.73135542869568\n","[50,    32] loss: 1.2602828741073608, time: 17.264064073562622\n","[50,    33] loss: 1.1431446075439453, time: 17.78712749481201\n","[50,    34] loss: 1.210742712020874, time: 18.313908576965332\n","[50,    35] loss: 1.5571426153182983, time: 18.85468816757202\n","[50,    36] loss: 1.0239837169647217, time: 19.38184952735901\n","[50,    37] loss: 1.2783944606781006, time: 19.93469500541687\n","[50,    38] loss: 1.2493232488632202, time: 20.499377727508545\n","[50,    39] loss: 1.063481092453003, time: 21.04533362388611\n","[50,    40] loss: 1.0348068475723267, time: 21.590965747833252\n","[50,    41] loss: 1.1080502271652222, time: 22.14722514152527\n","[50,    42] loss: 1.3868205547332764, time: 22.673149585723877\n","[50,    43] loss: 0.9342696666717529, time: 23.236849308013916\n","[50,    44] loss: 1.3008999824523926, time: 23.77956247329712\n","[50,    45] loss: 1.2663280963897705, time: 24.308358907699585\n","[50,    46] loss: 1.3571702241897583, time: 24.853615760803223\n","[50,    47] loss: 1.366109848022461, time: 25.396740436553955\n","[50,    48] loss: 1.205437183380127, time: 25.937126398086548\n","[50,    49] loss: 1.2229273319244385, time: 26.489447593688965\n","[50,    50] loss: 1.7547115087509155, time: 26.656841039657593\n","\n","Evaluation: Average loss: 1.3871, Accuracy: 568/947 (59.979%)\n","\n","************************************************************\n","Total removed parameters: 864304.0\n","Take 24.511849749834518 % of active parameters\n","Total redistribution parameters: 2662988.0\n","Take: 308.10779540532036 % of removed parameters\n","Pruning rate: 0.25249999999999956\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.01 seconds.\n","\n","Total nonzero parameters:  3092829\n","Take 13.11076748139635 %\n","------------------------------------------------------------\n","[51,     1] loss: 1.3397929668426514, time: 0.5414962768554688\n","[51,     2] loss: 1.3130197525024414, time: 1.08176589012146\n","[51,     3] loss: 1.451073408126831, time: 1.6146950721740723\n","[51,     4] loss: 1.1918531656265259, time: 2.1412723064422607\n","[51,     5] loss: 1.2922561168670654, time: 2.6712982654571533\n","[51,     6] loss: 1.1869962215423584, time: 3.214311122894287\n","[51,     7] loss: 1.5261904001235962, time: 3.7583606243133545\n","[51,     8] loss: 1.0834473371505737, time: 4.288462400436401\n","[51,     9] loss: 1.4269797801971436, time: 4.836500644683838\n","[51,    10] loss: 1.175700306892395, time: 5.368577241897583\n","[51,    11] loss: 1.3626253604888916, time: 5.91583251953125\n","[51,    12] loss: 1.4194139242172241, time: 6.447713851928711\n","[51,    13] loss: 1.4000698328018188, time: 6.9837870597839355\n","[51,    14] loss: 1.2215760946273804, time: 7.513123512268066\n","[51,    15] loss: 0.9168287515640259, time: 8.041624069213867\n","[51,    16] loss: 1.1557254791259766, time: 8.588526487350464\n","[51,    17] loss: 1.4557749032974243, time: 9.124591588973999\n","[51,    18] loss: 1.1099077463150024, time: 9.664962768554688\n","[51,    19] loss: 1.4762645959854126, time: 10.196309328079224\n","[51,    20] loss: 1.148564338684082, time: 10.732510566711426\n","[51,    21] loss: 0.9146999716758728, time: 11.255459070205688\n","[51,    22] loss: 1.44894540309906, time: 11.799827098846436\n","[51,    23] loss: 1.6268846988677979, time: 12.343452215194702\n","[51,    24] loss: 0.9720640182495117, time: 12.883174419403076\n","[51,    25] loss: 1.2930757999420166, time: 13.40549087524414\n","[51,    26] loss: 1.3719441890716553, time: 13.943583250045776\n","[51,    27] loss: 0.9951664805412292, time: 14.47901439666748\n","[51,    28] loss: 1.2678337097167969, time: 14.997717142105103\n","[51,    29] loss: 1.3628711700439453, time: 15.543368339538574\n","[51,    30] loss: 1.3254692554473877, time: 16.083091974258423\n","[51,    31] loss: 1.3417575359344482, time: 16.611389636993408\n","[51,    32] loss: 1.4875483512878418, time: 17.168825387954712\n","[51,    33] loss: 1.2583760023117065, time: 17.71634268760681\n","[51,    34] loss: 1.000784158706665, time: 18.261302947998047\n","[51,    35] loss: 1.6414141654968262, time: 18.808820247650146\n","[51,    36] loss: 1.2029316425323486, time: 19.336291313171387\n","[51,    37] loss: 1.376734733581543, time: 19.887638330459595\n","[51,    38] loss: 1.2361418008804321, time: 20.406903982162476\n","[51,    39] loss: 1.5145527124404907, time: 20.93514060974121\n","[51,    40] loss: 1.093953013420105, time: 21.48082947731018\n","[51,    41] loss: 1.1477807760238647, time: 22.030264377593994\n","[51,    42] loss: 1.2704111337661743, time: 22.57259726524353\n","[51,    43] loss: 1.3395768404006958, time: 23.127817630767822\n","[51,    44] loss: 1.2674839496612549, time: 23.6551513671875\n","[51,    45] loss: 1.2438225746154785, time: 24.196855306625366\n","[51,    46] loss: 1.3156358003616333, time: 24.745968341827393\n","[51,    47] loss: 1.36410391330719, time: 25.307405710220337\n","[51,    48] loss: 1.0778295993804932, time: 25.843223571777344\n","[51,    49] loss: 1.5926421880722046, time: 26.40703058242798\n","[51,    50] loss: 1.5731019973754883, time: 26.57960844039917\n","\n","Evaluation: Average loss: 1.3062, Accuracy: 623/947 (65.787%)\n","\n","************************************************************\n","Total removed parameters: 836043.0\n","Take 23.702120493568437 % of active parameters\n","Total redistribution parameters: 2690484.0\n","Take: 321.81167715057717 % of removed parameters\n","Pruning rate: 0.24472583712816273\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.05 seconds.\n","\n","Total nonzero parameters:  3111638\n","Take 13.190500446121389 %\n","------------------------------------------------------------\n","[52,     1] loss: 1.0211687088012695, time: 0.550706148147583\n","[52,     2] loss: 1.3451794385910034, time: 1.099125623703003\n","[52,     3] loss: 1.2325024604797363, time: 1.6615872383117676\n","[52,     4] loss: 1.3580342531204224, time: 2.206674814224243\n","[52,     5] loss: 1.390684962272644, time: 2.7555429935455322\n","[52,     6] loss: 1.3111363649368286, time: 3.295698642730713\n","[52,     7] loss: 1.4086774587631226, time: 3.8172476291656494\n","[52,     8] loss: 1.3396433591842651, time: 4.338434934616089\n","[52,     9] loss: 1.5408766269683838, time: 4.900092124938965\n","[52,    10] loss: 1.0033735036849976, time: 5.4562156200408936\n","[52,    11] loss: 1.2726532220840454, time: 6.000903129577637\n","[52,    12] loss: 1.5225706100463867, time: 6.539059638977051\n","[52,    13] loss: 1.1788761615753174, time: 7.086943864822388\n","[52,    14] loss: 1.6248811483383179, time: 7.639785289764404\n","[52,    15] loss: 1.3606555461883545, time: 8.177040815353394\n","[52,    16] loss: 1.3869210481643677, time: 8.724086999893188\n","[52,    17] loss: 1.0111563205718994, time: 9.263078451156616\n","[52,    18] loss: 0.9394620060920715, time: 9.78854513168335\n","[52,    19] loss: 0.8942650556564331, time: 10.33040738105774\n","[52,    20] loss: 1.4128586053848267, time: 10.880640983581543\n","[52,    21] loss: 1.3194481134414673, time: 11.423121690750122\n","[52,    22] loss: 1.3917500972747803, time: 11.955708980560303\n","[52,    23] loss: 1.205820918083191, time: 12.51017713546753\n","[52,    24] loss: 1.3632084131240845, time: 13.064112901687622\n","[52,    25] loss: 1.3100680112838745, time: 13.607290029525757\n","[52,    26] loss: 1.1662758588790894, time: 14.126049757003784\n","[52,    27] loss: 0.9676662683486938, time: 14.676196813583374\n","[52,    28] loss: 1.1494895219802856, time: 15.221779108047485\n","[52,    29] loss: 1.3519160747528076, time: 15.769711017608643\n","[52,    30] loss: 0.9967473149299622, time: 16.290092945098877\n","[52,    31] loss: 1.266633152961731, time: 16.8275089263916\n","[52,    32] loss: 1.2215015888214111, time: 17.365514516830444\n","[52,    33] loss: 0.8765090703964233, time: 17.90968418121338\n","[52,    34] loss: 1.0057839155197144, time: 18.45417356491089\n","[52,    35] loss: 1.482837200164795, time: 18.98107361793518\n","[52,    36] loss: 1.3315861225128174, time: 19.526371240615845\n","[52,    37] loss: 1.1158281564712524, time: 20.08777904510498\n","[52,    38] loss: 1.5231060981750488, time: 20.641281604766846\n","[52,    39] loss: 1.1502394676208496, time: 21.17215895652771\n","[52,    40] loss: 1.3004217147827148, time: 21.72244167327881\n","[52,    41] loss: 0.9530338048934937, time: 22.27163338661194\n","[52,    42] loss: 1.2197539806365967, time: 22.81197237968445\n","[52,    43] loss: 1.4067670106887817, time: 23.346155166625977\n","[52,    44] loss: 1.2439005374908447, time: 23.87234401702881\n","[52,    45] loss: 1.3509938716888428, time: 24.39169692993164\n","[52,    46] loss: 1.2124606370925903, time: 24.914446353912354\n","[52,    47] loss: 1.4686670303344727, time: 25.475102424621582\n","[52,    48] loss: 1.1725114583969116, time: 26.003186464309692\n","[52,    49] loss: 1.3126972913742065, time: 26.539180994033813\n","[52,    50] loss: 1.2296195030212402, time: 26.719531774520874\n","\n","Evaluation: Average loss: 1.2338, Accuracy: 620/947 (65.470%)\n","\n","************************************************************\n","Total removed parameters: 811324.0\n","Take 23.00631754698036 % of active parameters\n","Total redistribution parameters: 2715097.0\n","Take: 334.65015209706604 % of removed parameters\n","Pruning rate: 0.23695934641649458\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.06 seconds.\n","\n","Total nonzero parameters:  3128416\n","Take 13.261623827596042 %\n","------------------------------------------------------------\n","[53,     1] loss: 1.9008762836456299, time: 0.5420191287994385\n","[53,     2] loss: 1.373261570930481, time: 1.0939314365386963\n","[53,     3] loss: 1.537264347076416, time: 1.6248795986175537\n","[53,     4] loss: 1.488777995109558, time: 2.1770315170288086\n","[53,     5] loss: 1.5395722389221191, time: 2.7351555824279785\n","[53,     6] loss: 1.3164143562316895, time: 3.272279739379883\n","[53,     7] loss: 1.0229095220565796, time: 3.8130288124084473\n","[53,     8] loss: 1.1931838989257812, time: 4.350557804107666\n","[53,     9] loss: 1.3240159749984741, time: 4.881331443786621\n","[53,    10] loss: 1.300636887550354, time: 5.427263021469116\n","[53,    11] loss: 1.307532548904419, time: 5.980860233306885\n","[53,    12] loss: 0.8553338050842285, time: 6.50059700012207\n","[53,    13] loss: 1.4093565940856934, time: 7.064122676849365\n","[53,    14] loss: 1.2718114852905273, time: 7.620759010314941\n","[53,    15] loss: 1.3787589073181152, time: 8.152270078659058\n","[53,    16] loss: 1.2059723138809204, time: 8.696911334991455\n","[53,    17] loss: 1.0522067546844482, time: 9.24181342124939\n","[53,    18] loss: 1.2327258586883545, time: 9.77593183517456\n","[53,    19] loss: 1.014650821685791, time: 10.29451322555542\n","[53,    20] loss: 1.2891639471054077, time: 10.856916666030884\n","[53,    21] loss: 1.574953556060791, time: 11.395855903625488\n","[53,    22] loss: 1.0497270822525024, time: 11.925676584243774\n","[53,    23] loss: 1.1741944551467896, time: 12.467449188232422\n","[53,    24] loss: 1.2704848051071167, time: 13.019199848175049\n","[53,    25] loss: 0.9466911554336548, time: 13.577399253845215\n","[53,    26] loss: 1.3609954118728638, time: 14.123078107833862\n","[53,    27] loss: 1.4372339248657227, time: 14.658200740814209\n","[53,    28] loss: 1.2690684795379639, time: 15.203827857971191\n","[53,    29] loss: 1.1342930793762207, time: 15.745497941970825\n","[53,    30] loss: 1.2360930442810059, time: 16.313576698303223\n","[53,    31] loss: 1.3719085454940796, time: 16.85720944404602\n","[53,    32] loss: 1.0555227994918823, time: 17.405030250549316\n","[53,    33] loss: 1.3561465740203857, time: 17.95224642753601\n","[53,    34] loss: 1.3384287357330322, time: 18.49661684036255\n","[53,    35] loss: 1.3135331869125366, time: 19.041507244110107\n","[53,    36] loss: 1.3539878129959106, time: 19.58728337287903\n","[53,    37] loss: 1.1969578266143799, time: 20.13320779800415\n","[53,    38] loss: 1.3315337896347046, time: 20.695690870285034\n","[53,    39] loss: 1.4448645114898682, time: 21.24941086769104\n","[53,    40] loss: 1.1241428852081299, time: 21.81784439086914\n","[53,    41] loss: 0.958350658416748, time: 22.361663818359375\n","[53,    42] loss: 1.2830296754837036, time: 22.923054218292236\n","[53,    43] loss: 1.3172166347503662, time: 23.45547080039978\n","[53,    44] loss: 1.3326020240783691, time: 24.018527269363403\n","[53,    45] loss: 1.2497342824935913, time: 24.56516742706299\n","[53,    46] loss: 1.2000330686569214, time: 25.126081943511963\n","[53,    47] loss: 1.378835916519165, time: 25.673641681671143\n","[53,    48] loss: 1.2391303777694702, time: 26.21893620491028\n","[53,    49] loss: 1.0710430145263672, time: 26.734058380126953\n","[53,    50] loss: 1.7013965845108032, time: 26.903069734573364\n","\n","Evaluation: Average loss: 0.9979, Accuracy: 653/947 (68.955%)\n","\n","************************************************************\n","Total removed parameters: 783040.0\n","Take 22.2049494374041 % of active parameters\n","Total redistribution parameters: 2743660.0\n","Take: 350.3856763383735 % of removed parameters\n","Pruning rate: 0.22920819245366736\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.30 seconds.\n","\n","Total nonzero parameters:  3138601\n","Take 13.304798916421845 %\n","------------------------------------------------------------\n","[54,     1] loss: 1.597022533416748, time: 0.5517902374267578\n","[54,     2] loss: 1.3714804649353027, time: 1.1247613430023193\n","[54,     3] loss: 1.241459608078003, time: 1.6624062061309814\n","[54,     4] loss: 1.1112815141677856, time: 2.2224886417388916\n","[54,     5] loss: 1.1266659498214722, time: 2.7801153659820557\n","[54,     6] loss: 1.2332947254180908, time: 3.3046624660491943\n","[54,     7] loss: 1.0545642375946045, time: 3.8492116928100586\n","[54,     8] loss: 1.1518081426620483, time: 4.393007040023804\n","[54,     9] loss: 1.1862437725067139, time: 4.954613447189331\n","[54,    10] loss: 0.8282976150512695, time: 5.513061046600342\n","[54,    11] loss: 1.391194224357605, time: 6.044981956481934\n","[54,    12] loss: 1.3253883123397827, time: 6.578972339630127\n","[54,    13] loss: 1.095933437347412, time: 7.101850748062134\n","[54,    14] loss: 1.1403237581253052, time: 7.640229940414429\n","[54,    15] loss: 1.2305641174316406, time: 8.176224946975708\n","[54,    16] loss: 1.2450822591781616, time: 8.711849451065063\n","[54,    17] loss: 1.0598162412643433, time: 9.253798961639404\n","[54,    18] loss: 1.2633391618728638, time: 9.796477317810059\n","[54,    19] loss: 1.1209003925323486, time: 10.32847285270691\n","[54,    20] loss: 1.1638067960739136, time: 10.865015029907227\n","[54,    21] loss: 1.151289939880371, time: 11.413493871688843\n","[54,    22] loss: 1.0733424425125122, time: 11.976475238800049\n","[54,    23] loss: 1.1646426916122437, time: 12.535095930099487\n","[54,    24] loss: 1.2068623304367065, time: 13.090398788452148\n","[54,    25] loss: 1.2547751665115356, time: 13.646389484405518\n","[54,    26] loss: 0.987307071685791, time: 14.204851388931274\n","[54,    27] loss: 1.25466787815094, time: 14.755076885223389\n","[54,    28] loss: 1.1730321645736694, time: 15.321189641952515\n","[54,    29] loss: 1.2329986095428467, time: 15.862517356872559\n","[54,    30] loss: 1.218948245048523, time: 16.402518272399902\n","[54,    31] loss: 1.1649388074874878, time: 16.949646711349487\n","[54,    32] loss: 1.122036337852478, time: 17.50799012184143\n","[54,    33] loss: 0.8375319242477417, time: 18.056217670440674\n","[54,    34] loss: 1.1548665761947632, time: 18.599860429763794\n","[54,    35] loss: 1.2770901918411255, time: 19.145074129104614\n","[54,    36] loss: 1.2917245626449585, time: 19.70430016517639\n","[54,    37] loss: 1.4678856134414673, time: 20.249011039733887\n","[54,    38] loss: 1.333182692527771, time: 20.8199405670166\n","[54,    39] loss: 1.2384393215179443, time: 21.385311365127563\n","[54,    40] loss: 1.067113995552063, time: 21.932252407073975\n","[54,    41] loss: 0.9762208461761475, time: 22.465446949005127\n","[54,    42] loss: 1.1739698648452759, time: 23.029664993286133\n","[54,    43] loss: 1.115619421005249, time: 23.570168018341064\n","[54,    44] loss: 1.017918348312378, time: 24.122498273849487\n","[54,    45] loss: 1.414022445678711, time: 24.696128606796265\n","[54,    46] loss: 1.0658327341079712, time: 25.247620582580566\n","[54,    47] loss: 0.9356406331062317, time: 25.793803453445435\n","[54,    48] loss: 1.0425187349319458, time: 26.329174280166626\n","[54,    49] loss: 1.8505505323410034, time: 26.898717164993286\n","[54,    50] loss: 1.4824882745742798, time: 27.077675104141235\n","\n","Evaluation: Average loss: 0.8524, Accuracy: 703/947 (74.234%)\n","\n","************************************************************\n","Total removed parameters: 756821.0\n","Take 21.45974990784586 % of active parameters\n","Total redistribution parameters: 2770125.0\n","Take: 366.0211595608473 % of removed parameters\n","Pruning rate: 0.2214800246928344\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.56 seconds.\n","\n","Total nonzero parameters:  3148501\n","Take 13.34676586579597 %\n","------------------------------------------------------------\n","[55,     1] loss: 0.987808883190155, time: 0.557610273361206\n","[55,     2] loss: 1.3053191900253296, time: 1.1494953632354736\n","[55,     3] loss: 0.8927206993103027, time: 1.6895544528961182\n","[55,     4] loss: 1.2073290348052979, time: 2.2594656944274902\n","[55,     5] loss: 1.2260773181915283, time: 2.8120431900024414\n","[55,     6] loss: 1.3489512205123901, time: 3.3397157192230225\n","[55,     7] loss: 1.656726598739624, time: 3.8673110008239746\n","[55,     8] loss: 1.3431860208511353, time: 4.409275770187378\n","[55,     9] loss: 1.1219499111175537, time: 4.957191467285156\n","[55,    10] loss: 1.1985033750534058, time: 5.510008096694946\n","[55,    11] loss: 1.3105961084365845, time: 6.057290315628052\n","[55,    12] loss: 1.2102365493774414, time: 6.587742328643799\n","[55,    13] loss: 1.3120050430297852, time: 7.1284801959991455\n","[55,    14] loss: 1.297395944595337, time: 7.688774824142456\n","[55,    15] loss: 1.342020034790039, time: 8.25317120552063\n","[55,    16] loss: 0.9937654733657837, time: 8.801286458969116\n","[55,    17] loss: 1.200386643409729, time: 9.352329730987549\n","[55,    18] loss: 1.0259617567062378, time: 9.869631052017212\n","[55,    19] loss: 1.0251351594924927, time: 10.423215627670288\n","[55,    20] loss: 1.3222711086273193, time: 10.981346607208252\n","[55,    21] loss: 1.1798102855682373, time: 11.522225618362427\n","[55,    22] loss: 1.0992939472198486, time: 12.09806752204895\n","[55,    23] loss: 1.3685780763626099, time: 12.670801162719727\n","[55,    24] loss: 1.1968871355056763, time: 13.208776712417603\n","[55,    25] loss: 1.5419381856918335, time: 13.758899211883545\n","[55,    26] loss: 0.8764348030090332, time: 14.295663118362427\n","[55,    27] loss: 0.9564276933670044, time: 14.830684900283813\n","[55,    28] loss: 1.0009074211120605, time: 15.380263328552246\n","[55,    29] loss: 1.278878092765808, time: 15.940321683883667\n","[55,    30] loss: 1.1274493932724, time: 16.49071955680847\n","[55,    31] loss: 0.9665398597717285, time: 17.03097629547119\n","[55,    32] loss: 1.1705424785614014, time: 17.57880425453186\n","[55,    33] loss: 0.9528409242630005, time: 18.129292249679565\n","[55,    34] loss: 0.7668018937110901, time: 18.684369802474976\n","[55,    35] loss: 1.1012107133865356, time: 19.235559463500977\n","[55,    36] loss: 1.0751171112060547, time: 19.783922910690308\n","[55,    37] loss: 1.2795977592468262, time: 20.320802688598633\n","[55,    38] loss: 1.368220567703247, time: 20.86073327064514\n","[55,    39] loss: 0.8430667519569397, time: 21.40472722053528\n","[55,    40] loss: 1.2320250272750854, time: 21.964674949645996\n","[55,    41] loss: 1.3046185970306396, time: 22.502189874649048\n","[55,    42] loss: 1.4148764610290527, time: 23.035574674606323\n","[55,    43] loss: 1.1269252300262451, time: 23.56498956680298\n","[55,    44] loss: 1.2666444778442383, time: 24.120813369750977\n","[55,    45] loss: 1.4123848676681519, time: 24.672708988189697\n","[55,    46] loss: 1.1655538082122803, time: 25.212385654449463\n","[55,    47] loss: 1.3061819076538086, time: 25.751616716384888\n","[55,    48] loss: 1.052868127822876, time: 26.29868459701538\n","[55,    49] loss: 1.2432225942611694, time: 26.838205814361572\n","[55,    50] loss: 2.127190589904785, time: 27.013295888900757\n","\n","Evaluation: Average loss: 0.9012, Accuracy: 706/947 (74.551%)\n","\n","************************************************************\n","Total removed parameters: 726219.0\n","Take 20.59059027271753 % of active parameters\n","Total redistribution parameters: 2800584.0\n","Take: 385.63904276809063 % of removed parameters\n","Pruning rate: 0.21378246990254268\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.42 seconds.\n","\n","Total nonzero parameters:  3162798\n","Take 13.407372075412319 %\n","------------------------------------------------------------\n","[56,     1] loss: 1.0448764562606812, time: 0.5547511577606201\n","[56,     2] loss: 1.054386854171753, time: 1.0887377262115479\n","[56,     3] loss: 1.4301882982254028, time: 1.6066546440124512\n","[56,     4] loss: 1.1499766111373901, time: 2.164031982421875\n","[56,     5] loss: 0.9629824757575989, time: 2.6987760066986084\n","[56,     6] loss: 1.255264163017273, time: 3.2394309043884277\n","[56,     7] loss: 1.4954164028167725, time: 3.7893359661102295\n","[56,     8] loss: 1.4041842222213745, time: 4.325750827789307\n","[56,     9] loss: 1.7745810747146606, time: 4.864710807800293\n","[56,    10] loss: 1.1621453762054443, time: 5.41177773475647\n","[56,    11] loss: 1.211466908454895, time: 5.946404218673706\n","[56,    12] loss: 1.4790234565734863, time: 6.48137640953064\n","[56,    13] loss: 1.2639389038085938, time: 7.023639440536499\n","[56,    14] loss: 1.3024488687515259, time: 7.561809778213501\n","[56,    15] loss: 1.2009029388427734, time: 8.11906123161316\n","[56,    16] loss: 1.1097276210784912, time: 8.663053512573242\n","[56,    17] loss: 1.407589077949524, time: 9.225662231445312\n","[56,    18] loss: 1.389589786529541, time: 9.792992115020752\n","[56,    19] loss: 1.000778317451477, time: 10.370540618896484\n","[56,    20] loss: 1.189733624458313, time: 10.936237096786499\n","[56,    21] loss: 1.2665141820907593, time: 11.513399362564087\n","[56,    22] loss: 1.38141667842865, time: 12.057353496551514\n","[56,    23] loss: 1.2078624963760376, time: 12.603208541870117\n","[56,    24] loss: 1.191443681716919, time: 13.155945062637329\n","[56,    25] loss: 1.3351857662200928, time: 13.701399326324463\n","[56,    26] loss: 1.4756475687026978, time: 14.241265535354614\n","[56,    27] loss: 1.2896286249160767, time: 14.780535697937012\n","[56,    28] loss: 1.2375400066375732, time: 15.333694219589233\n","[56,    29] loss: 1.0893770456314087, time: 15.886795043945312\n","[56,    30] loss: 0.9431187510490417, time: 16.425750970840454\n","[56,    31] loss: 1.2271456718444824, time: 16.964511156082153\n","[56,    32] loss: 1.1613630056381226, time: 17.5099880695343\n","[56,    33] loss: 1.235022783279419, time: 18.051923990249634\n","[56,    34] loss: 1.27387273311615, time: 18.587389707565308\n","[56,    35] loss: 1.0933105945587158, time: 19.11550807952881\n","[56,    36] loss: 1.1416211128234863, time: 19.653252601623535\n","[56,    37] loss: 0.7722794413566589, time: 20.180470943450928\n","[56,    38] loss: 1.2598485946655273, time: 20.722246885299683\n","[56,    39] loss: 1.3777095079421997, time: 21.260437488555908\n","[56,    40] loss: 0.8902540802955627, time: 21.79701519012451\n","[56,    41] loss: 0.802989661693573, time: 22.323835849761963\n","[56,    42] loss: 1.25723397731781, time: 22.863516569137573\n","[56,    43] loss: 1.2045459747314453, time: 23.417867422103882\n","[56,    44] loss: 1.2513717412948608, time: 23.962588787078857\n","[56,    45] loss: 1.0847480297088623, time: 24.50222396850586\n","[56,    46] loss: 1.0439155101776123, time: 25.012727737426758\n","[56,    47] loss: 1.220402717590332, time: 25.540673971176147\n","[56,    48] loss: 1.1204091310501099, time: 26.11016607284546\n","[56,    49] loss: 1.3234188556671143, time: 26.65414333343506\n","[56,    50] loss: 0.7809411883354187, time: 26.821775436401367\n","\n","Evaluation: Average loss: 0.9259, Accuracy: 670/947 (70.750%)\n","\n","************************************************************\n","Total removed parameters: 703356.0\n","Take 19.943160987443868 % of active parameters\n","Total redistribution parameters: 2822811.0\n","Take: 401.33460153890775 % of removed parameters\n","Pruning rate: 0.20612312464003302\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.17 seconds.\n","\n","Total nonzero parameters:  3175853\n","Take 13.462713340470822 %\n","------------------------------------------------------------\n","[57,     1] loss: 0.8970850110054016, time: 0.52652907371521\n","[57,     2] loss: 1.0461434125900269, time: 1.0746173858642578\n","[57,     3] loss: 1.119942545890808, time: 1.6108558177947998\n","[57,     4] loss: 1.2256886959075928, time: 2.1526167392730713\n","[57,     5] loss: 1.200402021408081, time: 2.6989641189575195\n","[57,     6] loss: 0.9613237977027893, time: 3.2486300468444824\n","[57,     7] loss: 1.3325846195220947, time: 3.8039331436157227\n","[57,     8] loss: 1.2519088983535767, time: 4.362549543380737\n","[57,     9] loss: 1.073121428489685, time: 4.905086994171143\n","[57,    10] loss: 1.3926646709442139, time: 5.436253070831299\n","[57,    11] loss: 0.97633296251297, time: 5.977766513824463\n","[57,    12] loss: 1.1432193517684937, time: 6.5329430103302\n","[57,    13] loss: 1.1591743230819702, time: 7.076132535934448\n","[57,    14] loss: 1.2987385988235474, time: 7.605047941207886\n","[57,    15] loss: 1.4133175611495972, time: 8.145691156387329\n","[57,    16] loss: 1.4151769876480103, time: 8.678331851959229\n","[57,    17] loss: 1.0004633665084839, time: 9.218149900436401\n","[57,    18] loss: 1.5418920516967773, time: 9.745744466781616\n","[57,    19] loss: 1.2518564462661743, time: 10.263654947280884\n","[57,    20] loss: 1.2903317213058472, time: 10.818805694580078\n","[57,    21] loss: 1.3222678899765015, time: 11.390467882156372\n","[57,    22] loss: 1.2592273950576782, time: 11.951887607574463\n","[57,    23] loss: 1.2835299968719482, time: 12.498038053512573\n","[57,    24] loss: 1.4395073652267456, time: 13.05380630493164\n","[57,    25] loss: 1.3561453819274902, time: 13.578071355819702\n","[57,    26] loss: 1.3447108268737793, time: 14.113530158996582\n","[57,    27] loss: 1.2443768978118896, time: 14.642162799835205\n","[57,    28] loss: 1.3529824018478394, time: 15.179828882217407\n","[57,    29] loss: 1.3140804767608643, time: 15.715144872665405\n","[57,    30] loss: 1.3329521417617798, time: 16.25283694267273\n","[57,    31] loss: 1.1638416051864624, time: 16.789073944091797\n","[57,    32] loss: 1.0785748958587646, time: 17.357965230941772\n","[57,    33] loss: 1.1717852354049683, time: 17.908381938934326\n","[57,    34] loss: 1.3035695552825928, time: 18.444432497024536\n","[57,    35] loss: 1.0556033849716187, time: 18.98855996131897\n","[57,    36] loss: 0.9945636987686157, time: 19.514864683151245\n","[57,    37] loss: 1.3080880641937256, time: 20.06417965888977\n","[57,    38] loss: 1.1173547506332397, time: 20.6154305934906\n","[57,    39] loss: 1.1297481060028076, time: 21.16005229949951\n","[57,    40] loss: 1.222123146057129, time: 21.70694923400879\n","[57,    41] loss: 1.1220647096633911, time: 22.247302293777466\n","[57,    42] loss: 1.0554897785186768, time: 22.786505699157715\n","[57,    43] loss: 1.2888585329055786, time: 23.319234371185303\n","[57,    44] loss: 1.2260160446166992, time: 23.86247968673706\n","[57,    45] loss: 1.2363674640655518, time: 24.401507139205933\n","[57,    46] loss: 1.2726824283599854, time: 24.934998750686646\n","[57,    47] loss: 1.066907286643982, time: 25.48477602005005\n","[57,    48] loss: 1.0321475267410278, time: 26.02631974220276\n","[57,    49] loss: 1.3207182884216309, time: 26.563811779022217\n","[57,    50] loss: 1.211085557937622, time: 26.74317216873169\n","\n","Evaluation: Average loss: 1.1189, Accuracy: 634/947 (66.948%)\n","\n","************************************************************\n","Total removed parameters: 667084.0\n","Take 18.918105693802932 % of active parameters\n","Total redistribution parameters: 2858340.0\n","Take: 428.4827697861139 % of removed parameters\n","Pruning rate: 0.19850954775435548\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.16 seconds.\n","\n","Total nonzero parameters:  3192108\n","Take 13.531619680074499 %\n","------------------------------------------------------------\n","[58,     1] loss: 1.4769794940948486, time: 0.540294885635376\n","[58,     2] loss: 1.3306776285171509, time: 1.0776562690734863\n","[58,     3] loss: 1.1684553623199463, time: 1.6115131378173828\n","[58,     4] loss: 1.0429174900054932, time: 2.1594834327697754\n","[58,     5] loss: 1.1378145217895508, time: 2.704230308532715\n","[58,     6] loss: 1.5774387121200562, time: 3.2617855072021484\n","[58,     7] loss: 1.190761685371399, time: 3.8282737731933594\n","[58,     8] loss: 1.0164597034454346, time: 4.365458965301514\n","[58,     9] loss: 1.0851300954818726, time: 4.929480791091919\n","[58,    10] loss: 1.10468327999115, time: 5.484165668487549\n","[58,    11] loss: 1.1805758476257324, time: 6.067541599273682\n","[58,    12] loss: 1.047212839126587, time: 6.6164939403533936\n","[58,    13] loss: 1.3178997039794922, time: 7.158573389053345\n","[58,    14] loss: 0.9721763730049133, time: 7.6991119384765625\n","[58,    15] loss: 1.141167402267456, time: 8.247627258300781\n","[58,    16] loss: 1.1494331359863281, time: 8.786005020141602\n","[58,    17] loss: 0.7906031608581543, time: 9.336211681365967\n","[58,    18] loss: 0.998516857624054, time: 9.876537084579468\n","[58,    19] loss: 1.3124330043792725, time: 10.433148622512817\n","[58,    20] loss: 1.1692148447036743, time: 10.992472171783447\n","[58,    21] loss: 0.992782473564148, time: 11.51715874671936\n","[58,    22] loss: 0.9301565289497375, time: 12.050148248672485\n","[58,    23] loss: 1.2221230268478394, time: 12.597808837890625\n","[58,    24] loss: 1.0457504987716675, time: 13.15223741531372\n","[58,    25] loss: 1.5528253316879272, time: 13.705864429473877\n","[58,    26] loss: 1.4877142906188965, time: 14.264267206192017\n","[58,    27] loss: 1.176504373550415, time: 14.795536041259766\n","[58,    28] loss: 0.8834955096244812, time: 15.334066152572632\n","[58,    29] loss: 1.087742567062378, time: 15.881592273712158\n","[58,    30] loss: 1.1271889209747314, time: 16.42515993118286\n","[58,    31] loss: 1.0674406290054321, time: 16.973397731781006\n","[58,    32] loss: 0.9949074387550354, time: 17.50550413131714\n","[58,    33] loss: 0.7300252914428711, time: 18.041354417800903\n","[58,    34] loss: 1.3461332321166992, time: 18.5742084980011\n","[58,    35] loss: 1.0195330381393433, time: 19.122087717056274\n","[58,    36] loss: 0.9791219830513, time: 19.64324378967285\n","[58,    37] loss: 1.0764737129211426, time: 20.164961099624634\n","[58,    38] loss: 1.1420317888259888, time: 20.693055152893066\n","[58,    39] loss: 1.2538431882858276, time: 21.23900032043457\n","[58,    40] loss: 1.1902533769607544, time: 21.798254251480103\n","[58,    41] loss: 1.501240611076355, time: 22.35353112220764\n","[58,    42] loss: 1.5872540473937988, time: 22.905269622802734\n","[58,    43] loss: 1.5251785516738892, time: 23.451971530914307\n","[58,    44] loss: 1.0034332275390625, time: 23.97529149055481\n","[58,    45] loss: 1.057976484298706, time: 24.53701949119568\n","[58,    46] loss: 1.2746690511703491, time: 25.083101272583008\n","[58,    47] loss: 1.0538809299468994, time: 25.619219064712524\n","[58,    48] loss: 1.216233253479004, time: 26.153292417526245\n","[58,    49] loss: 0.9922370314598083, time: 26.69297981262207\n","[58,    50] loss: 0.872271716594696, time: 26.858131647109985\n","\n","Evaluation: Average loss: 1.7346, Accuracy: 572/947 (60.401%)\n","\n","************************************************************\n","Total removed parameters: 651699.0\n","Take 18.48569136648528 % of active parameters\n","Total redistribution parameters: 2874356.0\n","Take: 441.0557634736282 % of removed parameters\n","Pruning rate: 0.19094925292669818\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.29 seconds.\n","\n","Total nonzero parameters:  3204284\n","Take 13.583234788718876 %\n","------------------------------------------------------------\n","[59,     1] loss: 1.1305679082870483, time: 0.547339916229248\n","[59,     2] loss: 1.0248732566833496, time: 1.104424238204956\n","[59,     3] loss: 0.9837523698806763, time: 1.6466732025146484\n","[59,     4] loss: 1.2108097076416016, time: 2.179929494857788\n","[59,     5] loss: 1.410340666770935, time: 2.704867124557495\n","[59,     6] loss: 1.0739325284957886, time: 3.250354290008545\n","[59,     7] loss: 1.0832284688949585, time: 3.78566312789917\n","[59,     8] loss: 1.2988320589065552, time: 4.322363376617432\n","[59,     9] loss: 0.9977070093154907, time: 4.8739001750946045\n","[59,    10] loss: 1.2042919397354126, time: 5.41093111038208\n","[59,    11] loss: 1.08309006690979, time: 5.9533421993255615\n","[59,    12] loss: 1.0310152769088745, time: 6.496046781539917\n","[59,    13] loss: 1.2655889987945557, time: 7.01431679725647\n","[59,    14] loss: 1.2070014476776123, time: 7.572211503982544\n","[59,    15] loss: 1.014176368713379, time: 8.11331820487976\n","[59,    16] loss: 1.2549177408218384, time: 8.649300575256348\n","[59,    17] loss: 1.413055181503296, time: 9.17015027999878\n","[59,    18] loss: 1.233528971672058, time: 9.700030088424683\n","[59,    19] loss: 1.0786893367767334, time: 10.248807668685913\n","[59,    20] loss: 1.0310722589492798, time: 10.788450956344604\n","[59,    21] loss: 1.0745549201965332, time: 11.307279109954834\n","[59,    22] loss: 1.148216724395752, time: 11.861756086349487\n","[59,    23] loss: 1.2943611145019531, time: 12.411632537841797\n","[59,    24] loss: 1.240268349647522, time: 12.961801767349243\n","[59,    25] loss: 1.2313635349273682, time: 13.489411115646362\n","[59,    26] loss: 1.3940036296844482, time: 14.023966073989868\n","[59,    27] loss: 1.1532156467437744, time: 14.550631046295166\n","[59,    28] loss: 1.0557149648666382, time: 15.0837984085083\n","[59,    29] loss: 1.5614486932754517, time: 15.629752397537231\n","[59,    30] loss: 0.994716465473175, time: 16.15915298461914\n","[59,    31] loss: 1.0120177268981934, time: 16.702866554260254\n","[59,    32] loss: 0.9233997464179993, time: 17.25681471824646\n","[59,    33] loss: 1.0871107578277588, time: 17.78322672843933\n","[59,    34] loss: 1.0305224657058716, time: 18.327813625335693\n","[59,    35] loss: 0.9694988131523132, time: 18.88243556022644\n","[59,    36] loss: 1.5709185600280762, time: 19.41779398918152\n","[59,    37] loss: 1.1459202766418457, time: 19.98600125312805\n","[59,    38] loss: 1.1805071830749512, time: 20.534006595611572\n","[59,    39] loss: 1.0564930438995361, time: 21.075854778289795\n","[59,    40] loss: 0.9798055291175842, time: 21.61868119239807\n","[59,    41] loss: 0.8917091488838196, time: 22.155309200286865\n","[59,    42] loss: 1.471063494682312, time: 22.704217433929443\n","[59,    43] loss: 1.0338926315307617, time: 23.249250411987305\n","[59,    44] loss: 1.288743019104004, time: 23.815858840942383\n","[59,    45] loss: 1.2417807579040527, time: 24.360338926315308\n","[59,    46] loss: 0.8941048383712769, time: 24.886073112487793\n","[59,    47] loss: 1.2183974981307983, time: 25.419809579849243\n","[59,    48] loss: 1.0791599750518799, time: 25.952146291732788\n","[59,    49] loss: 1.444197416305542, time: 26.491389989852905\n","[59,    50] loss: 0.8792162537574768, time: 26.660688161849976\n","\n","Evaluation: Average loss: 0.7219, Accuracy: 723/947 (76.346%)\n","\n","************************************************************\n","Total removed parameters: 615440.0\n","Take 17.454066938831073 % of active parameters\n","Total redistribution parameters: 2911080.0\n","Take: 473.00792928636423 % of removed parameters\n","Pruning rate: 0.18344970125529053\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.05 seconds.\n","\n","Total nonzero parameters:  3217062\n","Take 13.637401827012066 %\n","------------------------------------------------------------\n","[60,     1] loss: 1.065099835395813, time: 0.5390634536743164\n","[60,     2] loss: 1.35564124584198, time: 1.093813419342041\n","[60,     3] loss: 1.3171035051345825, time: 1.6362535953521729\n","[60,     4] loss: 1.1948325634002686, time: 2.1828856468200684\n","[60,     5] loss: 0.9569687247276306, time: 2.726738214492798\n","[60,     6] loss: 0.9091364741325378, time: 3.2771244049072266\n","[60,     7] loss: 1.2218728065490723, time: 3.821186065673828\n","[60,     8] loss: 1.044558048248291, time: 4.375372648239136\n","[60,     9] loss: 1.692941665649414, time: 4.951926946640015\n","[60,    10] loss: 0.9478563666343689, time: 5.505128860473633\n","[60,    11] loss: 1.1204262971878052, time: 6.045550584793091\n","[60,    12] loss: 0.9767271280288696, time: 6.5858190059661865\n","[60,    13] loss: 1.3983591794967651, time: 7.144793748855591\n","[60,    14] loss: 1.116194486618042, time: 7.679384708404541\n","[60,    15] loss: 0.9925218820571899, time: 8.217423677444458\n","[60,    16] loss: 1.2058186531066895, time: 8.774946689605713\n","[60,    17] loss: 0.8583731055259705, time: 9.325317144393921\n","[60,    18] loss: 1.2390687465667725, time: 9.865007162094116\n","[60,    19] loss: 1.2960598468780518, time: 10.418340682983398\n","[60,    20] loss: 1.07272207736969, time: 10.979583740234375\n","[60,    21] loss: 0.9266742467880249, time: 11.53242826461792\n","[60,    22] loss: 1.0875247716903687, time: 12.0998055934906\n","[60,    23] loss: 1.0043474435806274, time: 12.653719663619995\n","[60,    24] loss: 0.9095422625541687, time: 13.200024127960205\n","[60,    25] loss: 1.355973720550537, time: 13.753602743148804\n","[60,    26] loss: 0.598328173160553, time: 14.278281927108765\n","[60,    27] loss: 0.8333348631858826, time: 14.83633303642273\n","[60,    28] loss: 1.0373311042785645, time: 15.398049354553223\n","[60,    29] loss: 1.1338510513305664, time: 15.945701599121094\n","[60,    30] loss: 1.3332347869873047, time: 16.481338500976562\n","[60,    31] loss: 1.3260523080825806, time: 17.0268337726593\n","[60,    32] loss: 1.328491449356079, time: 17.562612771987915\n","[60,    33] loss: 0.8694114089012146, time: 18.102315664291382\n","[60,    34] loss: 1.2299623489379883, time: 18.64452862739563\n","[60,    35] loss: 1.179657220840454, time: 19.182328701019287\n","[60,    36] loss: 1.3568061590194702, time: 19.726564407348633\n","[60,    37] loss: 1.0410182476043701, time: 20.27552843093872\n","[60,    38] loss: 1.2344223260879517, time: 20.82541561126709\n","[60,    39] loss: 1.1908540725708008, time: 21.381929397583008\n","[60,    40] loss: 1.5836467742919922, time: 21.94679069519043\n","[60,    41] loss: 0.7248750329017639, time: 22.50576162338257\n","[60,    42] loss: 1.4665488004684448, time: 23.05496072769165\n","[60,    43] loss: 1.178844690322876, time: 23.604912996292114\n","[60,    44] loss: 1.1562613248825073, time: 24.142009258270264\n","[60,    45] loss: 1.1962088346481323, time: 24.68721652030945\n","[60,    46] loss: 1.1786317825317383, time: 25.201301336288452\n","[60,    47] loss: 1.3342515230178833, time: 25.7227725982666\n","[60,    48] loss: 1.3466483354568481, time: 26.251240491867065\n","[60,    49] loss: 1.1646732091903687, time: 26.786296844482422\n","[60,    50] loss: 1.2166591882705688, time: 26.96157145500183\n","\n","Evaluation: Average loss: 0.8770, Accuracy: 690/947 (72.862%)\n","\n","************************************************************\n","Total removed parameters: 598153.0\n","Take 16.96156550934065 % of active parameters\n","Total redistribution parameters: 2928580.0\n","Take: 489.6038304580935 % of removed parameters\n","Pruning rate: 0.1760182938922004\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.47 seconds.\n","\n","Total nonzero parameters:  3229773\n","Take 13.691284846556965 %\n","------------------------------------------------------------\n","[61,     1] loss: 0.8453050851821899, time: 0.5524446964263916\n","[61,     2] loss: 1.1120073795318604, time: 1.1037406921386719\n","[61,     3] loss: 1.195737600326538, time: 1.636587381362915\n","[61,     4] loss: 1.6496670246124268, time: 2.1984760761260986\n","[61,     5] loss: 1.0353697538375854, time: 2.737555742263794\n","[61,     6] loss: 1.2184090614318848, time: 3.2841320037841797\n","[61,     7] loss: 1.2198724746704102, time: 3.835162878036499\n","[61,     8] loss: 1.082481861114502, time: 4.392470598220825\n","[61,     9] loss: 1.1629023551940918, time: 4.956725358963013\n","[61,    10] loss: 1.2893154621124268, time: 5.534753084182739\n","[61,    11] loss: 0.9544578194618225, time: 6.083005666732788\n","[61,    12] loss: 1.243606686592102, time: 6.634845972061157\n","[61,    13] loss: 1.187600016593933, time: 7.203747034072876\n","[61,    14] loss: 1.2188395261764526, time: 7.752708435058594\n","[61,    15] loss: 1.00664222240448, time: 8.310510396957397\n","[61,    16] loss: 1.2634601593017578, time: 8.855345726013184\n","[61,    17] loss: 0.9957548975944519, time: 9.38108777999878\n","[61,    18] loss: 1.0261642932891846, time: 9.905053615570068\n","[61,    19] loss: 1.174836277961731, time: 10.438342332839966\n","[61,    20] loss: 0.953407347202301, time: 10.961254358291626\n","[61,    21] loss: 1.2399812936782837, time: 11.516149759292603\n","[61,    22] loss: 1.2963224649429321, time: 12.075627326965332\n","[61,    23] loss: 1.7378870248794556, time: 12.627374172210693\n","[61,    24] loss: 1.1381057500839233, time: 13.184180974960327\n","[61,    25] loss: 1.4281176328659058, time: 13.717235326766968\n","[61,    26] loss: 1.1801741123199463, time: 14.262069940567017\n","[61,    27] loss: 1.2875701189041138, time: 14.818969249725342\n","[61,    28] loss: 1.2838339805603027, time: 15.357254028320312\n","[61,    29] loss: 1.115177035331726, time: 15.893451929092407\n","[61,    30] loss: 0.8070212602615356, time: 16.42820453643799\n","[61,    31] loss: 1.0196802616119385, time: 16.965739727020264\n","[61,    32] loss: 1.1060951948165894, time: 17.500120639801025\n","[61,    33] loss: 1.0343587398529053, time: 18.037402153015137\n","[61,    34] loss: 1.2745722532272339, time: 18.58390212059021\n","[61,    35] loss: 1.0733473300933838, time: 19.140586137771606\n","[61,    36] loss: 1.400768756866455, time: 19.702900409698486\n","[61,    37] loss: 1.3211148977279663, time: 20.260576725006104\n","[61,    38] loss: 1.0602529048919678, time: 20.797110080718994\n","[61,    39] loss: 1.3012806177139282, time: 21.343918561935425\n","[61,    40] loss: 1.024045705795288, time: 21.874359846115112\n","[61,    41] loss: 0.8784982562065125, time: 22.428914070129395\n","[61,    42] loss: 1.2260304689407349, time: 22.974046230316162\n","[61,    43] loss: 1.383406400680542, time: 23.523764848709106\n","[61,    44] loss: 1.012490153312683, time: 24.07612657546997\n","[61,    45] loss: 1.2775256633758545, time: 24.600638389587402\n","[61,    46] loss: 1.1507703065872192, time: 25.14198327064514\n","[61,    47] loss: 1.5367670059204102, time: 25.68294930458069\n","[61,    48] loss: 0.9946531653404236, time: 26.24053692817688\n","[61,    49] loss: 1.3229639530181885, time: 26.785865783691406\n","[61,    50] loss: 1.0269463062286377, time: 26.96044397354126\n","\n","Evaluation: Average loss: 0.8395, Accuracy: 727/947 (76.769%)\n","\n","************************************************************\n","Total removed parameters: 578015.0\n","Take 16.389531047572923 % of active parameters\n","Total redistribution parameters: 2948193.0\n","Take: 510.0547563644542 % of removed parameters\n","Pruning rate: 0.16866236473929025\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.38 seconds.\n","\n","Total nonzero parameters:  3241886\n","Take 13.742632892796234 %\n","------------------------------------------------------------\n","[62,     1] loss: 1.3052308559417725, time: 0.5474874973297119\n","[62,     2] loss: 1.012766718864441, time: 1.0913686752319336\n","[62,     3] loss: 0.9828428626060486, time: 1.6388335227966309\n","[62,     4] loss: 1.0927963256835938, time: 2.1771390438079834\n","[62,     5] loss: 1.2384711503982544, time: 2.715672016143799\n","[62,     6] loss: 1.1128805875778198, time: 3.2774267196655273\n","[62,     7] loss: 1.0619769096374512, time: 3.849665880203247\n","[62,     8] loss: 0.9344903826713562, time: 4.425621509552002\n","[62,     9] loss: 1.3688180446624756, time: 4.982508659362793\n","[62,    10] loss: 1.3422281742095947, time: 5.5220863819122314\n","[62,    11] loss: 1.1759557723999023, time: 6.076753377914429\n","[62,    12] loss: 1.0745835304260254, time: 6.619237422943115\n","[62,    13] loss: 1.2907731533050537, time: 7.176846981048584\n","[62,    14] loss: 1.2216383218765259, time: 7.739309787750244\n","[62,    15] loss: 0.7227826714515686, time: 8.28151273727417\n","[62,    16] loss: 1.2752765417099, time: 8.804650783538818\n","[62,    17] loss: 1.0562759637832642, time: 9.338760375976562\n","[62,    18] loss: 1.066921353340149, time: 9.892501831054688\n","[62,    19] loss: 1.356984257698059, time: 10.441021203994751\n","[62,    20] loss: 0.8531854152679443, time: 11.003989934921265\n","[62,    21] loss: 1.6458343267440796, time: 11.557081937789917\n","[62,    22] loss: 0.8194693326950073, time: 12.09064769744873\n","[62,    23] loss: 1.114749789237976, time: 12.607534408569336\n","[62,    24] loss: 0.9865426421165466, time: 13.155722618103027\n","[62,    25] loss: 1.154911994934082, time: 13.684272527694702\n","[62,    26] loss: 1.012376070022583, time: 14.220416784286499\n","[62,    27] loss: 0.8747745156288147, time: 14.77072525024414\n","[62,    28] loss: 1.0860614776611328, time: 15.291280031204224\n","[62,    29] loss: 1.0227787494659424, time: 15.84585428237915\n","[62,    30] loss: 1.5951849222183228, time: 16.40842032432556\n","[62,    31] loss: 1.2673612833023071, time: 16.95167875289917\n","[62,    32] loss: 1.3898817300796509, time: 17.51873230934143\n","[62,    33] loss: 1.357154130935669, time: 18.066932916641235\n","[62,    34] loss: 0.9201009273529053, time: 18.60775113105774\n","[62,    35] loss: 0.9887515306472778, time: 19.1387300491333\n","[62,    36] loss: 1.0277472734451294, time: 19.71591591835022\n","[62,    37] loss: 1.2037334442138672, time: 20.27450704574585\n","[62,    38] loss: 1.177638053894043, time: 20.813180208206177\n","[62,    39] loss: 1.1565849781036377, time: 21.34943437576294\n","[62,    40] loss: 1.1048483848571777, time: 21.89329433441162\n","[62,    41] loss: 1.1784310340881348, time: 22.42481827735901\n","[62,    42] loss: 1.280251145362854, time: 22.967570066452026\n","[62,    43] loss: 0.8865265846252441, time: 23.51092219352722\n","[62,    44] loss: 1.1676735877990723, time: 24.071179389953613\n","[62,    45] loss: 1.2258315086364746, time: 24.603748559951782\n","[62,    46] loss: 0.8690357804298401, time: 25.131707906723022\n","[62,    47] loss: 1.117753028869629, time: 25.667443990707397\n","[62,    48] loss: 1.1910550594329834, time: 26.20534324645996\n","[62,    49] loss: 1.2033841609954834, time: 26.756343603134155\n","[62,    50] loss: 1.1657698154449463, time: 26.936022996902466\n","\n","Evaluation: Average loss: 1.0800, Accuracy: 664/947 (70.116%)\n","\n","************************************************************\n","Total removed parameters: 549033.0\n","Take 15.57006847015264 % of active parameters\n","Total redistribution parameters: 2977376.0\n","Take: 542.294543315247 % of removed parameters\n","Pruning rate: 0.16138917321054216\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.33 seconds.\n","\n","Total nonzero parameters:  3253536\n","Take 13.792018242312249 %\n","------------------------------------------------------------\n","[63,     1] loss: 0.9529255628585815, time: 0.5592479705810547\n","[63,     2] loss: 1.1095243692398071, time: 1.1168289184570312\n","[63,     3] loss: 1.1876965761184692, time: 1.669471025466919\n","[63,     4] loss: 1.3734921216964722, time: 2.2217397689819336\n","[63,     5] loss: 1.1723839044570923, time: 2.78147292137146\n","[63,     6] loss: 1.7273873090744019, time: 3.3342819213867188\n","[63,     7] loss: 0.8418272733688354, time: 3.890791177749634\n","[63,     8] loss: 1.6014776229858398, time: 4.423412799835205\n","[63,     9] loss: 1.1221208572387695, time: 4.972010374069214\n","[63,    10] loss: 0.791771411895752, time: 5.513730049133301\n","[63,    11] loss: 1.080427646636963, time: 6.057615041732788\n","[63,    12] loss: 1.2871339321136475, time: 6.615187644958496\n","[63,    13] loss: 1.139002799987793, time: 7.156094789505005\n","[63,    14] loss: 1.0002779960632324, time: 7.696268081665039\n","[63,    15] loss: 1.507979393005371, time: 8.229241609573364\n","[63,    16] loss: 1.0425491333007812, time: 8.774139404296875\n","[63,    17] loss: 0.8873867392539978, time: 9.29124641418457\n","[63,    18] loss: 1.0288541316986084, time: 9.824558019638062\n","[63,    19] loss: 1.1637674570083618, time: 10.365696907043457\n","[63,    20] loss: 1.1604763269424438, time: 10.908327579498291\n","[63,    21] loss: 1.2269257307052612, time: 11.464594841003418\n","[63,    22] loss: 1.3494367599487305, time: 12.025250911712646\n","[63,    23] loss: 0.9829815030097961, time: 12.573429107666016\n","[63,    24] loss: 1.2583224773406982, time: 13.127037763595581\n","[63,    25] loss: 1.079479455947876, time: 13.667414903640747\n","[63,    26] loss: 1.1655486822128296, time: 14.217674732208252\n","[63,    27] loss: 1.4786274433135986, time: 14.783802509307861\n","[63,    28] loss: 1.1442161798477173, time: 15.332632303237915\n","[63,    29] loss: 1.0542634725570679, time: 15.876661539077759\n","[63,    30] loss: 0.9361271858215332, time: 16.42163848876953\n","[63,    31] loss: 1.1138429641723633, time: 16.967639684677124\n","[63,    32] loss: 1.051216959953308, time: 17.51705288887024\n","[63,    33] loss: 1.0960767269134521, time: 18.07165813446045\n","[63,    34] loss: 1.2503032684326172, time: 18.64377236366272\n","[63,    35] loss: 0.9334544539451599, time: 19.219685792922974\n","[63,    36] loss: 1.008409857749939, time: 19.83779287338257\n","[63,    37] loss: 0.9735302329063416, time: 20.424490690231323\n","[63,    38] loss: 0.9603384137153625, time: 20.96207046508789\n","[63,    39] loss: 1.0397746562957764, time: 21.492138147354126\n","[63,    40] loss: 1.1599663496017456, time: 22.04848861694336\n","[63,    41] loss: 0.958431601524353, time: 22.576550722122192\n","[63,    42] loss: 0.763566255569458, time: 23.12783646583557\n","[63,    43] loss: 0.854685366153717, time: 23.691657304763794\n","[63,    44] loss: 0.757402241230011, time: 24.235755681991577\n","[63,    45] loss: 1.2731372117996216, time: 24.777765035629272\n","[63,    46] loss: 1.1931278705596924, time: 25.335598707199097\n","[63,    47] loss: 0.940455973148346, time: 25.875614404678345\n","[63,    48] loss: 1.190544605255127, time: 26.426528215408325\n","[63,    49] loss: 1.0747036933898926, time: 26.95685648918152\n","[63,    50] loss: 1.341414451599121, time: 27.129284858703613\n","\n","Evaluation: Average loss: 0.8297, Accuracy: 696/947 (73.495%)\n","\n","************************************************************\n","Total removed parameters: 527901.0\n","Take 14.96993116793883 % of active parameters\n","Total redistribution parameters: 2998238.0\n","Take: 567.9545975476462 % of removed parameters\n","Pruning rate: 0.1542058970678917\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.55 seconds.\n","\n","Total nonzero parameters:  3265716\n","Take 13.843650307299807 %\n","------------------------------------------------------------\n","[64,     1] loss: 1.001230001449585, time: 0.5526816844940186\n","[64,     2] loss: 1.0437411069869995, time: 1.08870530128479\n","[64,     3] loss: 0.979533851146698, time: 1.6396336555480957\n","[64,     4] loss: 0.8850780725479126, time: 2.1794960498809814\n","[64,     5] loss: 1.2511063814163208, time: 2.719149112701416\n","[64,     6] loss: 1.5997101068496704, time: 3.2727584838867188\n","[64,     7] loss: 1.0429171323776245, time: 3.817369222640991\n","[64,     8] loss: 1.293189525604248, time: 4.374456167221069\n","[64,     9] loss: 0.8363659977912903, time: 4.925199747085571\n","[64,    10] loss: 1.046302080154419, time: 5.477253198623657\n","[64,    11] loss: 1.2841614484786987, time: 6.032041549682617\n","[64,    12] loss: 1.1964303255081177, time: 6.576675891876221\n","[64,    13] loss: 1.0993801355361938, time: 7.13249659538269\n","[64,    14] loss: 0.8442589640617371, time: 7.683600664138794\n","[64,    15] loss: 1.0746666193008423, time: 8.250613451004028\n","[64,    16] loss: 1.1794469356536865, time: 8.804363489151001\n","[64,    17] loss: 1.097158670425415, time: 9.367661952972412\n","[64,    18] loss: 1.1931817531585693, time: 9.898619413375854\n","[64,    19] loss: 1.0987815856933594, time: 10.445640563964844\n","[64,    20] loss: 1.1266337633132935, time: 11.003504753112793\n","[64,    21] loss: 1.1223740577697754, time: 11.569918870925903\n","[64,    22] loss: 1.1973832845687866, time: 12.12572956085205\n","[64,    23] loss: 0.9782341718673706, time: 12.692330837249756\n","[64,    24] loss: 1.3768393993377686, time: 13.247500896453857\n","[64,    25] loss: 1.2542134523391724, time: 13.785510540008545\n","[64,    26] loss: 1.105311632156372, time: 14.326587200164795\n","[64,    27] loss: 1.2056059837341309, time: 14.88550329208374\n","[64,    28] loss: 0.9261027574539185, time: 15.456336498260498\n","[64,    29] loss: 0.8856542110443115, time: 16.00042414665222\n","[64,    30] loss: 1.1765031814575195, time: 16.55566143989563\n","[64,    31] loss: 1.1276170015335083, time: 17.09792423248291\n","[64,    32] loss: 0.9405930638313293, time: 17.672722816467285\n","[64,    33] loss: 1.0188549757003784, time: 18.210782289505005\n","[64,    34] loss: 1.2502273321151733, time: 18.782071590423584\n","[64,    35] loss: 1.0709511041641235, time: 19.335541486740112\n","[64,    36] loss: 1.3631658554077148, time: 19.871057510375977\n","[64,    37] loss: 1.2146929502487183, time: 20.396453142166138\n","[64,    38] loss: 1.042471170425415, time: 20.950801610946655\n","[64,    39] loss: 1.1491379737854004, time: 21.505431413650513\n","[64,    40] loss: 1.2022035121917725, time: 22.05372428894043\n","[64,    41] loss: 1.2317590713500977, time: 22.597639322280884\n","[64,    42] loss: 1.2646275758743286, time: 23.1615309715271\n","[64,    43] loss: 1.2228670120239258, time: 23.71967601776123\n","[64,    44] loss: 1.045634388923645, time: 24.27488136291504\n","[64,    45] loss: 1.3907134532928467, time: 24.814440965652466\n","[64,    46] loss: 0.9727083444595337, time: 25.365827560424805\n","[64,    47] loss: 1.4100056886672974, time: 25.91851806640625\n","[64,    48] loss: 1.1119436025619507, time: 26.47800087928772\n","[64,    49] loss: 1.137434720993042, time: 27.02416157722473\n","[64,    50] loss: 1.4514340162277222, time: 27.199583530426025\n","\n","Evaluation: Average loss: 0.5935, Accuracy: 774/947 (81.732%)\n","\n","************************************************************\n","Total removed parameters: 501183.0\n","Take 14.213364816304745 % of active parameters\n","Total redistribution parameters: 3024686.0\n","Take: 603.5092970032903 % of removed parameters\n","Pruning rate: 0.1471196253376445\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.61 seconds.\n","\n","Total nonzero parameters:  3276827\n","Take 13.89075078957212 %\n","------------------------------------------------------------\n","[65,     1] loss: 0.8513067960739136, time: 0.5279788970947266\n","[65,     2] loss: 0.7919771671295166, time: 1.0713305473327637\n","[65,     3] loss: 1.0630695819854736, time: 1.615950107574463\n","[65,     4] loss: 1.163720965385437, time: 2.171487331390381\n","[65,     5] loss: 0.804567277431488, time: 2.740046739578247\n","[65,     6] loss: 1.3668930530548096, time: 3.294060707092285\n","[65,     7] loss: 1.1825014352798462, time: 3.84761381149292\n","[65,     8] loss: 1.1275570392608643, time: 4.3804931640625\n","[65,     9] loss: 1.098584771156311, time: 4.929105997085571\n","[65,    10] loss: 0.8350215554237366, time: 5.463779926300049\n","[65,    11] loss: 1.1911324262619019, time: 6.013593912124634\n","[65,    12] loss: 0.8436259627342224, time: 6.557119607925415\n","[65,    13] loss: 1.030903697013855, time: 7.123942852020264\n","[65,    14] loss: 0.9205999970436096, time: 7.663068056106567\n","[65,    15] loss: 1.2763370275497437, time: 8.225618362426758\n","[65,    16] loss: 1.1074275970458984, time: 8.776126146316528\n","[65,    17] loss: 1.175245761871338, time: 9.332433700561523\n","[65,    18] loss: 1.0114877223968506, time: 9.908448219299316\n","[65,    19] loss: 1.1519098281860352, time: 10.46746826171875\n","[65,    20] loss: 1.1616473197937012, time: 11.03429627418518\n","[65,    21] loss: 0.922400176525116, time: 11.57025146484375\n","[65,    22] loss: 0.9985074400901794, time: 12.112752199172974\n","[65,    23] loss: 1.2572287321090698, time: 12.660206079483032\n","[65,    24] loss: 1.178606629371643, time: 13.213258981704712\n","[65,    25] loss: 1.0816583633422852, time: 13.747409343719482\n","[65,    26] loss: 1.0540730953216553, time: 14.293042659759521\n","[65,    27] loss: 1.028355360031128, time: 14.83394169807434\n","[65,    28] loss: 1.0051199197769165, time: 15.368398904800415\n","[65,    29] loss: 1.1044219732284546, time: 15.910974979400635\n","[65,    30] loss: 1.1052261590957642, time: 16.45819067955017\n","[65,    31] loss: 0.9613519906997681, time: 16.992268562316895\n","[65,    32] loss: 0.8990197777748108, time: 17.520753145217896\n","[65,    33] loss: 1.3373216390609741, time: 18.06484842300415\n","[65,    34] loss: 0.8097006678581238, time: 18.599743366241455\n","[65,    35] loss: 1.182875633239746, time: 19.144509077072144\n","[65,    36] loss: 1.1896947622299194, time: 19.71234440803528\n","[65,    37] loss: 1.140251636505127, time: 20.249163150787354\n","[65,    38] loss: 0.8620177507400513, time: 20.78557515144348\n","[65,    39] loss: 1.1423063278198242, time: 21.327367305755615\n","[65,    40] loss: 1.0336459875106812, time: 21.889204740524292\n","[65,    41] loss: 0.9397726058959961, time: 22.444705724716187\n","[65,    42] loss: 1.173697829246521, time: 23.014482259750366\n","[65,    43] loss: 0.9458361268043518, time: 23.578566789627075\n","[65,    44] loss: 1.0567262172698975, time: 24.10110592842102\n","[65,    45] loss: 0.9031357765197754, time: 24.650762796401978\n","[65,    46] loss: 0.8825197815895081, time: 25.176230669021606\n","[65,    47] loss: 0.90090411901474, time: 25.693710327148438\n","[65,    48] loss: 1.070513129234314, time: 26.237669229507446\n","[65,    49] loss: 1.3040987253189087, time: 26.775071382522583\n","[65,    50] loss: 1.0459128618240356, time: 26.95429539680481\n","\n","Evaluation: Average loss: 0.7092, Accuracy: 739/947 (78.036%)\n","\n","************************************************************\n","Total removed parameters: 479969.0\n","Take 13.612785954327855 % of active parameters\n","Total redistribution parameters: 3046423.0\n","Take: 634.712450179074 % of removed parameters\n","Pruning rate: 0.14013735131446214\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.44 seconds.\n","\n","Total nonzero parameters:  3291276\n","Take 13.952001340229364 %\n","------------------------------------------------------------\n","[66,     1] loss: 1.1660858392715454, time: 0.5636246204376221\n","[66,     2] loss: 0.855058491230011, time: 1.1223118305206299\n","[66,     3] loss: 1.1557846069335938, time: 1.6532402038574219\n","[66,     4] loss: 0.8400750160217285, time: 2.18326473236084\n","[66,     5] loss: 1.4501631259918213, time: 2.7284224033355713\n","[66,     6] loss: 1.304144024848938, time: 3.270358085632324\n","[66,     7] loss: 1.1613883972167969, time: 3.8171803951263428\n","[66,     8] loss: 1.2101051807403564, time: 4.361562013626099\n","[66,     9] loss: 1.03780198097229, time: 4.898620843887329\n","[66,    10] loss: 1.099707841873169, time: 5.432196140289307\n","[66,    11] loss: 0.8005887269973755, time: 5.981394052505493\n","[66,    12] loss: 1.3384122848510742, time: 6.519556522369385\n","[66,    13] loss: 1.0054436922073364, time: 7.06348180770874\n","[66,    14] loss: 0.9357097744941711, time: 7.611646413803101\n","[66,    15] loss: 1.2354493141174316, time: 8.153846979141235\n","[66,    16] loss: 1.0114883184432983, time: 8.710593700408936\n","[66,    17] loss: 0.9726279377937317, time: 9.251405954360962\n","[66,    18] loss: 1.1331208944320679, time: 9.827650785446167\n","[66,    19] loss: 1.0851104259490967, time: 10.356122255325317\n","[66,    20] loss: 1.450817346572876, time: 10.893584251403809\n","[66,    21] loss: 1.206288456916809, time: 11.439332962036133\n","[66,    22] loss: 1.3933521509170532, time: 11.973369359970093\n","[66,    23] loss: 0.9752631783485413, time: 12.51283311843872\n","[66,    24] loss: 0.9194400906562805, time: 13.064246416091919\n","[66,    25] loss: 0.8245869874954224, time: 13.604937314987183\n","[66,    26] loss: 0.8371581435203552, time: 14.138951778411865\n","[66,    27] loss: 0.9808129072189331, time: 14.668187618255615\n","[66,    28] loss: 1.2570743560791016, time: 15.221639394760132\n","[66,    29] loss: 1.1395891904830933, time: 15.779213190078735\n","[66,    30] loss: 1.3123942613601685, time: 16.312663316726685\n","[66,    31] loss: 0.7926021218299866, time: 16.8605535030365\n","[66,    32] loss: 0.6627460718154907, time: 17.395760774612427\n","[66,    33] loss: 0.9195837378501892, time: 17.961263418197632\n","[66,    34] loss: 0.8371237516403198, time: 18.492304801940918\n","[66,    35] loss: 1.203246831893921, time: 19.07464027404785\n","[66,    36] loss: 1.1833068132400513, time: 19.618387699127197\n","[66,    37] loss: 1.084104061126709, time: 20.161647081375122\n","[66,    38] loss: 1.1415177583694458, time: 20.70360231399536\n","[66,    39] loss: 0.712254524230957, time: 21.2379789352417\n","[66,    40] loss: 0.9377522468566895, time: 21.79199194908142\n","[66,    41] loss: 1.2334150075912476, time: 22.333307027816772\n","[66,    42] loss: 1.0645322799682617, time: 22.873969554901123\n","[66,    43] loss: 1.3355638980865479, time: 23.42793583869934\n","[66,    44] loss: 0.8667768239974976, time: 23.983977794647217\n","[66,    45] loss: 1.0454838275909424, time: 24.52682113647461\n","[66,    46] loss: 1.2390214204788208, time: 25.08657693862915\n","[66,    47] loss: 0.9155497550964355, time: 25.63825297355652\n","[66,    48] loss: 1.4581871032714844, time: 26.186521768569946\n","[66,    49] loss: 1.0641628503799438, time: 26.73112392425537\n","[66,    50] loss: 1.0783905982971191, time: 26.913339376449585\n","\n","Evaluation: Average loss: 0.9406, Accuracy: 690/947 (72.862%)\n","\n","************************************************************\n","Total removed parameters: 456663.0\n","Take 12.949864904412214 % of active parameters\n","Total redistribution parameters: 3069892.0\n","Take: 672.2445216713419 % of removed parameters\n","Pruning rate: 0.13326596565982538\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.36 seconds.\n","\n","Total nonzero parameters:  3304029\n","Take 14.006062401377669 %\n","------------------------------------------------------------\n","[67,     1] loss: 1.1029243469238281, time: 0.5537209510803223\n","[67,     2] loss: 1.098958134651184, time: 1.1110351085662842\n","[67,     3] loss: 1.1201635599136353, time: 1.6538410186767578\n","[67,     4] loss: 1.2009745836257935, time: 2.2069451808929443\n","[67,     5] loss: 1.0157099962234497, time: 2.7226898670196533\n","[67,     6] loss: 1.0581941604614258, time: 3.2718160152435303\n","[67,     7] loss: 1.1500107049942017, time: 3.830596685409546\n","[67,     8] loss: 0.8175406455993652, time: 4.377430438995361\n","[67,     9] loss: 1.3335694074630737, time: 4.930492877960205\n","[67,    10] loss: 0.9990578293800354, time: 5.463898181915283\n","[67,    11] loss: 1.3054522275924683, time: 5.993421792984009\n","[67,    12] loss: 0.9170677661895752, time: 6.522153615951538\n","[67,    13] loss: 1.1500509977340698, time: 7.070963621139526\n","[67,    14] loss: 1.2927045822143555, time: 7.63421106338501\n","[67,    15] loss: 1.1324247121810913, time: 8.188918590545654\n","[67,    16] loss: 1.1776432991027832, time: 8.719419240951538\n","[67,    17] loss: 0.68998783826828, time: 9.254825592041016\n","[67,    18] loss: 0.8297975659370422, time: 9.794190168380737\n","[67,    19] loss: 0.9955472350120544, time: 10.315921306610107\n","[67,    20] loss: 1.1279349327087402, time: 10.858944416046143\n","[67,    21] loss: 0.8229491710662842, time: 11.392378330230713\n","[67,    22] loss: 0.8384796977043152, time: 11.955772638320923\n","[67,    23] loss: 1.1121033430099487, time: 12.499627351760864\n","[67,    24] loss: 1.0324089527130127, time: 13.027795314788818\n","[67,    25] loss: 1.2953799962997437, time: 13.570874691009521\n","[67,    26] loss: 0.7579541206359863, time: 14.092875003814697\n","[67,    27] loss: 0.882997989654541, time: 14.640310525894165\n","[67,    28] loss: 0.782829999923706, time: 15.169026136398315\n","[67,    29] loss: 1.5299365520477295, time: 15.71019458770752\n","[67,    30] loss: 0.9502969980239868, time: 16.263086557388306\n","[67,    31] loss: 1.0627048015594482, time: 16.808655500411987\n","[67,    32] loss: 1.0257794857025146, time: 17.34920644760132\n","[67,    33] loss: 0.9600118398666382, time: 17.895790338516235\n","[67,    34] loss: 0.9403093457221985, time: 18.46203327178955\n","[67,    35] loss: 1.160526990890503, time: 19.02683424949646\n","[67,    36] loss: 1.1087614297866821, time: 19.58037042617798\n","[67,    37] loss: 1.2562367916107178, time: 20.10737943649292\n","[67,    38] loss: 1.001261830329895, time: 20.64598560333252\n","[67,    39] loss: 1.0692040920257568, time: 21.19472908973694\n","[67,    40] loss: 1.2672635316848755, time: 21.739099979400635\n","[67,    41] loss: 1.0280364751815796, time: 22.264421939849854\n","[67,    42] loss: 0.9064592123031616, time: 22.813262939453125\n","[67,    43] loss: 0.9222656488418579, time: 23.361602783203125\n","[67,    44] loss: 1.0394675731658936, time: 23.886637926101685\n","[67,    45] loss: 1.7513971328735352, time: 24.438746690750122\n","[67,    46] loss: 1.122658133506775, time: 24.982747793197632\n","[67,    47] loss: 0.8346269130706787, time: 25.517669439315796\n","[67,    48] loss: 1.002425193786621, time: 26.046809673309326\n","[67,    49] loss: 0.9350072145462036, time: 26.591668367385864\n","[67,    50] loss: 1.5058763027191162, time: 26.76274847984314\n","\n","Evaluation: Average loss: 2.9917, Accuracy: 374/947 (39.493%)\n","\n","************************************************************\n","Total removed parameters: 433710.0\n","Take 12.298404533602907 % of active parameters\n","Total redistribution parameters: 3093494.0\n","Take: 713.2632404141016 % of removed parameters\n","Pruning rate: 0.12651224960178287\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.13 seconds.\n","\n","Total nonzero parameters:  3310032\n","Take 14.031509633407252 %\n","------------------------------------------------------------\n","[68,     1] loss: 1.3324286937713623, time: 0.5335342884063721\n","[68,     2] loss: 1.1092045307159424, time: 1.0893528461456299\n","[68,     3] loss: 1.4473345279693604, time: 1.6295397281646729\n","[68,     4] loss: 1.3227139711380005, time: 2.1786723136901855\n","[68,     5] loss: 1.1022708415985107, time: 2.7359073162078857\n","[68,     6] loss: 1.4851304292678833, time: 3.29054594039917\n","[68,     7] loss: 0.9621613621711731, time: 3.8292734622955322\n","[68,     8] loss: 1.1266530752182007, time: 4.371664762496948\n","[68,     9] loss: 0.9785901308059692, time: 4.8994386196136475\n","[68,    10] loss: 1.2231260538101196, time: 5.455787420272827\n","[68,    11] loss: 1.1465330123901367, time: 5.983281135559082\n","[68,    12] loss: 1.2016286849975586, time: 6.543551206588745\n","[68,    13] loss: 1.052556037902832, time: 7.064275026321411\n","[68,    14] loss: 1.211501955986023, time: 7.606578826904297\n","[68,    15] loss: 1.045875072479248, time: 8.14592170715332\n","[68,    16] loss: 1.1982624530792236, time: 8.683184146881104\n","[68,    17] loss: 0.9949269890785217, time: 9.224761486053467\n","[68,    18] loss: 0.941202700138092, time: 9.786524295806885\n","[68,    19] loss: 0.9597747325897217, time: 10.32966947555542\n","[68,    20] loss: 1.0592873096466064, time: 10.8769690990448\n","[68,    21] loss: 1.057565689086914, time: 11.404568672180176\n","[68,    22] loss: 0.8559415936470032, time: 11.939162254333496\n","[68,    23] loss: 1.213041067123413, time: 12.482861280441284\n","[68,    24] loss: 1.0232508182525635, time: 13.011766910552979\n","[68,    25] loss: 1.2155780792236328, time: 13.56152892112732\n","[68,    26] loss: 0.9941739439964294, time: 14.130699872970581\n","[68,    27] loss: 1.0952423810958862, time: 14.681980848312378\n","[68,    28] loss: 0.9862673878669739, time: 15.240054845809937\n","[68,    29] loss: 1.0260943174362183, time: 15.775800466537476\n","[68,    30] loss: 1.154458999633789, time: 16.3248291015625\n","[68,    31] loss: 1.0478110313415527, time: 16.854421377182007\n","[68,    32] loss: 1.4398274421691895, time: 17.3941969871521\n","[68,    33] loss: 0.7208254337310791, time: 17.925950527191162\n","[68,    34] loss: 0.8371220231056213, time: 18.466310501098633\n","[68,    35] loss: 0.8646172881126404, time: 18.99942684173584\n","[68,    36] loss: 1.4288569688796997, time: 19.53148865699768\n","[68,    37] loss: 0.8172475695610046, time: 20.074529886245728\n","[68,    38] loss: 1.0358304977416992, time: 20.6145281791687\n","[68,    39] loss: 0.9253731369972229, time: 21.15817904472351\n","[68,    40] loss: 1.2195591926574707, time: 21.707544565200806\n","[68,    41] loss: 0.9374651908874512, time: 22.255638599395752\n","[68,    42] loss: 1.0812889337539673, time: 22.780900716781616\n","[68,    43] loss: 0.9449300765991211, time: 23.334022521972656\n","[68,    44] loss: 1.084934949874878, time: 23.90224027633667\n","[68,    45] loss: 1.1874979734420776, time: 24.457435607910156\n","[68,    46] loss: 1.004167914390564, time: 25.012317657470703\n","[68,    47] loss: 1.203744888305664, time: 25.56539297103882\n","[68,    48] loss: 0.7996786236763, time: 26.11171841621399\n","[68,    49] loss: 1.3569985628128052, time: 26.68241262435913\n","[68,    50] loss: 0.8933461904525757, time: 26.853974103927612\n","\n","Evaluation: Average loss: 0.6110, Accuracy: 774/947 (81.732%)\n","\n","************************************************************\n","Total removed parameters: 411235.0\n","Take 11.658951396063284 % of active parameters\n","Total redistribution parameters: 3115569.0\n","Take: 757.6128004668864 % of removed parameters\n","Pruning rate: 0.1198828682426981\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.32 seconds.\n","\n","Total nonzero parameters:  3322843\n","Take 14.085816561531686 %\n","------------------------------------------------------------\n","[69,     1] loss: 1.5648118257522583, time: 0.5656886100769043\n","[69,     2] loss: 1.3418632745742798, time: 1.1047134399414062\n","[69,     3] loss: 0.7140247821807861, time: 1.6418259143829346\n","[69,     4] loss: 0.9483597278594971, time: 2.173506498336792\n","[69,     5] loss: 1.1798831224441528, time: 2.7229702472686768\n","[69,     6] loss: 1.1771553754806519, time: 3.287830114364624\n","[69,     7] loss: 1.503158688545227, time: 3.822476387023926\n","[69,     8] loss: 1.2317999601364136, time: 4.349805593490601\n","[69,     9] loss: 1.2861603498458862, time: 4.87917947769165\n","[69,    10] loss: 1.0606802701950073, time: 5.399831056594849\n","[69,    11] loss: 1.2754935026168823, time: 5.926513910293579\n","[69,    12] loss: 1.432265043258667, time: 6.458507299423218\n","[69,    13] loss: 1.2398924827575684, time: 6.990492343902588\n","[69,    14] loss: 1.1826468706130981, time: 7.545353651046753\n","[69,    15] loss: 0.9147828817367554, time: 8.08809518814087\n","[69,    16] loss: 1.2061840295791626, time: 8.64534616470337\n","[69,    17] loss: 0.9446134567260742, time: 9.206252574920654\n","[69,    18] loss: 0.966366171836853, time: 9.752250909805298\n","[69,    19] loss: 0.6638425588607788, time: 10.2959885597229\n","[69,    20] loss: 1.0472919940948486, time: 10.851243495941162\n","[69,    21] loss: 0.8547425270080566, time: 11.400796175003052\n","[69,    22] loss: 0.9968240261077881, time: 11.942996501922607\n","[69,    23] loss: 1.1923333406448364, time: 12.507487773895264\n","[69,    24] loss: 0.8832560777664185, time: 13.05226731300354\n","[69,    25] loss: 1.1216444969177246, time: 13.608303546905518\n","[69,    26] loss: 0.9819638729095459, time: 14.141782522201538\n","[69,    27] loss: 1.208732008934021, time: 14.706075668334961\n","[69,    28] loss: 1.05538809299469, time: 15.27788782119751\n","[69,    29] loss: 1.3315454721450806, time: 15.818206310272217\n","[69,    30] loss: 0.8779169321060181, time: 16.350423097610474\n","[69,    31] loss: 0.9203112125396729, time: 16.895123958587646\n","[69,    32] loss: 1.016530990600586, time: 17.430328607559204\n","[69,    33] loss: 0.8542895317077637, time: 17.98457360267639\n","[69,    34] loss: 1.1769793033599854, time: 18.539941549301147\n","[69,    35] loss: 0.9018505811691284, time: 19.098480463027954\n","[69,    36] loss: 1.2670410871505737, time: 19.616392374038696\n","[69,    37] loss: 0.9314881563186646, time: 20.19144916534424\n","[69,    38] loss: 0.9301124811172485, time: 20.73704433441162\n","[69,    39] loss: 1.248558521270752, time: 21.27808117866516\n","[69,    40] loss: 1.1420376300811768, time: 21.83029270172119\n","[69,    41] loss: 0.7290440201759338, time: 22.369775772094727\n","[69,    42] loss: 0.8555300235748291, time: 22.909386157989502\n","[69,    43] loss: 1.3235955238342285, time: 23.49365496635437\n","[69,    44] loss: 1.1874773502349854, time: 24.045642375946045\n","[69,    45] loss: 1.110726237297058, time: 24.603257417678833\n","[69,    46] loss: 1.1750938892364502, time: 25.15428876876831\n","[69,    47] loss: 0.9893855452537537, time: 25.711723566055298\n","[69,    48] loss: 0.7287315726280212, time: 26.273143768310547\n","[69,    49] loss: 0.8481301665306091, time: 26.813011407852173\n","[69,    50] loss: 0.9769880175590515, time: 26.982969522476196\n","\n","Evaluation: Average loss: 1.4043, Accuracy: 590/947 (62.302%)\n","\n","************************************************************\n","Total removed parameters: 385409.0\n","Take 10.927995998643532 % of active parameters\n","Total redistribution parameters: 3140880.0\n","Take: 814.9472378693803 % of removed parameters\n","Pruning rate: 0.11338436398159749\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.45 seconds.\n","\n","Total nonzero parameters:  3338170\n","Take 14.150789029517263 %\n","------------------------------------------------------------\n","[70,     1] loss: 0.8932676911354065, time: 0.5476675033569336\n","[70,     2] loss: 0.9481247067451477, time: 1.095428705215454\n","[70,     3] loss: 0.9261457920074463, time: 1.6478271484375\n","[70,     4] loss: 1.0628865957260132, time: 2.2008399963378906\n","[70,     5] loss: 0.821918785572052, time: 2.744654893875122\n","[70,     6] loss: 1.33450186252594, time: 3.3008992671966553\n","[70,     7] loss: 0.8801367878913879, time: 3.8494839668273926\n","[70,     8] loss: 0.9069076180458069, time: 4.383286237716675\n","[70,     9] loss: 0.8600524067878723, time: 4.928293704986572\n","[70,    10] loss: 1.3093430995941162, time: 5.460683584213257\n","[70,    11] loss: 0.7373573184013367, time: 5.9999003410339355\n","[70,    12] loss: 0.7944074273109436, time: 6.581772089004517\n","[70,    13] loss: 1.2498483657836914, time: 7.130544662475586\n","[70,    14] loss: 0.8601369857788086, time: 7.666665077209473\n","[70,    15] loss: 0.9633715748786926, time: 8.202356815338135\n","[70,    16] loss: 0.9806349277496338, time: 8.765249252319336\n","[70,    17] loss: 1.093422770500183, time: 9.318308115005493\n","[70,    18] loss: 0.8676910400390625, time: 9.8668954372406\n","[70,    19] loss: 0.7363035082817078, time: 10.40068531036377\n","[70,    20] loss: 1.203663945198059, time: 10.951046466827393\n","[70,    21] loss: 1.3250147104263306, time: 11.50326418876648\n","[70,    22] loss: 0.9099637866020203, time: 12.032387018203735\n","[70,    23] loss: 0.9690068364143372, time: 12.57834267616272\n","[70,    24] loss: 1.2342520952224731, time: 13.150319337844849\n","[70,    25] loss: 1.0318959951400757, time: 13.697280645370483\n","[70,    26] loss: 0.9678748250007629, time: 14.240303993225098\n","[70,    27] loss: 0.8088524341583252, time: 14.815014839172363\n","[70,    28] loss: 1.2673619985580444, time: 15.383540630340576\n","[70,    29] loss: 1.1468521356582642, time: 15.947258472442627\n","[70,    30] loss: 0.9654459357261658, time: 16.48735499382019\n","[70,    31] loss: 0.9298107028007507, time: 17.035032510757446\n","[70,    32] loss: 0.780170738697052, time: 17.57405948638916\n","[70,    33] loss: 0.8326172232627869, time: 18.105672597885132\n","[70,    34] loss: 0.9168888330459595, time: 18.643022775650024\n","[70,    35] loss: 0.8811255097389221, time: 19.20331335067749\n","[70,    36] loss: 1.0625371932983398, time: 19.7699556350708\n","[70,    37] loss: 1.0610568523406982, time: 20.31065607070923\n","[70,    38] loss: 0.9030212759971619, time: 20.867055416107178\n","[70,    39] loss: 1.0823235511779785, time: 21.407620191574097\n","[70,    40] loss: 0.8548104763031006, time: 21.95845127105713\n","[70,    41] loss: 1.1795611381530762, time: 22.48997926712036\n","[70,    42] loss: 0.8857986927032471, time: 23.034714221954346\n","[70,    43] loss: 1.094900131225586, time: 23.570189952850342\n","[70,    44] loss: 1.5686484575271606, time: 24.11926817893982\n","[70,    45] loss: 1.0167640447616577, time: 24.685807943344116\n","[70,    46] loss: 1.0464215278625488, time: 25.2279052734375\n","[70,    47] loss: 1.1165544986724854, time: 25.808042764663696\n","[70,    48] loss: 1.0335639715194702, time: 26.366870880126953\n","[70,    49] loss: 0.9773988127708435, time: 26.898875951766968\n","[70,    50] loss: 1.6785712242126465, time: 27.0792179107666\n","\n","Evaluation: Average loss: 0.8696, Accuracy: 714/947 (75.396%)\n","\n","************************************************************\n","Total removed parameters: 367361.0\n","Take 10.417779144023646 % of active parameters\n","Total redistribution parameters: 3158904.0\n","Take: 859.8909519518947 % of removed parameters\n","Pruning rate: 0.10702315005761272\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.62 seconds.\n","\n","Total nonzero parameters:  3352077\n","Take 14.209741995673419 %\n","------------------------------------------------------------\n","[71,     1] loss: 1.1779484748840332, time: 0.6091873645782471\n","[71,     2] loss: 1.278900146484375, time: 1.2132256031036377\n","[71,     3] loss: 1.2264440059661865, time: 1.754936933517456\n","[71,     4] loss: 1.4031901359558105, time: 2.3034543991088867\n","[71,     5] loss: 1.528432846069336, time: 2.8560690879821777\n","[71,     6] loss: 0.8918923139572144, time: 3.384737730026245\n","[71,     7] loss: 1.075311541557312, time: 3.9218287467956543\n","[71,     8] loss: 1.2288819551467896, time: 4.475936412811279\n","[71,     9] loss: 0.9746294617652893, time: 5.018865346908569\n","[71,    10] loss: 1.1823375225067139, time: 5.559609889984131\n","[71,    11] loss: 1.040588617324829, time: 6.1166815757751465\n","[71,    12] loss: 0.899390459060669, time: 6.64648699760437\n","[71,    13] loss: 1.3253577947616577, time: 7.193208932876587\n","[71,    14] loss: 1.175505518913269, time: 7.743733644485474\n","[71,    15] loss: 0.9207993745803833, time: 8.304561138153076\n","[71,    16] loss: 1.1601096391677856, time: 8.846168994903564\n","[71,    17] loss: 1.2926568984985352, time: 9.386872291564941\n","[71,    18] loss: 0.9092962741851807, time: 9.91494107246399\n","[71,    19] loss: 1.1637351512908936, time: 10.470370292663574\n","[71,    20] loss: 0.890048086643219, time: 11.004473209381104\n","[71,    21] loss: 1.1549196243286133, time: 11.55044436454773\n","[71,    22] loss: 1.0101401805877686, time: 12.082136869430542\n","[71,    23] loss: 1.2691113948822021, time: 12.62938904762268\n","[71,    24] loss: 1.0353107452392578, time: 13.187895774841309\n","[71,    25] loss: 0.9105499386787415, time: 13.732816696166992\n","[71,    26] loss: 1.320342779159546, time: 14.266800165176392\n","[71,    27] loss: 1.0762441158294678, time: 14.816351175308228\n","[71,    28] loss: 1.1359574794769287, time: 15.37418246269226\n","[71,    29] loss: 1.2109124660491943, time: 15.957218408584595\n","[71,    30] loss: 1.1458402872085571, time: 16.524794816970825\n","[71,    31] loss: 1.1121209859848022, time: 17.072511672973633\n","[71,    32] loss: 1.2574446201324463, time: 17.63940978050232\n","[71,    33] loss: 1.1683791875839233, time: 18.201629161834717\n","[71,    34] loss: 1.1915956735610962, time: 18.76759171485901\n","[71,    35] loss: 0.9713969826698303, time: 19.346115589141846\n","[71,    36] loss: 0.8356882929801941, time: 19.89343762397766\n","[71,    37] loss: 0.9586546421051025, time: 20.448105096817017\n","[71,    38] loss: 1.1284503936767578, time: 21.009664297103882\n","[71,    39] loss: 0.9904593229293823, time: 21.552175760269165\n","[71,    40] loss: 0.89113849401474, time: 22.101489067077637\n","[71,    41] loss: 1.0965619087219238, time: 22.67599129676819\n","[71,    42] loss: 1.153247356414795, time: 23.260342121124268\n","[71,    43] loss: 1.0547107458114624, time: 23.81645131111145\n","[71,    44] loss: 1.15280282497406, time: 24.388406991958618\n","[71,    45] loss: 1.0248854160308838, time: 24.92839741706848\n","[71,    46] loss: 1.046223759651184, time: 25.49312686920166\n","[71,    47] loss: 1.1027966737747192, time: 26.055822372436523\n","[71,    48] loss: 0.9991611242294312, time: 26.592365503311157\n","[71,    49] loss: 1.1158511638641357, time: 27.147764444351196\n","[71,    50] loss: 1.0495433807373047, time: 27.323326587677002\n","\n","Evaluation: Average loss: 0.7440, Accuracy: 721/947 (76.135%)\n","\n","************************************************************\n","Total removed parameters: 346117.0\n","Take 9.815399580008876 % of active parameters\n","Total redistribution parameters: 3180447.0\n","Take: 918.8936111199392 % of removed parameters\n","Pruning rate: 0.10080550422088823\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.78 seconds.\n","\n","Total nonzero parameters:  3363701\n","Take 14.259017128958757 %\n","------------------------------------------------------------\n","[72,     1] loss: 0.9708563089370728, time: 0.5413577556610107\n","[72,     2] loss: 1.0965142250061035, time: 1.0899875164031982\n","[72,     3] loss: 1.2127379179000854, time: 1.652611255645752\n","[72,     4] loss: 0.8784002661705017, time: 2.196749448776245\n","[72,     5] loss: 1.1512224674224854, time: 2.7406253814697266\n","[72,     6] loss: 1.1134066581726074, time: 3.295372486114502\n","[72,     7] loss: 0.8317522406578064, time: 3.830803394317627\n","[72,     8] loss: 0.8605673909187317, time: 4.390197038650513\n","[72,     9] loss: 0.8589217662811279, time: 4.946828126907349\n","[72,    10] loss: 0.9636546969413757, time: 5.506437540054321\n","[72,    11] loss: 1.2137726545333862, time: 6.0596208572387695\n","[72,    12] loss: 0.9637861847877502, time: 6.60013747215271\n","[72,    13] loss: 1.0156981945037842, time: 7.155099391937256\n","[72,    14] loss: 0.9230064153671265, time: 7.716440916061401\n","[72,    15] loss: 1.2553315162658691, time: 8.229075908660889\n","[72,    16] loss: 0.91179358959198, time: 8.781450271606445\n","[72,    17] loss: 1.1358239650726318, time: 9.353858232498169\n","[72,    18] loss: 1.0381962060928345, time: 9.929332733154297\n","[72,    19] loss: 0.8672801852226257, time: 10.47525954246521\n","[72,    20] loss: 0.9701022505760193, time: 11.009369850158691\n","[72,    21] loss: 1.0811923742294312, time: 11.560458660125732\n","[72,    22] loss: 1.3666669130325317, time: 12.11203145980835\n","[72,    23] loss: 0.9174898862838745, time: 12.677476644515991\n","[72,    24] loss: 1.1047992706298828, time: 13.2152099609375\n","[72,    25] loss: 0.8579837083816528, time: 13.75326657295227\n","[72,    26] loss: 1.0719293355941772, time: 14.317025423049927\n","[72,    27] loss: 0.9319823980331421, time: 14.882835388183594\n","[72,    28] loss: 1.0335211753845215, time: 15.466678380966187\n","[72,    29] loss: 0.8284708857536316, time: 16.035699129104614\n","[72,    30] loss: 0.6934101581573486, time: 16.605295658111572\n","[72,    31] loss: 1.1578972339630127, time: 17.156373262405396\n","[72,    32] loss: 1.1643471717834473, time: 17.706716060638428\n","[72,    33] loss: 0.9395242929458618, time: 18.265848875045776\n","[72,    34] loss: 0.9327103495597839, time: 18.84859871864319\n","[72,    35] loss: 0.6620944142341614, time: 19.389559268951416\n","[72,    36] loss: 1.1272300481796265, time: 19.957603693008423\n","[72,    37] loss: 1.1372771263122559, time: 20.531365394592285\n","[72,    38] loss: 1.144043207168579, time: 21.08168601989746\n","[72,    39] loss: 1.093355417251587, time: 21.659749269485474\n","[72,    40] loss: 1.2220966815948486, time: 22.193995714187622\n","[72,    41] loss: 1.1018586158752441, time: 22.745540618896484\n","[72,    42] loss: 0.9724290370941162, time: 23.280136823654175\n","[72,    43] loss: 0.9408695101737976, time: 23.829905033111572\n","[72,    44] loss: 0.9420687556266785, time: 24.3538818359375\n","[72,    45] loss: 1.2364431619644165, time: 24.90908169746399\n","[72,    46] loss: 0.7896559238433838, time: 25.454995155334473\n","[72,    47] loss: 0.8420548439025879, time: 26.009851932525635\n","[72,    48] loss: 1.1956390142440796, time: 26.590261697769165\n","[72,    49] loss: 0.7026691436767578, time: 27.147899866104126\n","[72,    50] loss: 1.7280540466308594, time: 27.337618112564087\n","\n","Evaluation: Average loss: 1.1467, Accuracy: 612/947 (64.625%)\n","\n","************************************************************\n","Total removed parameters: 325417.0\n","Take 9.227593771160825 % of active parameters\n","Total redistribution parameters: 3200985.0\n","Take: 983.656354769419 % of removed parameters\n","Pruning rate: 0.09473756253719914\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.72 seconds.\n","\n","Total nonzero parameters:  3374439\n","Take 14.304536432229394 %\n","------------------------------------------------------------\n","[73,     1] loss: 0.9052988290786743, time: 0.5429489612579346\n","[73,     2] loss: 1.2364345788955688, time: 1.1127188205718994\n","[73,     3] loss: 1.1664947271347046, time: 1.6513774394989014\n","[73,     4] loss: 1.0494608879089355, time: 2.1923599243164062\n","[73,     5] loss: 0.7346048951148987, time: 2.7282354831695557\n","[73,     6] loss: 1.0193958282470703, time: 3.2707278728485107\n","[73,     7] loss: 1.1735984086990356, time: 3.8241026401519775\n","[73,     8] loss: 0.9854544401168823, time: 4.352097511291504\n","[73,     9] loss: 0.964877188205719, time: 4.874363899230957\n","[73,    10] loss: 0.9334017038345337, time: 5.403810262680054\n","[73,    11] loss: 1.1519176959991455, time: 5.9344117641448975\n","[73,    12] loss: 1.1427266597747803, time: 6.454484224319458\n","[73,    13] loss: 0.9415966868400574, time: 6.983802318572998\n","[73,    14] loss: 0.9131299257278442, time: 7.513911962509155\n","[73,    15] loss: 0.8877649307250977, time: 8.05667757987976\n","[73,    16] loss: 1.3482972383499146, time: 8.61296272277832\n","[73,    17] loss: 1.0841338634490967, time: 9.186322927474976\n","[73,    18] loss: 1.0056871175765991, time: 9.726262092590332\n","[73,    19] loss: 0.8085542917251587, time: 10.272085189819336\n","[73,    20] loss: 0.9195823073387146, time: 10.805840730667114\n","[73,    21] loss: 0.8603228330612183, time: 11.368460893630981\n","[73,    22] loss: 0.9329646229743958, time: 11.920848846435547\n","[73,    23] loss: 1.2022674083709717, time: 12.48430061340332\n","[73,    24] loss: 0.9861094951629639, time: 13.026485204696655\n","[73,    25] loss: 0.7275552153587341, time: 13.560077428817749\n","[73,    26] loss: 0.8465043306350708, time: 14.100549697875977\n","[73,    27] loss: 0.775386393070221, time: 14.644095182418823\n","[73,    28] loss: 0.9939842820167542, time: 15.18342661857605\n","[73,    29] loss: 1.1788511276245117, time: 15.74945616722107\n","[73,    30] loss: 0.9864814281463623, time: 16.280750036239624\n","[73,    31] loss: 0.9447358846664429, time: 16.800975799560547\n","[73,    32] loss: 1.3012230396270752, time: 17.36314344406128\n","[73,    33] loss: 1.3848152160644531, time: 17.916000604629517\n","[73,    34] loss: 1.0247480869293213, time: 18.485189199447632\n","[73,    35] loss: 0.8393835425376892, time: 19.035703659057617\n","[73,    36] loss: 1.1509989500045776, time: 19.567755222320557\n","[73,    37] loss: 0.8669494390487671, time: 20.113141536712646\n","[73,    38] loss: 0.9225983023643494, time: 20.65184497833252\n","[73,    39] loss: 0.73483806848526, time: 21.214174270629883\n","[73,    40] loss: 1.0990711450576782, time: 21.78456425666809\n","[73,    41] loss: 1.0183298587799072, time: 22.349138259887695\n","[73,    42] loss: 1.2189724445343018, time: 22.90433382987976\n","[73,    43] loss: 1.0436310768127441, time: 23.459505319595337\n","[73,    44] loss: 1.0001939535140991, time: 23.984434604644775\n","[73,    45] loss: 1.1304258108139038, time: 24.533066034317017\n","[73,    46] loss: 0.9090357422828674, time: 25.062493562698364\n","[73,    47] loss: 1.1639314889907837, time: 25.615695476531982\n","[73,    48] loss: 1.2232075929641724, time: 26.145637035369873\n","[73,    49] loss: 0.8848679661750793, time: 26.69249725341797\n","[73,    50] loss: 1.1249550580978394, time: 26.86014485359192\n","\n","Evaluation: Average loss: 0.7559, Accuracy: 732/947 (77.297%)\n","\n","************************************************************\n","Total removed parameters: 305200.0\n","Take 8.654713784758515 % of active parameters\n","Total redistribution parameters: 3221653.0\n","Take: 1055.5874836173002 % of removed parameters\n","Pruning rate: 0.08882531333239606\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.67 seconds.\n","\n","Total nonzero parameters:  3387125\n","Take 14.35831347462941 %\n","------------------------------------------------------------\n","[74,     1] loss: 1.4521074295043945, time: 0.5547802448272705\n","[74,     2] loss: 1.2413029670715332, time: 1.1093478202819824\n","[74,     3] loss: 1.152861475944519, time: 1.6652553081512451\n","[74,     4] loss: 0.9277967214584351, time: 2.2134439945220947\n","[74,     5] loss: 0.9928451180458069, time: 2.7799971103668213\n","[74,     6] loss: 1.1949479579925537, time: 3.33029842376709\n","[74,     7] loss: 1.0166159868240356, time: 3.862340211868286\n","[74,     8] loss: 0.9034913778305054, time: 4.400242328643799\n","[74,     9] loss: 1.0453828573226929, time: 4.945580720901489\n","[74,    10] loss: 1.1020991802215576, time: 5.50139045715332\n","[74,    11] loss: 1.0938775539398193, time: 6.037109136581421\n","[74,    12] loss: 0.7436807155609131, time: 6.587464094161987\n","[74,    13] loss: 0.9220473766326904, time: 7.128300666809082\n","[74,    14] loss: 0.8607162833213806, time: 7.686458587646484\n","[74,    15] loss: 0.9703888893127441, time: 8.221433877944946\n","[74,    16] loss: 1.1878607273101807, time: 8.778871774673462\n","[74,    17] loss: 1.1805529594421387, time: 9.335309982299805\n","[74,    18] loss: 1.4102177619934082, time: 9.866532325744629\n","[74,    19] loss: 1.0812252759933472, time: 10.390671968460083\n","[74,    20] loss: 0.9605575799942017, time: 10.933866739273071\n","[74,    21] loss: 1.0986056327819824, time: 11.47797417640686\n","[74,    22] loss: 1.2188289165496826, time: 12.012253999710083\n","[74,    23] loss: 1.3795719146728516, time: 12.569302082061768\n","[74,    24] loss: 1.0976953506469727, time: 13.117084741592407\n","[74,    25] loss: 1.153931736946106, time: 13.659178733825684\n","[74,    26] loss: 1.1184934377670288, time: 14.198998928070068\n","[74,    27] loss: 0.8882330656051636, time: 14.73938798904419\n","[74,    28] loss: 1.0730034112930298, time: 15.260811567306519\n","[74,    29] loss: 1.1363584995269775, time: 15.798646688461304\n","[74,    30] loss: 1.00698721408844, time: 16.33420753479004\n","[74,    31] loss: 1.147468090057373, time: 16.866158962249756\n","[74,    32] loss: 0.8395522832870483, time: 17.403929471969604\n","[74,    33] loss: 1.2094852924346924, time: 17.944597482681274\n","[74,    34] loss: 1.0811374187469482, time: 18.48004722595215\n","[74,    35] loss: 1.0645631551742554, time: 19.026738166809082\n","[74,    36] loss: 1.012192964553833, time: 19.54989743232727\n","[74,    37] loss: 1.1513605117797852, time: 20.086007118225098\n","[74,    38] loss: 0.9095679521560669, time: 20.61162519454956\n","[74,    39] loss: 0.8514752388000488, time: 21.135087490081787\n","[74,    40] loss: 1.1636065244674683, time: 21.679277896881104\n","[74,    41] loss: 1.0296655893325806, time: 22.22493290901184\n","[74,    42] loss: 0.9445551633834839, time: 22.79609179496765\n","[74,    43] loss: 1.26533842086792, time: 23.338202238082886\n","[74,    44] loss: 0.9409202933311462, time: 23.88481903076172\n","[74,    45] loss: 0.7544900178909302, time: 24.47724223136902\n","[74,    46] loss: 1.007006287574768, time: 25.018341541290283\n","[74,    47] loss: 0.9991918802261353, time: 25.55415439605713\n","[74,    48] loss: 1.237354040145874, time: 26.099714040756226\n","[74,    49] loss: 0.8049247860908508, time: 26.64059567451477\n","[74,    50] loss: 1.074889898300171, time: 26.807515144348145\n","\n","Evaluation: Average loss: 0.7826, Accuracy: 727/947 (76.769%)\n","\n","************************************************************\n","Total removed parameters: 285541.0\n","Take 8.096197941904581 % of active parameters\n","Total redistribution parameters: 3241628.0\n","Take: 1135.2583341796799 % of removed parameters\n","Pruning rate: 0.08307459128264937\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.32 seconds.\n","\n","Total nonzero parameters:  3398860\n","Take 14.408059146438031 %\n","------------------------------------------------------------\n","[75,     1] loss: 1.167014479637146, time: 0.5584311485290527\n","[75,     2] loss: 1.1591262817382812, time: 1.128279447555542\n","[75,     3] loss: 1.112011432647705, time: 1.6721949577331543\n","[75,     4] loss: 0.9018633961677551, time: 2.2095978260040283\n","[75,     5] loss: 1.1496275663375854, time: 2.741074323654175\n","[75,     6] loss: 1.0463613271713257, time: 3.2840046882629395\n","[75,     7] loss: 1.0052298307418823, time: 3.834545612335205\n","[75,     8] loss: 1.0517683029174805, time: 4.36577033996582\n","[75,     9] loss: 1.261925220489502, time: 4.911161422729492\n","[75,    10] loss: 0.8455410599708557, time: 5.450816869735718\n","[75,    11] loss: 1.0095393657684326, time: 6.020092487335205\n","[75,    12] loss: 1.0064332485198975, time: 6.5530102252960205\n","[75,    13] loss: 0.923746645450592, time: 7.093714475631714\n","[75,    14] loss: 1.0585339069366455, time: 7.634274244308472\n","[75,    15] loss: 0.9529725909233093, time: 8.182615995407104\n","[75,    16] loss: 0.9407857656478882, time: 8.73166561126709\n","[75,    17] loss: 1.0420445203781128, time: 9.279810905456543\n","[75,    18] loss: 0.8014994859695435, time: 9.844744205474854\n","[75,    19] loss: 1.0012056827545166, time: 10.390648126602173\n","[75,    20] loss: 1.199371576309204, time: 10.917664051055908\n","[75,    21] loss: 1.1650854349136353, time: 11.45761752128601\n","[75,    22] loss: 1.142609715461731, time: 12.007506132125854\n","[75,    23] loss: 1.0810387134552002, time: 12.563915967941284\n","[75,    24] loss: 0.9886069297790527, time: 13.102897644042969\n","[75,    25] loss: 0.8233789205551147, time: 13.654548645019531\n","[75,    26] loss: 1.033402919769287, time: 14.198868989944458\n","[75,    27] loss: 1.1006407737731934, time: 14.73517656326294\n","[75,    28] loss: 1.0059958696365356, time: 15.298133373260498\n","[75,    29] loss: 1.229030728340149, time: 15.833244323730469\n","[75,    30] loss: 0.8521990776062012, time: 16.378206491470337\n","[75,    31] loss: 0.9426320195198059, time: 16.889461278915405\n","[75,    32] loss: 0.7820562124252319, time: 17.412589073181152\n","[75,    33] loss: 0.8436197638511658, time: 17.947553157806396\n","[75,    34] loss: 0.8036527633666992, time: 18.489482164382935\n","[75,    35] loss: 0.9057133197784424, time: 19.023420095443726\n","[75,    36] loss: 0.7237929105758667, time: 19.569922924041748\n","[75,    37] loss: 0.8033590912818909, time: 20.110624313354492\n","[75,    38] loss: 0.9932987689971924, time: 20.648173093795776\n","[75,    39] loss: 1.3130829334259033, time: 21.178234815597534\n","[75,    40] loss: 0.6909171342849731, time: 21.70050072669983\n","[75,    41] loss: 1.0154778957366943, time: 22.22362446784973\n","[75,    42] loss: 0.6494225263595581, time: 22.781436920166016\n","[75,    43] loss: 1.0211251974105835, time: 23.349196434020996\n","[75,    44] loss: 1.0966309309005737, time: 23.88210368156433\n","[75,    45] loss: 1.235398530960083, time: 24.4234356880188\n","[75,    46] loss: 0.7847018241882324, time: 24.962347269058228\n","[75,    47] loss: 1.1804362535476685, time: 25.520461320877075\n","[75,    48] loss: 1.0685992240905762, time: 26.079397916793823\n","[75,    49] loss: 0.7373449802398682, time: 26.635835647583008\n","[75,    50] loss: 0.9326650500297546, time: 26.804437398910522\n","\n","Evaluation: Average loss: 0.7152, Accuracy: 733/947 (77.402%)\n","\n","************************************************************\n","Total removed parameters: 265557.0\n","Take 7.528899239021436 % of active parameters\n","Total redistribution parameters: 3260689.0\n","Take: 1227.8678400494057 % of removed parameters\n","Pruning rate: 0.07749107165632935\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.30 seconds.\n","\n","Total nonzero parameters:  3410556\n","Take 14.457639493900635 %\n","------------------------------------------------------------\n","[76,     1] loss: 0.994001030921936, time: 0.5439939498901367\n","[76,     2] loss: 0.9032451510429382, time: 1.0717058181762695\n","[76,     3] loss: 0.961466372013092, time: 1.618619441986084\n","[76,     4] loss: 1.0275033712387085, time: 2.1595120429992676\n","[76,     5] loss: 0.9388813972473145, time: 2.704240083694458\n","[76,     6] loss: 1.172023892402649, time: 3.2486555576324463\n","[76,     7] loss: 0.9317561984062195, time: 3.7951223850250244\n","[76,     8] loss: 0.909538984298706, time: 4.3169426918029785\n","[76,     9] loss: 0.8964331150054932, time: 4.845068454742432\n","[76,    10] loss: 1.0485610961914062, time: 5.37907075881958\n","[76,    11] loss: 0.897650957107544, time: 5.924211740493774\n","[76,    12] loss: 1.0393511056900024, time: 6.468709945678711\n","[76,    13] loss: 0.9358793497085571, time: 7.028624534606934\n","[76,    14] loss: 1.0890543460845947, time: 7.54980731010437\n","[76,    15] loss: 1.0348505973815918, time: 8.11478328704834\n","[76,    16] loss: 0.8229549527168274, time: 8.654614686965942\n","[76,    17] loss: 0.9486899971961975, time: 9.174317836761475\n","[76,    18] loss: 1.2851195335388184, time: 9.718826293945312\n","[76,    19] loss: 0.9911743402481079, time: 10.254164218902588\n","[76,    20] loss: 1.0166059732437134, time: 10.795277833938599\n","[76,    21] loss: 0.8756139278411865, time: 11.338647603988647\n","[76,    22] loss: 0.8871961236000061, time: 11.87779450416565\n","[76,    23] loss: 1.1116653680801392, time: 12.425832986831665\n","[76,    24] loss: 1.0500229597091675, time: 12.979755640029907\n","[76,    25] loss: 0.7950742244720459, time: 13.503243684768677\n","[76,    26] loss: 0.8623116612434387, time: 14.046744346618652\n","[76,    27] loss: 1.103482723236084, time: 14.57134222984314\n","[76,    28] loss: 1.0291845798492432, time: 15.092637538909912\n","[76,    29] loss: 0.6671146750450134, time: 15.655514478683472\n","[76,    30] loss: 1.1062393188476562, time: 16.210472345352173\n","[76,    31] loss: 0.7540544271469116, time: 16.748449087142944\n","[76,    32] loss: 1.2266100645065308, time: 17.286568880081177\n","[76,    33] loss: 0.919914722442627, time: 17.806190252304077\n","[76,    34] loss: 0.8962442874908447, time: 18.338587045669556\n","[76,    35] loss: 1.1410036087036133, time: 18.87558937072754\n","[76,    36] loss: 1.1334227323532104, time: 19.399746417999268\n","[76,    37] loss: 0.9155070781707764, time: 19.948222160339355\n","[76,    38] loss: 0.8875468969345093, time: 20.489951610565186\n","[76,    39] loss: 0.867485761642456, time: 21.029274940490723\n","[76,    40] loss: 0.8298681974411011, time: 21.56358814239502\n","[76,    41] loss: 0.9692015647888184, time: 22.110881328582764\n","[76,    42] loss: 1.2612124681472778, time: 22.630423069000244\n","[76,    43] loss: 1.0095897912979126, time: 23.175981998443604\n","[76,    44] loss: 0.995955228805542, time: 23.726666688919067\n","[76,    45] loss: 0.8585198521614075, time: 24.277274131774902\n","[76,    46] loss: 0.9846773147583008, time: 24.813268899917603\n","[76,    47] loss: 0.913951575756073, time: 25.361308574676514\n","[76,    48] loss: 1.0150641202926636, time: 25.89159369468689\n","[76,    49] loss: 0.9772371649742126, time: 26.41718602180481\n","[76,    50] loss: 1.1088969707489014, time: 26.58870005607605\n","\n","Evaluation: Average loss: 0.8958, Accuracy: 703/947 (74.234%)\n","\n","************************************************************\n","Total removed parameters: 247754.0\n","Take 7.025998753348461 % of active parameters\n","Total redistribution parameters: 3278752.0\n","Take: 1323.3901369907246 % of removed parameters\n","Pruning rate: 0.07208026471320053\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 31.99 seconds.\n","\n","Total nonzero parameters:  3418453\n","Take 14.49111555442664 %\n","------------------------------------------------------------\n","[77,     1] loss: 0.910860538482666, time: 0.5488913059234619\n","[77,     2] loss: 0.7557410001754761, time: 1.0689074993133545\n","[77,     3] loss: 1.3451130390167236, time: 1.6118016242980957\n","[77,     4] loss: 0.7702335119247437, time: 2.1665608882904053\n","[77,     5] loss: 1.2571552991867065, time: 2.7190980911254883\n","[77,     6] loss: 0.7164789438247681, time: 3.2691569328308105\n","[77,     7] loss: 1.0802181959152222, time: 3.8270721435546875\n","[77,     8] loss: 1.27358877658844, time: 4.363168239593506\n","[77,     9] loss: 1.0508824586868286, time: 4.892797231674194\n","[77,    10] loss: 1.308121919631958, time: 5.447211742401123\n","[77,    11] loss: 0.8640354871749878, time: 5.9816200733184814\n","[77,    12] loss: 1.0371966361999512, time: 6.519567012786865\n","[77,    13] loss: 1.2860159873962402, time: 7.060080528259277\n","[77,    14] loss: 1.0434203147888184, time: 7.608668088912964\n","[77,    15] loss: 0.9717971682548523, time: 8.156702756881714\n","[77,    16] loss: 1.1614545583724976, time: 8.694449186325073\n","[77,    17] loss: 0.8647142648696899, time: 9.245756149291992\n","[77,    18] loss: 1.0247411727905273, time: 9.79748249053955\n","[77,    19] loss: 0.9349174499511719, time: 10.367930173873901\n","[77,    20] loss: 0.799946665763855, time: 10.913082361221313\n","[77,    21] loss: 1.2108310461044312, time: 11.452988386154175\n","[77,    22] loss: 1.1372839212417603, time: 12.032402753829956\n","[77,    23] loss: 1.3459160327911377, time: 12.572914123535156\n","[77,    24] loss: 1.0917116403579712, time: 13.104076147079468\n","[77,    25] loss: 1.0241822004318237, time: 13.639412641525269\n","[77,    26] loss: 0.867769181728363, time: 14.172600030899048\n","[77,    27] loss: 1.450518250465393, time: 14.726544380187988\n","[77,    28] loss: 1.0379599332809448, time: 15.26497769355774\n","[77,    29] loss: 1.089172124862671, time: 15.829323768615723\n","[77,    30] loss: 1.0961054563522339, time: 16.37794780731201\n","[77,    31] loss: 0.9551867842674255, time: 16.93884515762329\n","[77,    32] loss: 0.8865014314651489, time: 17.46460795402527\n","[77,    33] loss: 1.2696958780288696, time: 18.0292866230011\n","[77,    34] loss: 1.0832897424697876, time: 18.578649044036865\n","[77,    35] loss: 0.9477298259735107, time: 19.109820127487183\n","[77,    36] loss: 1.0263431072235107, time: 19.656012773513794\n","[77,    37] loss: 1.008070707321167, time: 20.18789839744568\n","[77,    38] loss: 1.253400206565857, time: 20.729140758514404\n","[77,    39] loss: 0.7032011151313782, time: 21.278801679611206\n","[77,    40] loss: 1.1032745838165283, time: 21.83188247680664\n","[77,    41] loss: 0.921510636806488, time: 22.375977754592896\n","[77,    42] loss: 1.02169930934906, time: 22.919236660003662\n","[77,    43] loss: 0.8419532179832458, time: 23.44644808769226\n","[77,    44] loss: 1.1449289321899414, time: 23.987942934036255\n","[77,    45] loss: 1.1819868087768555, time: 24.541338443756104\n","[77,    46] loss: 0.9707569479942322, time: 25.10682463645935\n","[77,    47] loss: 1.33596670627594, time: 25.665113925933838\n","[77,    48] loss: 1.081790566444397, time: 26.246582746505737\n","[77,    49] loss: 1.1254606246948242, time: 26.82369613647461\n","[77,    50] loss: 1.4657877683639526, time: 26.99933409690857\n","\n","Evaluation: Average loss: 1.0588, Accuracy: 670/947 (70.750%)\n","\n","************************************************************\n","Total removed parameters: 229795.0\n","Take 6.516223139844367 % of active parameters\n","Total redistribution parameters: 3297773.0\n","Take: 1435.0934528601579 % of removed parameters\n","Pruning rate: 0.06684751026646127\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.51 seconds.\n","\n","Total nonzero parameters:  3428687\n","Take 14.534498358456416 %\n","------------------------------------------------------------\n","[78,     1] loss: 0.9522377848625183, time: 0.5349798202514648\n","[78,     2] loss: 1.0100648403167725, time: 1.0716862678527832\n","[78,     3] loss: 0.938573956489563, time: 1.6384272575378418\n","[78,     4] loss: 0.9332616329193115, time: 2.1775736808776855\n","[78,     5] loss: 1.1521506309509277, time: 2.728426218032837\n","[78,     6] loss: 1.1115683317184448, time: 3.2761337757110596\n","[78,     7] loss: 1.2234184741973877, time: 3.7994868755340576\n","[78,     8] loss: 0.9749192595481873, time: 4.357549428939819\n","[78,     9] loss: 1.4235897064208984, time: 4.919473171234131\n","[78,    10] loss: 1.0150036811828613, time: 5.453888416290283\n","[78,    11] loss: 0.9640228748321533, time: 5.987598896026611\n","[78,    12] loss: 1.1700894832611084, time: 6.537028551101685\n","[78,    13] loss: 1.152475118637085, time: 7.079516172409058\n","[78,    14] loss: 1.0171637535095215, time: 7.629899024963379\n","[78,    15] loss: 1.1107507944107056, time: 8.184130668640137\n","[78,    16] loss: 1.3566875457763672, time: 8.71828317642212\n","[78,    17] loss: 1.0804206132888794, time: 9.258269309997559\n","[78,    18] loss: 1.1496509313583374, time: 9.81133508682251\n","[78,    19] loss: 1.0696978569030762, time: 10.343727588653564\n","[78,    20] loss: 1.3310176134109497, time: 10.859540939331055\n","[78,    21] loss: 0.8352146148681641, time: 11.390855312347412\n","[78,    22] loss: 1.1330583095550537, time: 11.941411972045898\n","[78,    23] loss: 0.7927649021148682, time: 12.492202758789062\n","[78,    24] loss: 1.0083237886428833, time: 13.064585447311401\n","[78,    25] loss: 1.0376836061477661, time: 13.61944842338562\n","[78,    26] loss: 0.878892183303833, time: 14.202532052993774\n","[78,    27] loss: 0.8722143173217773, time: 14.783632755279541\n","[78,    28] loss: 0.9911497831344604, time: 15.342968463897705\n","[78,    29] loss: 1.164016842842102, time: 15.914541482925415\n","[78,    30] loss: 0.9971358776092529, time: 16.487849473953247\n","[78,    31] loss: 1.0902029275894165, time: 17.038681507110596\n","[78,    32] loss: 0.8527049422264099, time: 17.57254147529602\n","[78,    33] loss: 0.6123687028884888, time: 18.10411238670349\n","[78,    34] loss: 0.8995175361633301, time: 18.632470846176147\n","[78,    35] loss: 1.1058670282363892, time: 19.16337561607361\n","[78,    36] loss: 0.9973181486129761, time: 19.69809865951538\n","[78,    37] loss: 0.8955976963043213, time: 20.225516319274902\n","[78,    38] loss: 1.0257751941680908, time: 20.772176265716553\n","[78,    39] loss: 1.0061649084091187, time: 21.309518814086914\n","[78,    40] loss: 0.7223874926567078, time: 21.85217022895813\n","[78,    41] loss: 1.0469043254852295, time: 22.38681936264038\n","[78,    42] loss: 0.8921582698822021, time: 22.921666622161865\n","[78,    43] loss: 0.9439945816993713, time: 23.47892141342163\n","[78,    44] loss: 0.7334147095680237, time: 24.000428676605225\n","[78,    45] loss: 1.0471739768981934, time: 24.532890796661377\n","[78,    46] loss: 0.6883206963539124, time: 25.059428930282593\n","[78,    47] loss: 1.2187446355819702, time: 25.632679224014282\n","[78,    48] loss: 1.0797158479690552, time: 26.185479879379272\n","[78,    49] loss: 1.044419288635254, time: 26.7314715385437\n","[78,    50] loss: 0.5558565258979797, time: 26.90733575820923\n","\n","Evaluation: Average loss: 0.6809, Accuracy: 744/947 (78.564%)\n","\n","************************************************************\n","Total removed parameters: 212511.0\n","Take 6.024292090187914 % of active parameters\n","Total redistribution parameters: 3315496.0\n","Take: 1560.1526509215994 % of removed parameters\n","Pruning rate: 0.06179797241299227\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.34 seconds.\n","\n","Total nonzero parameters:  3439009\n","Take 14.578254202036186 %\n","------------------------------------------------------------\n","[79,     1] loss: 0.8348014950752258, time: 0.5471487045288086\n","[79,     2] loss: 1.015084147453308, time: 1.1026406288146973\n","[79,     3] loss: 0.8184225559234619, time: 1.644235610961914\n","[79,     4] loss: 0.9645793437957764, time: 2.1976754665374756\n","[79,     5] loss: 1.1351186037063599, time: 2.7682015895843506\n","[79,     6] loss: 0.9748611450195312, time: 3.299973726272583\n","[79,     7] loss: 1.0636141300201416, time: 3.8553168773651123\n","[79,     8] loss: 0.7381004095077515, time: 4.378683090209961\n","[79,     9] loss: 0.9928185343742371, time: 4.921407699584961\n","[79,    10] loss: 0.711026132106781, time: 5.467691898345947\n","[79,    11] loss: 0.8716519474983215, time: 5.996650457382202\n","[79,    12] loss: 0.8300973773002625, time: 6.529669761657715\n","[79,    13] loss: 0.9976014494895935, time: 7.0904860496521\n","[79,    14] loss: 0.8365520238876343, time: 7.6232287883758545\n","[79,    15] loss: 0.8451323509216309, time: 8.169076442718506\n","[79,    16] loss: 0.9441370964050293, time: 8.713348388671875\n","[79,    17] loss: 1.0682190656661987, time: 9.277513265609741\n","[79,    18] loss: 0.9042186737060547, time: 9.824341058731079\n","[79,    19] loss: 1.076598882675171, time: 10.409664392471313\n","[79,    20] loss: 1.2892118692398071, time: 10.947750568389893\n","[79,    21] loss: 1.0327067375183105, time: 11.484769105911255\n","[79,    22] loss: 0.9879496097564697, time: 12.021382570266724\n","[79,    23] loss: 1.0607562065124512, time: 12.553587675094604\n","[79,    24] loss: 0.8868609070777893, time: 13.106299638748169\n","[79,    25] loss: 1.090248465538025, time: 13.660448551177979\n","[79,    26] loss: 1.086086392402649, time: 14.192776441574097\n","[79,    27] loss: 1.159406065940857, time: 14.715313196182251\n","[79,    28] loss: 0.971307635307312, time: 15.241437911987305\n","[79,    29] loss: 1.092443585395813, time: 15.768210411071777\n","[79,    30] loss: 1.2190556526184082, time: 16.301044702529907\n","[79,    31] loss: 0.9696781635284424, time: 16.8365318775177\n","[79,    32] loss: 1.015465497970581, time: 17.36693263053894\n","[79,    33] loss: 0.7053388357162476, time: 17.90832257270813\n","[79,    34] loss: 1.0182231664657593, time: 18.44719672203064\n","[79,    35] loss: 0.8585478067398071, time: 18.970813274383545\n","[79,    36] loss: 0.763594925403595, time: 19.50470781326294\n","[79,    37] loss: 1.0809926986694336, time: 20.065622568130493\n","[79,    38] loss: 0.7520314455032349, time: 20.598744869232178\n","[79,    39] loss: 0.8776178359985352, time: 21.142568588256836\n","[79,    40] loss: 0.9233527779579163, time: 21.701624393463135\n","[79,    41] loss: 0.9617125988006592, time: 22.242550373077393\n","[79,    42] loss: 0.7938293814659119, time: 22.78267002105713\n","[79,    43] loss: 0.8329669237136841, time: 23.315988063812256\n","[79,    44] loss: 0.7278037071228027, time: 23.86638045310974\n","[79,    45] loss: 0.8899253010749817, time: 24.404741764068604\n","[79,    46] loss: 0.7631998062133789, time: 24.948920965194702\n","[79,    47] loss: 0.9869182109832764, time: 25.503004789352417\n","[79,    48] loss: 1.1960113048553467, time: 26.033189296722412\n","[79,    49] loss: 0.7012110352516174, time: 26.588494539260864\n","[79,    50] loss: 0.9835586547851562, time: 26.759509563446045\n","\n","Evaluation: Average loss: 0.5410, Accuracy: 798/947 (84.266%)\n","\n","************************************************************\n","Total removed parameters: 195832.0\n","Take 5.550782637336037 % of active parameters\n","Total redistribution parameters: 3331818.0\n","Take: 1701.365456105233 % of removed parameters\n","Pruning rate: 0.05693663443701676\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.40 seconds.\n","\n","Total nonzero parameters:  3448827\n","Take 14.61987354637509 %\n","------------------------------------------------------------\n","[80,     1] loss: 0.8215583562850952, time: 0.5369083881378174\n","[80,     2] loss: 0.9809665083885193, time: 1.0838019847869873\n","[80,     3] loss: 0.6371637582778931, time: 1.6069228649139404\n","[80,     4] loss: 1.075749397277832, time: 2.1516926288604736\n","[80,     5] loss: 1.214712142944336, time: 2.716822624206543\n","[80,     6] loss: 1.146371603012085, time: 3.280452251434326\n","[80,     7] loss: 0.9198725819587708, time: 3.8341264724731445\n","[80,     8] loss: 1.0150418281555176, time: 4.408484935760498\n","[80,     9] loss: 1.2518047094345093, time: 4.973491907119751\n","[80,    10] loss: 1.286409854888916, time: 5.519757032394409\n","[80,    11] loss: 1.0340874195098877, time: 6.054883718490601\n","[80,    12] loss: 0.8438763618469238, time: 6.613872051239014\n","[80,    13] loss: 0.9519519805908203, time: 7.161601543426514\n","[80,    14] loss: 0.954780101776123, time: 7.725654363632202\n","[80,    15] loss: 1.0218240022659302, time: 8.281666994094849\n","[80,    16] loss: 1.0382477045059204, time: 8.833532571792603\n","[80,    17] loss: 1.186691164970398, time: 9.37404990196228\n","[80,    18] loss: 0.7593016028404236, time: 9.895261526107788\n","[80,    19] loss: 1.0543535947799683, time: 10.42463231086731\n","[80,    20] loss: 0.9316126108169556, time: 10.943873405456543\n","[80,    21] loss: 0.9270929098129272, time: 11.485095262527466\n","[80,    22] loss: 0.8468396067619324, time: 12.020266056060791\n","[80,    23] loss: 0.6324734091758728, time: 12.5511314868927\n","[80,    24] loss: 1.0457335710525513, time: 13.077115774154663\n","[80,    25] loss: 0.9646409749984741, time: 13.638976335525513\n","[80,    26] loss: 1.278175950050354, time: 14.180710315704346\n","[80,    27] loss: 0.8466963768005371, time: 14.721960067749023\n","[80,    28] loss: 0.8629273176193237, time: 15.27364468574524\n","[80,    29] loss: 1.160715937614441, time: 15.820111274719238\n","[80,    30] loss: 1.0712921619415283, time: 16.3678240776062\n","[80,    31] loss: 1.1226234436035156, time: 16.915778636932373\n","[80,    32] loss: 0.7561217546463013, time: 17.445757150650024\n","[80,    33] loss: 1.1773802042007446, time: 17.99201774597168\n","[80,    34] loss: 1.2192718982696533, time: 18.54395031929016\n","[80,    35] loss: 0.9223552346229553, time: 19.10777187347412\n","[80,    36] loss: 1.006775975227356, time: 19.66019582748413\n","[80,    37] loss: 1.2574284076690674, time: 20.213335752487183\n","[80,    38] loss: 0.8889618515968323, time: 20.745742559432983\n","[80,    39] loss: 1.0709643363952637, time: 21.30101728439331\n","[80,    40] loss: 1.005681037902832, time: 21.844221353530884\n","[80,    41] loss: 1.0623927116394043, time: 22.398568630218506\n","[80,    42] loss: 0.7179802656173706, time: 22.938036918640137\n","[80,    43] loss: 0.8228617906570435, time: 23.459293842315674\n","[80,    44] loss: 0.9087207913398743, time: 23.984301567077637\n","[80,    45] loss: 1.0162639617919922, time: 24.50441026687622\n","[80,    46] loss: 0.9683066010475159, time: 25.02612590789795\n","[80,    47] loss: 0.9390850067138672, time: 25.583677530288696\n","[80,    48] loss: 0.9094448089599609, time: 26.113581657409668\n","[80,    49] loss: 1.1055972576141357, time: 26.650348901748657\n","[80,    50] loss: 0.44736993312835693, time: 26.81826663017273\n","\n","Evaluation: Average loss: 0.5457, Accuracy: 787/947 (83.105%)\n","\n","************************************************************\n","Total removed parameters: 179765.0\n","Take 5.09588536277692 % of active parameters\n","Total redistribution parameters: 3347795.0\n","Take: 1862.3174700303173 % of removed parameters\n","Pruning rate: 0.05226829389220063\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.13 seconds.\n","\n","Total nonzero parameters:  3460710\n","Take 14.670246602881425 %\n","------------------------------------------------------------\n","[81,     1] loss: 1.0615806579589844, time: 0.5402681827545166\n","[81,     2] loss: 0.7763001918792725, time: 1.1102871894836426\n","[81,     3] loss: 0.7829612493515015, time: 1.655674695968628\n","[81,     4] loss: 1.1216933727264404, time: 2.2037532329559326\n","[81,     5] loss: 0.8518434166908264, time: 2.7382450103759766\n","[81,     6] loss: 1.224675178527832, time: 3.3164303302764893\n","[81,     7] loss: 1.2627456188201904, time: 3.859400749206543\n","[81,     8] loss: 0.9682577848434448, time: 4.399940490722656\n","[81,     9] loss: 1.3464521169662476, time: 4.942068576812744\n","[81,    10] loss: 0.907112717628479, time: 5.494766473770142\n","[81,    11] loss: 0.9493173360824585, time: 6.044665336608887\n","[81,    12] loss: 1.177870750427246, time: 6.580147981643677\n","[81,    13] loss: 1.0189738273620605, time: 7.121079444885254\n","[81,    14] loss: 0.8097910284996033, time: 7.6627562046051025\n","[81,    15] loss: 0.7418018579483032, time: 8.215487718582153\n","[81,    16] loss: 0.689543604850769, time: 8.751317501068115\n","[81,    17] loss: 1.0546928644180298, time: 9.297304153442383\n","[81,    18] loss: 0.9195360541343689, time: 9.851196050643921\n","[81,    19] loss: 1.4340291023254395, time: 10.393627882003784\n","[81,    20] loss: 0.9042825698852539, time: 10.931634187698364\n","[81,    21] loss: 0.8854642510414124, time: 11.462200164794922\n","[81,    22] loss: 0.970258355140686, time: 11.988187313079834\n","[81,    23] loss: 1.0948020219802856, time: 12.534655809402466\n","[81,    24] loss: 0.923602283000946, time: 13.081619501113892\n","[81,    25] loss: 1.0071157217025757, time: 13.623428583145142\n","[81,    26] loss: 1.2846412658691406, time: 14.16285252571106\n","[81,    27] loss: 0.8664805889129639, time: 14.694819211959839\n","[81,    28] loss: 0.8154823184013367, time: 15.24299144744873\n","[81,    29] loss: 1.0583187341690063, time: 15.775996446609497\n","[81,    30] loss: 0.7467904090881348, time: 16.316516876220703\n","[81,    31] loss: 0.6796674132347107, time: 16.83942222595215\n","[81,    32] loss: 1.0451580286026, time: 17.382845163345337\n","[81,    33] loss: 1.238391637802124, time: 17.941845417022705\n","[81,    34] loss: 0.9613251090049744, time: 18.48150658607483\n","[81,    35] loss: 0.7944138050079346, time: 19.006291151046753\n","[81,    36] loss: 1.0025086402893066, time: 19.530211687088013\n","[81,    37] loss: 0.9129928946495056, time: 20.0579514503479\n","[81,    38] loss: 0.9427016377449036, time: 20.592812299728394\n","[81,    39] loss: 0.8536524176597595, time: 21.129544496536255\n","[81,    40] loss: 0.7576696872711182, time: 21.666912317276\n","[81,    41] loss: 0.8325676321983337, time: 22.21799063682556\n","[81,    42] loss: 0.9187259674072266, time: 22.736265420913696\n","[81,    43] loss: 1.0525449514389038, time: 23.286678791046143\n","[81,    44] loss: 1.0220870971679688, time: 23.81843662261963\n","[81,    45] loss: 1.0198266506195068, time: 24.36428952217102\n","[81,    46] loss: 1.0431797504425049, time: 24.91479730606079\n","[81,    47] loss: 1.0695382356643677, time: 25.475096464157104\n","[81,    48] loss: 0.8778383731842041, time: 26.0140118598938\n","[81,    49] loss: 0.91175377368927, time: 26.547456741333008\n","[81,    50] loss: 1.7413289546966553, time: 26.73085594177246\n","\n","Evaluation: Average loss: 0.7897, Accuracy: 724/947 (76.452%)\n","\n","************************************************************\n","Total removed parameters: 164400.0\n","Take 4.6604451802378986 % of active parameters\n","Total redistribution parameters: 3363579.0\n","Take: 2045.9726277372263 % of removed parameters\n","Pruning rate: 0.04779755786704606\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.20 seconds.\n","\n","Total nonzero parameters:  3469113\n","Take 14.705867640819886 %\n","------------------------------------------------------------\n","[82,     1] loss: 1.0726335048675537, time: 0.5421202182769775\n","[82,     2] loss: 0.908410906791687, time: 1.0932159423828125\n","[82,     3] loss: 0.9187610149383545, time: 1.6366055011749268\n","[82,     4] loss: 1.0613183975219727, time: 2.1778812408447266\n","[82,     5] loss: 1.1496329307556152, time: 2.71069598197937\n","[82,     6] loss: 1.5300668478012085, time: 3.239232063293457\n","[82,     7] loss: 1.224644660949707, time: 3.7856943607330322\n","[82,     8] loss: 0.973011314868927, time: 4.341960191726685\n","[82,     9] loss: 1.0626640319824219, time: 4.874862432479858\n","[82,    10] loss: 1.168342113494873, time: 5.413714408874512\n","[82,    11] loss: 0.9591405987739563, time: 5.953336477279663\n","[82,    12] loss: 0.7896944284439087, time: 6.47721004486084\n","[82,    13] loss: 1.2685484886169434, time: 7.021625757217407\n","[82,    14] loss: 0.8385004997253418, time: 7.560790300369263\n","[82,    15] loss: 0.9298405051231384, time: 8.111193180084229\n","[82,    16] loss: 0.9274989366531372, time: 8.658507585525513\n","[82,    17] loss: 0.7171903848648071, time: 9.199499130249023\n","[82,    18] loss: 0.8935690522193909, time: 9.736425161361694\n","[82,    19] loss: 1.0950653553009033, time: 10.297332525253296\n","[82,    20] loss: 1.0960724353790283, time: 10.837329387664795\n","[82,    21] loss: 1.0073975324630737, time: 11.36592149734497\n","[82,    22] loss: 0.9792948365211487, time: 11.925732135772705\n","[82,    23] loss: 0.9976471662521362, time: 12.46593427658081\n","[82,    24] loss: 1.058567762374878, time: 12.9911470413208\n","[82,    25] loss: 1.2517757415771484, time: 13.542497873306274\n","[82,    26] loss: 0.900770366191864, time: 14.086616277694702\n","[82,    27] loss: 1.0816515684127808, time: 14.623912572860718\n","[82,    28] loss: 1.1577876806259155, time: 15.157121896743774\n","[82,    29] loss: 0.9745190143585205, time: 15.704885959625244\n","[82,    30] loss: 0.9114696383476257, time: 16.250855922698975\n","[82,    31] loss: 1.0597633123397827, time: 16.77836012840271\n","[82,    32] loss: 1.0308167934417725, time: 17.30739665031433\n","[82,    33] loss: 0.9272899627685547, time: 17.840070724487305\n","[82,    34] loss: 1.0995643138885498, time: 18.382924795150757\n","[82,    35] loss: 0.9791985154151917, time: 18.905701875686646\n","[82,    36] loss: 0.7914435267448425, time: 19.434399366378784\n","[82,    37] loss: 0.99115389585495, time: 19.975945472717285\n","[82,    38] loss: 1.115910291671753, time: 20.519359350204468\n","[82,    39] loss: 1.130030870437622, time: 21.065441608428955\n","[82,    40] loss: 1.0257396697998047, time: 21.626869201660156\n","[82,    41] loss: 0.9929743409156799, time: 22.18174171447754\n","[82,    42] loss: 0.7755348086357117, time: 22.72252321243286\n","[82,    43] loss: 0.9842583537101746, time: 23.27565288543701\n","[82,    44] loss: 0.779485821723938, time: 23.82138466835022\n","[82,    45] loss: 1.0749022960662842, time: 24.357938051223755\n","[82,    46] loss: 1.198117971420288, time: 24.909458875656128\n","[82,    47] loss: 0.7472927570343018, time: 25.453861474990845\n","[82,    48] loss: 0.8748689889907837, time: 25.99466347694397\n","[82,    49] loss: 0.9134650230407715, time: 26.52269721031189\n","[82,    50] loss: 1.018844485282898, time: 26.70154356956482\n","\n","Evaluation: Average loss: 0.5207, Accuracy: 800/947 (84.477%)\n","\n","************************************************************\n","Total removed parameters: 149755.0\n","Take 4.244781502384226 % of active parameters\n","Total redistribution parameters: 3377831.0\n","Take: 2255.571433341124 % of removed parameters\n","Pruning rate: 0.043528838438251366\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.18 seconds.\n","\n","Total nonzero parameters:  3478973\n","Take 14.747665026762197 %\n","------------------------------------------------------------\n","[83,     1] loss: 0.7271102666854858, time: 0.5622284412384033\n","[83,     2] loss: 0.9492127299308777, time: 1.102651596069336\n","[83,     3] loss: 1.3146743774414062, time: 1.6520781517028809\n","[83,     4] loss: 1.2804527282714844, time: 2.1963977813720703\n","[83,     5] loss: 1.0038529634475708, time: 2.752152919769287\n","[83,     6] loss: 0.9510987997055054, time: 3.2888989448547363\n","[83,     7] loss: 1.0743149518966675, time: 3.8242697715759277\n","[83,     8] loss: 0.6659887433052063, time: 4.369910001754761\n","[83,     9] loss: 0.9390953779220581, time: 4.909052848815918\n","[83,    10] loss: 0.9523012042045593, time: 5.419000864028931\n","[83,    11] loss: 0.9672386646270752, time: 5.966876983642578\n","[83,    12] loss: 0.7469705939292908, time: 6.501908540725708\n","[83,    13] loss: 0.7581166625022888, time: 7.059225797653198\n","[83,    14] loss: 1.1142771244049072, time: 7.634950399398804\n","[83,    15] loss: 0.8694765567779541, time: 8.197387218475342\n","[83,    16] loss: 0.8671306371688843, time: 8.731546878814697\n","[83,    17] loss: 0.8262953162193298, time: 9.286397218704224\n","[83,    18] loss: 1.2507141828536987, time: 9.849946737289429\n","[83,    19] loss: 0.6549407243728638, time: 10.397865533828735\n","[83,    20] loss: 0.9502598643302917, time: 10.946314096450806\n","[83,    21] loss: 1.2901896238327026, time: 11.489622116088867\n","[83,    22] loss: 0.9806641340255737, time: 12.057401418685913\n","[83,    23] loss: 0.7926977276802063, time: 12.601686954498291\n","[83,    24] loss: 0.875855028629303, time: 13.154775142669678\n","[83,    25] loss: 0.6998908519744873, time: 13.716371774673462\n","[83,    26] loss: 0.7453331351280212, time: 14.283787727355957\n","[83,    27] loss: 0.8509886860847473, time: 14.823173761367798\n","[83,    28] loss: 0.6608574390411377, time: 15.377898216247559\n","[83,    29] loss: 1.0244401693344116, time: 15.924444675445557\n","[83,    30] loss: 0.9858144521713257, time: 16.498271703720093\n","[83,    31] loss: 1.1093354225158691, time: 17.050650119781494\n","[83,    32] loss: 0.9785420894622803, time: 17.585511445999146\n","[83,    33] loss: 0.8958922028541565, time: 18.135598182678223\n","[83,    34] loss: 0.6626420021057129, time: 18.683697938919067\n","[83,    35] loss: 1.0906696319580078, time: 19.22630500793457\n","[83,    36] loss: 0.9861657023429871, time: 19.768686771392822\n","[83,    37] loss: 0.9406849145889282, time: 20.291672706604004\n","[83,    38] loss: 1.2258615493774414, time: 20.8356876373291\n","[83,    39] loss: 0.8144066333770752, time: 21.36965036392212\n","[83,    40] loss: 1.127958059310913, time: 21.931277751922607\n","[83,    41] loss: 0.931623637676239, time: 22.49073076248169\n","[83,    42] loss: 1.0517175197601318, time: 23.034492254257202\n","[83,    43] loss: 1.4877643585205078, time: 23.565182209014893\n","[83,    44] loss: 0.7868412733078003, time: 24.12497329711914\n","[83,    45] loss: 0.9723677039146423, time: 24.668807983398438\n","[83,    46] loss: 0.6823318004608154, time: 25.224671125411987\n","[83,    47] loss: 1.247164249420166, time: 25.76954698562622\n","[83,    48] loss: 0.8036172389984131, time: 26.303962469100952\n","[83,    49] loss: 0.717597246170044, time: 26.855304718017578\n","[83,    50] loss: 0.6332589983940125, time: 27.036532640457153\n","\n","Evaluation: Average loss: 0.7897, Accuracy: 720/947 (76.030%)\n","\n","************************************************************\n","Total removed parameters: 135775.0\n","Take 3.848949394855292 % of active parameters\n","Total redistribution parameters: 3392627.0\n","Take: 2498.712575952863 % of removed parameters\n","Pruning rate: 0.03946634831652407\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.36 seconds.\n","\n","Total nonzero parameters:  3486839\n","Take 14.781009675628546 %\n","------------------------------------------------------------\n","[84,     1] loss: 0.9648374915122986, time: 0.5445671081542969\n","[84,     2] loss: 0.6844516396522522, time: 1.0988514423370361\n","[84,     3] loss: 0.6320165395736694, time: 1.6570158004760742\n","[84,     4] loss: 0.8754821419715881, time: 2.204808473587036\n","[84,     5] loss: 0.9251016974449158, time: 2.740771770477295\n","[84,     6] loss: 0.8385787606239319, time: 3.3081371784210205\n","[84,     7] loss: 0.7017019987106323, time: 3.83859920501709\n","[84,     8] loss: 0.8567400574684143, time: 4.371778964996338\n","[84,     9] loss: 1.0765732526779175, time: 4.906383514404297\n","[84,    10] loss: 1.102707862854004, time: 5.46260929107666\n","[84,    11] loss: 1.4112321138381958, time: 6.01336145401001\n","[84,    12] loss: 1.0388233661651611, time: 6.5780863761901855\n","[84,    13] loss: 0.8623872995376587, time: 7.145461797714233\n","[84,    14] loss: 0.7705707550048828, time: 7.675595760345459\n","[84,    15] loss: 1.0199899673461914, time: 8.218358755111694\n","[84,    16] loss: 0.9320646524429321, time: 8.759195566177368\n","[84,    17] loss: 1.170082688331604, time: 9.28514814376831\n","[84,    18] loss: 0.9527608156204224, time: 9.842546939849854\n","[84,    19] loss: 0.6962961554527283, time: 10.389748573303223\n","[84,    20] loss: 0.9234620928764343, time: 10.95320439338684\n","[84,    21] loss: 1.2218369245529175, time: 11.502744913101196\n","[84,    22] loss: 1.032039999961853, time: 12.036456108093262\n","[84,    23] loss: 1.0256617069244385, time: 12.599315881729126\n","[84,    24] loss: 1.130021333694458, time: 13.161476135253906\n","[84,    25] loss: 0.8847559094429016, time: 13.713531970977783\n","[84,    26] loss: 1.3174049854278564, time: 14.272223711013794\n","[84,    27] loss: 0.8993522524833679, time: 14.817838430404663\n","[84,    28] loss: 0.6294744610786438, time: 15.370784997940063\n","[84,    29] loss: 1.1188381910324097, time: 15.931121349334717\n","[84,    30] loss: 1.0897295475006104, time: 16.464787483215332\n","[84,    31] loss: 0.7347642779350281, time: 17.001789093017578\n","[84,    32] loss: 1.396544098854065, time: 17.54999089241028\n","[84,    33] loss: 1.1866692304611206, time: 18.105377435684204\n","[84,    34] loss: 0.6504825949668884, time: 18.65273928642273\n","[84,    35] loss: 0.6672345399856567, time: 19.170480966567993\n","[84,    36] loss: 0.7597925662994385, time: 19.709688901901245\n","[84,    37] loss: 0.7825063467025757, time: 20.257487297058105\n","[84,    38] loss: 0.9190980792045593, time: 20.792123794555664\n","[84,    39] loss: 0.659885048866272, time: 21.316158056259155\n","[84,    40] loss: 0.8949126601219177, time: 21.858176231384277\n","[84,    41] loss: 0.9691689610481262, time: 22.38536500930786\n","[84,    42] loss: 1.1578348875045776, time: 22.939684867858887\n","[84,    43] loss: 0.8982239365577698, time: 23.480626106262207\n","[84,    44] loss: 0.8179632425308228, time: 24.007254123687744\n","[84,    45] loss: 1.1165937185287476, time: 24.560808658599854\n","[84,    46] loss: 0.9672570824623108, time: 25.098448753356934\n","[84,    47] loss: 0.9577921628952026, time: 25.643624305725098\n","[84,    48] loss: 1.021715760231018, time: 26.190016508102417\n","[84,    49] loss: 1.2053881883621216, time: 26.7148494720459\n","[84,    50] loss: 1.0567950010299683, time: 26.894096612930298\n","\n","Evaluation: Average loss: 0.5518, Accuracy: 789/947 (83.316%)\n","\n","************************************************************\n","Total removed parameters: 122566.0\n","Take 3.473697158090263 % of active parameters\n","Total redistribution parameters: 3405871.0\n","Take: 2778.8057046815593 % of removed parameters\n","Pruning rate: 0.035614096689143844\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.26 seconds.\n","\n","Total nonzero parameters:  3496200\n","Take 14.820691757758969 %\n","------------------------------------------------------------\n","[85,     1] loss: 0.9025200605392456, time: 0.5753271579742432\n","[85,     2] loss: 0.8283688426017761, time: 1.0995638370513916\n","[85,     3] loss: 1.107720136642456, time: 1.6545584201812744\n","[85,     4] loss: 1.1542938947677612, time: 2.198012590408325\n","[85,     5] loss: 0.7660382390022278, time: 2.726086139678955\n","[85,     6] loss: 1.119168758392334, time: 3.2484476566314697\n","[85,     7] loss: 0.8602406978607178, time: 3.7731950283050537\n","[85,     8] loss: 1.235119342803955, time: 4.350663900375366\n","[85,     9] loss: 1.163956642150879, time: 4.892950057983398\n","[85,    10] loss: 0.7565991878509521, time: 5.4174511432647705\n","[85,    11] loss: 1.153263807296753, time: 5.966305494308472\n","[85,    12] loss: 0.8472726345062256, time: 6.498064756393433\n","[85,    13] loss: 1.246363878250122, time: 7.010589599609375\n","[85,    14] loss: 0.7743244767189026, time: 7.547703504562378\n","[85,    15] loss: 0.9097921252250671, time: 8.088862419128418\n","[85,    16] loss: 0.8007906675338745, time: 8.631712675094604\n","[85,    17] loss: 0.7572928667068481, time: 9.169198513031006\n","[85,    18] loss: 0.5013791918754578, time: 9.707492589950562\n","[85,    19] loss: 1.0458592176437378, time: 10.25747013092041\n","[85,    20] loss: 1.4789587259292603, time: 10.816211938858032\n","[85,    21] loss: 0.8187429308891296, time: 11.354929208755493\n","[85,    22] loss: 0.9167863130569458, time: 11.913711547851562\n","[85,    23] loss: 0.7841365933418274, time: 12.458651065826416\n","[85,    24] loss: 0.9121689796447754, time: 12.99646520614624\n","[85,    25] loss: 0.9624698162078857, time: 13.535064697265625\n","[85,    26] loss: 1.4538793563842773, time: 14.083154201507568\n","[85,    27] loss: 1.0519477128982544, time: 14.651700973510742\n","[85,    28] loss: 1.0354512929916382, time: 15.197819471359253\n","[85,    29] loss: 0.9423832297325134, time: 15.72629165649414\n","[85,    30] loss: 0.8970168232917786, time: 16.279916763305664\n","[85,    31] loss: 1.0821547508239746, time: 16.829748153686523\n","[85,    32] loss: 0.819320023059845, time: 17.406050205230713\n","[85,    33] loss: 0.923803448677063, time: 17.962183237075806\n","[85,    34] loss: 0.9317358136177063, time: 18.49198341369629\n","[85,    35] loss: 1.0536121129989624, time: 19.036497831344604\n","[85,    36] loss: 1.1268285512924194, time: 19.577223539352417\n","[85,    37] loss: 0.8986932039260864, time: 20.106685161590576\n","[85,    38] loss: 1.2564408779144287, time: 20.654513597488403\n","[85,    39] loss: 0.8663208484649658, time: 21.20825457572937\n","[85,    40] loss: 1.0639673471450806, time: 21.73829221725464\n","[85,    41] loss: 0.8951808214187622, time: 22.27579689025879\n","[85,    42] loss: 0.8606816530227661, time: 22.823867321014404\n","[85,    43] loss: 0.7946174144744873, time: 23.35816502571106\n","[85,    44] loss: 0.696613609790802, time: 23.891162395477295\n","[85,    45] loss: 1.1208841800689697, time: 24.407028675079346\n","[85,    46] loss: 0.9639070630073547, time: 24.954074144363403\n","[85,    47] loss: 1.259128212928772, time: 25.499911308288574\n","[85,    48] loss: 0.9209160208702087, time: 26.03409242630005\n","[85,    49] loss: 1.0737251043319702, time: 26.57908844947815\n","[85,    50] loss: 0.9760027527809143, time: 26.7368106842041\n","\n","Evaluation: Average loss: 0.8249, Accuracy: 714/947 (75.396%)\n","\n","************************************************************\n","Total removed parameters: 110062.0\n","Take 3.1192848278146954 % of active parameters\n","Total redistribution parameters: 3418481.0\n","Take: 3105.9593683560174 % of removed parameters\n","Pruning rate: 0.03197588526337897\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.25 seconds.\n","\n","Total nonzero parameters:  3503667\n","Take 14.852345011392968 %\n","------------------------------------------------------------\n","[86,     1] loss: 0.8175996541976929, time: 0.6041028499603271\n","[86,     2] loss: 1.244950532913208, time: 1.1697452068328857\n","[86,     3] loss: 1.1473501920700073, time: 1.7190303802490234\n","[86,     4] loss: 1.106101155281067, time: 2.26706862449646\n","[86,     5] loss: 0.9132874608039856, time: 2.8419902324676514\n","[86,     6] loss: 1.400632619857788, time: 3.3873708248138428\n","[86,     7] loss: 0.9458988904953003, time: 3.933875322341919\n","[86,     8] loss: 1.2560685873031616, time: 4.494477272033691\n","[86,     9] loss: 0.9175028800964355, time: 5.040122985839844\n","[86,    10] loss: 0.8975876569747925, time: 5.576848268508911\n","[86,    11] loss: 1.3011327981948853, time: 6.125304937362671\n","[86,    12] loss: 0.9828252792358398, time: 6.644350528717041\n","[86,    13] loss: 0.8376148343086243, time: 7.181181907653809\n","[86,    14] loss: 0.9856910705566406, time: 7.717250347137451\n","[86,    15] loss: 0.9031876921653748, time: 8.238797664642334\n","[86,    16] loss: 1.2404530048370361, time: 8.782164812088013\n","[86,    17] loss: 1.0225675106048584, time: 9.324104070663452\n","[86,    18] loss: 1.1129640340805054, time: 9.857319831848145\n","[86,    19] loss: 0.8420082330703735, time: 10.41001582145691\n","[86,    20] loss: 0.8920780420303345, time: 10.95998215675354\n","[86,    21] loss: 0.9145631194114685, time: 11.504520177841187\n","[86,    22] loss: 0.893182635307312, time: 12.036355257034302\n","[86,    23] loss: 1.00437331199646, time: 12.591970682144165\n","[86,    24] loss: 1.249093770980835, time: 13.147313117980957\n","[86,    25] loss: 0.7346290349960327, time: 13.700376033782959\n","[86,    26] loss: 0.8494628071784973, time: 14.224287748336792\n","[86,    27] loss: 1.1015639305114746, time: 14.811310052871704\n","[86,    28] loss: 0.8788143396377563, time: 15.367757320404053\n","[86,    29] loss: 0.998454213142395, time: 15.938720226287842\n","[86,    30] loss: 0.9025988578796387, time: 16.476351976394653\n","[86,    31] loss: 0.9023402333259583, time: 17.02902889251709\n","[86,    32] loss: 0.8326073288917542, time: 17.589745044708252\n","[86,    33] loss: 1.0580151081085205, time: 18.12472653388977\n","[86,    34] loss: 0.9333617687225342, time: 18.666288137435913\n","[86,    35] loss: 1.011121153831482, time: 19.203203201293945\n","[86,    36] loss: 0.911191999912262, time: 19.744370698928833\n","[86,    37] loss: 0.8664984107017517, time: 20.278215646743774\n","[86,    38] loss: 0.7427664399147034, time: 20.825597763061523\n","[86,    39] loss: 0.9006302952766418, time: 21.37136697769165\n","[86,    40] loss: 0.8548747897148132, time: 21.90093731880188\n","[86,    41] loss: 1.0672752857208252, time: 22.43237018585205\n","[86,    42] loss: 0.8864096999168396, time: 22.99384093284607\n","[86,    43] loss: 1.0970615148544312, time: 23.530917644500732\n","[86,    44] loss: 1.2564468383789062, time: 24.079713106155396\n","[86,    45] loss: 0.8738541007041931, time: 24.623169660568237\n","[86,    46] loss: 1.0479084253311157, time: 25.17591643333435\n","[86,    47] loss: 0.9154840707778931, time: 25.722888231277466\n","[86,    48] loss: 0.8206412196159363, time: 26.272289276123047\n","[86,    49] loss: 0.9577667713165283, time: 26.834105014801025\n","[86,    50] loss: 1.1141881942749023, time: 27.016194581985474\n","\n","Evaluation: Average loss: 0.8089, Accuracy: 717/947 (75.713%)\n","\n","************************************************************\n","Total removed parameters: 98306.0\n","Take 2.786022446091772 % of active parameters\n","Total redistribution parameters: 3430602.0\n","Take: 3489.7178198685738 % of removed parameters\n","Pruning rate: 0.028555304514660203\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.47 seconds.\n","\n","Total nonzero parameters:  3512051\n","Take 14.887885506701318 %\n","------------------------------------------------------------\n","[87,     1] loss: 0.9385023713111877, time: 0.545295238494873\n","[87,     2] loss: 1.1396838426589966, time: 1.1047980785369873\n","[87,     3] loss: 1.079534888267517, time: 1.6588475704193115\n","[87,     4] loss: 0.6989257335662842, time: 2.2224724292755127\n","[87,     5] loss: 0.6697238683700562, time: 2.7639424800872803\n","[87,     6] loss: 0.7499738931655884, time: 3.2913153171539307\n","[87,     7] loss: 0.7469332218170166, time: 3.841850519180298\n","[87,     8] loss: 0.8567805290222168, time: 4.402156591415405\n","[87,     9] loss: 0.9830266833305359, time: 4.952791929244995\n","[87,    10] loss: 1.1115620136260986, time: 5.512549161911011\n","[87,    11] loss: 1.1875944137573242, time: 6.060461521148682\n","[87,    12] loss: 0.9202704429626465, time: 6.581517934799194\n","[87,    13] loss: 1.0218476057052612, time: 7.136451721191406\n","[87,    14] loss: 0.5846070647239685, time: 7.685022592544556\n","[87,    15] loss: 0.9029044508934021, time: 8.22856879234314\n","[87,    16] loss: 0.9566774964332581, time: 8.773583173751831\n","[87,    17] loss: 0.9819198250770569, time: 9.312927484512329\n","[87,    18] loss: 0.8406670093536377, time: 9.87386679649353\n","[87,    19] loss: 1.0418423414230347, time: 10.42356538772583\n","[87,    20] loss: 1.1779705286026, time: 10.954988718032837\n","[87,    21] loss: 0.9074600338935852, time: 11.482743501663208\n","[87,    22] loss: 0.902646005153656, time: 12.003242492675781\n","[87,    23] loss: 0.9077286124229431, time: 12.550222635269165\n","[87,    24] loss: 0.8872343301773071, time: 13.08353066444397\n","[87,    25] loss: 0.9954214692115784, time: 13.626099586486816\n","[87,    26] loss: 1.0317115783691406, time: 14.174641609191895\n","[87,    27] loss: 0.9186463356018066, time: 14.699997425079346\n","[87,    28] loss: 0.8523192405700684, time: 15.236748218536377\n","[87,    29] loss: 0.8655986189842224, time: 15.777421951293945\n","[87,    30] loss: 0.7194386124610901, time: 16.32732892036438\n","[87,    31] loss: 0.7418820858001709, time: 16.87197995185852\n","[87,    32] loss: 1.0260343551635742, time: 17.41837763786316\n","[87,    33] loss: 0.964834451675415, time: 17.941757917404175\n","[87,    34] loss: 0.9053661227226257, time: 18.46743083000183\n","[87,    35] loss: 0.8837335705757141, time: 19.014582872390747\n","[87,    36] loss: 0.9529173374176025, time: 19.54353642463684\n","[87,    37] loss: 0.8220459222793579, time: 20.108235359191895\n","[87,    38] loss: 0.4823744595050812, time: 20.650338649749756\n","[87,    39] loss: 0.7732661962509155, time: 21.177157640457153\n","[87,    40] loss: 1.1287472248077393, time: 21.70381736755371\n","[87,    41] loss: 0.8002874851226807, time: 22.2294442653656\n","[87,    42] loss: 0.7131890654563904, time: 22.772874116897583\n","[87,    43] loss: 0.6897526979446411, time: 23.317819833755493\n","[87,    44] loss: 0.7397327423095703, time: 23.867805242538452\n","[87,    45] loss: 0.817339301109314, time: 24.399911880493164\n","[87,    46] loss: 0.8090482950210571, time: 24.952467441558838\n","[87,    47] loss: 0.7555879354476929, time: 25.503185033798218\n","[87,    48] loss: 0.7744856476783752, time: 26.047416925430298\n","[87,    49] loss: 0.8918939232826233, time: 26.57228398323059\n","[87,    50] loss: 1.74639892578125, time: 26.74239706993103\n","\n","Evaluation: Average loss: 0.6335, Accuracy: 765/947 (80.781%)\n","\n","************************************************************\n","Total removed parameters: 86501.0\n","Take 2.451211536259942 % of active parameters\n","Total redistribution parameters: 3442174.0\n","Take: 3979.345903515566 % of removed parameters\n","Pruning rate: 0.025355730143214666\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.10 seconds.\n","\n","Total nonzero parameters:  3518596\n","Take 14.915630323231987 %\n","------------------------------------------------------------\n","[88,     1] loss: 1.0250128507614136, time: 0.5401146411895752\n","[88,     2] loss: 0.8267821669578552, time: 1.0862321853637695\n","[88,     3] loss: 1.1967289447784424, time: 1.6237754821777344\n","[88,     4] loss: 0.7854447364807129, time: 2.18406081199646\n","[88,     5] loss: 0.8927226662635803, time: 2.722616195678711\n","[88,     6] loss: 0.9722691178321838, time: 3.260812520980835\n","[88,     7] loss: 0.9943379163742065, time: 3.8028759956359863\n","[88,     8] loss: 1.2375643253326416, time: 4.332800626754761\n","[88,     9] loss: 0.8679256439208984, time: 4.8626837730407715\n","[88,    10] loss: 0.7821060419082642, time: 5.400006294250488\n","[88,    11] loss: 0.8304789066314697, time: 5.930450677871704\n","[88,    12] loss: 1.3161594867706299, time: 6.47502875328064\n","[88,    13] loss: 1.1445971727371216, time: 7.029383182525635\n","[88,    14] loss: 0.8816918134689331, time: 7.582857847213745\n","[88,    15] loss: 1.0526704788208008, time: 8.137029886245728\n","[88,    16] loss: 0.9593117833137512, time: 8.688832759857178\n","[88,    17] loss: 0.835669219493866, time: 9.260608196258545\n","[88,    18] loss: 0.8627766966819763, time: 9.800468444824219\n","[88,    19] loss: 0.9644309878349304, time: 10.320527791976929\n","[88,    20] loss: 0.8578174114227295, time: 10.853838682174683\n","[88,    21] loss: 0.8532195687294006, time: 11.396607637405396\n","[88,    22] loss: 1.0880502462387085, time: 11.936609506607056\n","[88,    23] loss: 1.35298752784729, time: 12.471108198165894\n","[88,    24] loss: 1.1656447649002075, time: 13.012314319610596\n","[88,    25] loss: 0.8440207839012146, time: 13.548905372619629\n","[88,    26] loss: 1.1732146739959717, time: 14.107943296432495\n","[88,    27] loss: 0.91072678565979, time: 14.65190577507019\n","[88,    28] loss: 0.8029171228408813, time: 15.165364503860474\n","[88,    29] loss: 1.1703438758850098, time: 15.690969467163086\n","[88,    30] loss: 0.93597412109375, time: 16.24936866760254\n","[88,    31] loss: 0.8061115145683289, time: 16.789380311965942\n","[88,    32] loss: 1.2087565660476685, time: 17.32860231399536\n","[88,    33] loss: 0.8693740963935852, time: 17.878453969955444\n","[88,    34] loss: 1.0223822593688965, time: 18.411454677581787\n","[88,    35] loss: 0.9073187112808228, time: 18.937276363372803\n","[88,    36] loss: 0.6777530312538147, time: 19.486831665039062\n","[88,    37] loss: 0.9379372000694275, time: 20.042206525802612\n","[88,    38] loss: 1.0558407306671143, time: 20.596277952194214\n","[88,    39] loss: 0.8438438177108765, time: 21.15426802635193\n","[88,    40] loss: 0.9671639800071716, time: 21.67961025238037\n","[88,    41] loss: 0.7232696413993835, time: 22.231797218322754\n","[88,    42] loss: 0.7819709777832031, time: 22.75939393043518\n","[88,    43] loss: 0.8765628337860107, time: 23.30913472175598\n","[88,    44] loss: 0.9547088146209717, time: 23.864110469818115\n","[88,    45] loss: 1.1603784561157227, time: 24.407792329788208\n","[88,    46] loss: 0.9225195646286011, time: 24.934123039245605\n","[88,    47] loss: 0.950745165348053, time: 25.484131574630737\n","[88,    48] loss: 1.039764165878296, time: 26.034536600112915\n","[88,    49] loss: 0.6877224445343018, time: 26.556390285491943\n","[88,    50] loss: 0.6347132325172424, time: 26.727126598358154\n","\n","Evaluation: Average loss: 0.7370, Accuracy: 729/947 (76.980%)\n","\n","************************************************************\n","Total removed parameters: 77083.0\n","Take 2.184474342352299 % of active parameters\n","Total redistribution parameters: 3451558.0\n","Take: 4477.716227962067 % of removed parameters\n","Pruning rate: 0.022380319742657792\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.15 seconds.\n","\n","Total nonzero parameters:  3524767\n","Take 14.941789721675192 %\n","------------------------------------------------------------\n","[89,     1] loss: 1.0843454599380493, time: 0.5357604026794434\n","[89,     2] loss: 1.0385544300079346, time: 1.079134225845337\n","[89,     3] loss: 0.7077769041061401, time: 1.6192970275878906\n","[89,     4] loss: 0.8924146294593811, time: 2.169711112976074\n","[89,     5] loss: 0.9767380356788635, time: 2.7547290325164795\n","[89,     6] loss: 0.8135707378387451, time: 3.3091249465942383\n","[89,     7] loss: 0.9407628178596497, time: 3.8480968475341797\n","[89,     8] loss: 1.044438123703003, time: 4.390872240066528\n","[89,     9] loss: 1.003069519996643, time: 4.946120500564575\n","[89,    10] loss: 0.7691814303398132, time: 5.467565059661865\n","[89,    11] loss: 0.7812924385070801, time: 5.990848779678345\n","[89,    12] loss: 1.3642560243606567, time: 6.551493406295776\n","[89,    13] loss: 0.6409443616867065, time: 7.08604097366333\n","[89,    14] loss: 0.8749865889549255, time: 7.608107566833496\n","[89,    15] loss: 0.9092153310775757, time: 8.143726825714111\n","[89,    16] loss: 0.9284084439277649, time: 8.680289030075073\n","[89,    17] loss: 1.0810271501541138, time: 9.211515188217163\n","[89,    18] loss: 0.8353496193885803, time: 9.749540328979492\n","[89,    19] loss: 1.0907175540924072, time: 10.281172037124634\n","[89,    20] loss: 0.977517306804657, time: 10.831131219863892\n","[89,    21] loss: 1.066178798675537, time: 11.357980251312256\n","[89,    22] loss: 0.8445561528205872, time: 11.873643159866333\n","[89,    23] loss: 1.3260167837142944, time: 12.41336703300476\n","[89,    24] loss: 0.8313565254211426, time: 12.953267335891724\n","[89,    25] loss: 1.092154622077942, time: 13.503278017044067\n","[89,    26] loss: 0.8220670223236084, time: 14.060099363327026\n","[89,    27] loss: 0.9191715121269226, time: 14.604137659072876\n","[89,    28] loss: 0.9929020404815674, time: 15.142306327819824\n","[89,    29] loss: 0.9044070243835449, time: 15.676212310791016\n","[89,    30] loss: 1.0693168640136719, time: 16.218950748443604\n","[89,    31] loss: 0.8578358292579651, time: 16.773051023483276\n","[89,    32] loss: 0.9993723630905151, time: 17.311227083206177\n","[89,    33] loss: 0.9986338019371033, time: 17.86415982246399\n","[89,    34] loss: 0.8260043859481812, time: 18.41379404067993\n","[89,    35] loss: 0.6906343698501587, time: 18.95054030418396\n","[89,    36] loss: 0.888831377029419, time: 19.484698057174683\n","[89,    37] loss: 0.7160418629646301, time: 20.02319073677063\n","[89,    38] loss: 1.0360544919967651, time: 20.55244016647339\n","[89,    39] loss: 0.9029513001441956, time: 21.098873376846313\n","[89,    40] loss: 0.964293897151947, time: 21.634982585906982\n","[89,    41] loss: 0.9857618808746338, time: 22.18421721458435\n","[89,    42] loss: 0.7881394028663635, time: 22.71400809288025\n","[89,    43] loss: 0.6521621346473694, time: 23.242774724960327\n","[89,    44] loss: 0.8885416984558105, time: 23.792511463165283\n","[89,    45] loss: 1.089133858680725, time: 24.330524444580078\n","[89,    46] loss: 0.9345064163208008, time: 24.862866401672363\n","[89,    47] loss: 0.8592906594276428, time: 25.391974210739136\n","[89,    48] loss: 1.0855226516723633, time: 25.924407958984375\n","[89,    49] loss: 0.6220476627349854, time: 26.470519304275513\n","[89,    50] loss: 1.133144736289978, time: 26.651456832885742\n","\n","Evaluation: Average loss: 0.6058, Accuracy: 775/947 (81.837%)\n","\n","************************************************************\n","Total removed parameters: 67636.0\n","Take 1.9167719243754182 % of active parameters\n","Total redistribution parameters: 3462959.0\n","Take: 5119.993790289195 % of removed parameters\n","Pruning rate: 0.019632009683829187\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.37 seconds.\n","\n","Total nonzero parameters:  3530906\n","Take 14.967813469372945 %\n","------------------------------------------------------------\n","[90,     1] loss: 0.7614226341247559, time: 0.5462098121643066\n","[90,     2] loss: 1.0705569982528687, time: 1.1103870868682861\n","[90,     3] loss: 0.9629907608032227, time: 1.6570863723754883\n","[90,     4] loss: 0.6523914933204651, time: 2.206099033355713\n","[90,     5] loss: 0.741371750831604, time: 2.762815237045288\n","[90,     6] loss: 0.8991719484329224, time: 3.3035218715667725\n","[90,     7] loss: 0.8478841185569763, time: 3.850827932357788\n","[90,     8] loss: 1.1104035377502441, time: 4.412582635879517\n","[90,     9] loss: 0.8468796610832214, time: 4.963471174240112\n","[90,    10] loss: 0.7601608037948608, time: 5.512899160385132\n","[90,    11] loss: 0.7338665723800659, time: 6.048284292221069\n","[90,    12] loss: 0.6421069502830505, time: 6.5946033000946045\n","[90,    13] loss: 1.0119366645812988, time: 7.130110502243042\n","[90,    14] loss: 0.6505005955696106, time: 7.67445182800293\n","[90,    15] loss: 0.9646090865135193, time: 8.227800369262695\n","[90,    16] loss: 0.6034051179885864, time: 8.763244867324829\n","[90,    17] loss: 0.6755660772323608, time: 9.29774284362793\n","[90,    18] loss: 0.7396317720413208, time: 9.839732885360718\n","[90,    19] loss: 0.7445100545883179, time: 10.374768733978271\n","[90,    20] loss: 0.8848474025726318, time: 10.918038129806519\n","[90,    21] loss: 0.8804357051849365, time: 11.445518732070923\n","[90,    22] loss: 0.9532029032707214, time: 11.968942165374756\n","[90,    23] loss: 0.7007066607475281, time: 12.503997564315796\n","[90,    24] loss: 0.6977184414863586, time: 13.043195724487305\n","[90,    25] loss: 1.0783611536026, time: 13.571176767349243\n","[90,    26] loss: 0.7375534772872925, time: 14.11313509941101\n","[90,    27] loss: 1.381963849067688, time: 14.664125204086304\n","[90,    28] loss: 0.8910605907440186, time: 15.201016187667847\n","[90,    29] loss: 0.9346324801445007, time: 15.758836269378662\n","[90,    30] loss: 0.9389568567276001, time: 16.326149225234985\n","[90,    31] loss: 0.86293625831604, time: 16.850263118743896\n","[90,    32] loss: 0.7571542859077454, time: 17.38841676712036\n","[90,    33] loss: 0.7232673168182373, time: 17.935089349746704\n","[90,    34] loss: 0.919792115688324, time: 18.46796441078186\n","[90,    35] loss: 0.946491003036499, time: 19.02518653869629\n","[90,    36] loss: 0.9373797178268433, time: 19.565076112747192\n","[90,    37] loss: 0.7086750268936157, time: 20.11098599433899\n","[90,    38] loss: 1.0575529336929321, time: 20.649208545684814\n","[90,    39] loss: 0.8495270609855652, time: 21.164637565612793\n","[90,    40] loss: 0.9434574842453003, time: 21.70080852508545\n","[90,    41] loss: 0.9076299071311951, time: 22.241693258285522\n","[90,    42] loss: 0.8401560187339783, time: 22.769562482833862\n","[90,    43] loss: 0.7207432985305786, time: 23.309067249298096\n","[90,    44] loss: 0.7646228671073914, time: 23.846774339675903\n","[90,    45] loss: 0.9699445366859436, time: 24.417555809020996\n","[90,    46] loss: 0.9628264307975769, time: 24.947962522506714\n","[90,    47] loss: 0.8984285593032837, time: 25.476663827896118\n","[90,    48] loss: 1.0232635736465454, time: 26.041515111923218\n","[90,    49] loss: 1.0796644687652588, time: 26.60286283493042\n","[90,    50] loss: 0.7598899602890015, time: 26.77144503593445\n","\n","Evaluation: Average loss: 0.8873, Accuracy: 714/947 (75.396%)\n","\n","************************************************************\n","Total removed parameters: 59012.0\n","Take 1.671446314289801 % of active parameters\n","Total redistribution parameters: 3472364.0\n","Take: 5884.165932352742 % of removed parameters\n","Pruning rate: 0.017113512216949442\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.17 seconds.\n","\n","Total nonzero parameters:  3539032\n","Take 15.00226028054609 %\n","------------------------------------------------------------\n","[91,     1] loss: 0.8620694875717163, time: 0.5558662414550781\n","[91,     2] loss: 0.8275396227836609, time: 1.1233041286468506\n","[91,     3] loss: 0.7348064184188843, time: 1.6878979206085205\n","[91,     4] loss: 0.7827317118644714, time: 2.2094786167144775\n","[91,     5] loss: 0.5825530886650085, time: 2.748586654663086\n","[91,     6] loss: 1.1343684196472168, time: 3.2885496616363525\n","[91,     7] loss: 1.1039564609527588, time: 3.8180625438690186\n","[91,     8] loss: 1.1226049661636353, time: 4.348037004470825\n","[91,     9] loss: 0.6812950968742371, time: 4.870720863342285\n","[91,    10] loss: 0.5860158801078796, time: 5.393462657928467\n","[91,    11] loss: 0.6945033669471741, time: 5.915775537490845\n","[91,    12] loss: 0.8282975554466248, time: 6.437897443771362\n","[91,    13] loss: 1.036834955215454, time: 6.98923659324646\n","[91,    14] loss: 1.1208698749542236, time: 7.518973350524902\n","[91,    15] loss: 1.088451623916626, time: 8.051494359970093\n","[91,    16] loss: 0.8278979063034058, time: 8.595602035522461\n","[91,    17] loss: 0.8183212876319885, time: 9.136757850646973\n","[91,    18] loss: 0.6816115379333496, time: 9.662965536117554\n","[91,    19] loss: 1.1162307262420654, time: 10.223059177398682\n","[91,    20] loss: 1.1035670042037964, time: 10.758704423904419\n","[91,    21] loss: 1.1806917190551758, time: 11.303589582443237\n","[91,    22] loss: 0.7495035529136658, time: 11.84757375717163\n","[91,    23] loss: 0.7383518218994141, time: 12.392282247543335\n","[91,    24] loss: 0.7810236811637878, time: 12.93403959274292\n","[91,    25] loss: 1.0087393522262573, time: 13.489874124526978\n","[91,    26] loss: 0.9043810963630676, time: 14.020609855651855\n","[91,    27] loss: 0.7795017957687378, time: 14.563041687011719\n","[91,    28] loss: 1.0178251266479492, time: 15.110469579696655\n","[91,    29] loss: 0.6409344673156738, time: 15.621776580810547\n","[91,    30] loss: 0.6577404141426086, time: 16.17286777496338\n","[91,    31] loss: 0.7063403129577637, time: 16.71438980102539\n","[91,    32] loss: 0.7646417617797852, time: 17.27025842666626\n","[91,    33] loss: 1.0137990713119507, time: 17.82658839225769\n","[91,    34] loss: 0.8273648619651794, time: 18.387443780899048\n","[91,    35] loss: 1.0352121591567993, time: 18.926881074905396\n","[91,    36] loss: 0.9444330334663391, time: 19.447773694992065\n","[91,    37] loss: 0.9545608758926392, time: 19.995803117752075\n","[91,    38] loss: 1.0350455045700073, time: 20.528512954711914\n","[91,    39] loss: 0.7236225605010986, time: 21.07553219795227\n","[91,    40] loss: 0.869278073310852, time: 21.5980064868927\n","[91,    41] loss: 0.9046369791030884, time: 22.11564874649048\n","[91,    42] loss: 0.7981396913528442, time: 22.671152114868164\n","[91,    43] loss: 0.6310340166091919, time: 23.22105646133423\n","[91,    44] loss: 0.7974599599838257, time: 23.78188991546631\n","[91,    45] loss: 0.7967045903205872, time: 24.32513689994812\n","[91,    46] loss: 0.8807307481765747, time: 24.875242710113525\n","[91,    47] loss: 0.4449756145477295, time: 25.386584281921387\n","[91,    48] loss: 0.9149398803710938, time: 25.93308925628662\n","[91,    49] loss: 0.9859930872917175, time: 26.48163938522339\n","[91,    50] loss: 1.0459396839141846, time: 26.660084009170532\n","\n","Evaluation: Average loss: 0.5988, Accuracy: 767/947 (80.993%)\n","\n","************************************************************\n","Total removed parameters: 51199.0\n","Take 1.4498314538015775 % of active parameters\n","Total redistribution parameters: 3479903.0\n","Take: 6796.8182972323675 % of removed parameters\n","Pruning rate: 0.014827312794956495\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.15 seconds.\n","\n","Total nonzero parameters:  3545415\n","Take 15.02931836517791 %\n","------------------------------------------------------------\n","[92,     1] loss: 0.6916957497596741, time: 0.538015604019165\n","[92,     2] loss: 0.7481507062911987, time: 1.0948050022125244\n","[92,     3] loss: 0.8527420163154602, time: 1.6419713497161865\n","[92,     4] loss: 0.9496656656265259, time: 2.1794941425323486\n","[92,     5] loss: 1.1146659851074219, time: 2.704178810119629\n","[92,     6] loss: 0.9813763499259949, time: 3.2336552143096924\n","[92,     7] loss: 1.1659331321716309, time: 3.781599283218384\n","[92,     8] loss: 0.9275520443916321, time: 4.3257880210876465\n","[92,     9] loss: 0.9537253379821777, time: 4.871935844421387\n","[92,    10] loss: 0.9615464210510254, time: 5.4393298625946045\n","[92,    11] loss: 0.6202822327613831, time: 5.9627721309661865\n","[92,    12] loss: 0.7990090847015381, time: 6.494352340698242\n","[92,    13] loss: 0.8530617952346802, time: 7.0554869174957275\n","[92,    14] loss: 0.8341325521469116, time: 7.6045215129852295\n","[92,    15] loss: 1.0752437114715576, time: 8.158814191818237\n","[92,    16] loss: 1.0354405641555786, time: 8.724191904067993\n","[92,    17] loss: 0.9499315023422241, time: 9.257574319839478\n","[92,    18] loss: 0.6975048184394836, time: 9.785382986068726\n","[92,    19] loss: 0.6707792282104492, time: 10.32901668548584\n","[92,    20] loss: 0.7994903326034546, time: 10.873584270477295\n","[92,    21] loss: 0.9428784847259521, time: 11.422406911849976\n","[92,    22] loss: 0.958243191242218, time: 11.946518659591675\n","[92,    23] loss: 0.9569729566574097, time: 12.477778434753418\n","[92,    24] loss: 0.7254091501235962, time: 13.005229473114014\n","[92,    25] loss: 0.6906376481056213, time: 13.583106994628906\n","[92,    26] loss: 1.225387454032898, time: 14.128261089324951\n","[92,    27] loss: 0.5276162624359131, time: 14.670438289642334\n","[92,    28] loss: 0.9561429619789124, time: 15.2187819480896\n","[92,    29] loss: 0.7609046697616577, time: 15.747367143630981\n","[92,    30] loss: 1.1438244581222534, time: 16.303836822509766\n","[92,    31] loss: 0.8029786348342896, time: 16.83752942085266\n","[92,    32] loss: 0.8346771597862244, time: 17.359788179397583\n","[92,    33] loss: 0.7449405193328857, time: 17.877729415893555\n","[92,    34] loss: 0.9266465306282043, time: 18.40225839614868\n","[92,    35] loss: 0.6675071120262146, time: 18.93250346183777\n","[92,    36] loss: 0.9918786883354187, time: 19.47968888282776\n","[92,    37] loss: 0.8392780423164368, time: 20.022429943084717\n","[92,    38] loss: 1.4003092050552368, time: 20.586820125579834\n","[92,    39] loss: 0.754260778427124, time: 21.1291561126709\n","[92,    40] loss: 0.7118226289749146, time: 21.66134476661682\n","[92,    41] loss: 0.5892530679702759, time: 22.18031120300293\n","[92,    42] loss: 0.5500529408454895, time: 22.71914052963257\n","[92,    43] loss: 1.1216037273406982, time: 23.253890991210938\n","[92,    44] loss: 1.0514143705368042, time: 23.770602464675903\n","[92,    45] loss: 0.9102149605751038, time: 24.322366952896118\n","[92,    46] loss: 0.7902320623397827, time: 24.88226890563965\n","[92,    47] loss: 0.5826882123947144, time: 25.410934925079346\n","[92,    48] loss: 1.260329008102417, time: 25.950076818466187\n","[92,    49] loss: 0.7480000257492065, time: 26.492905855178833\n","[92,    50] loss: 1.1518443822860718, time: 26.661322355270386\n","\n","Evaluation: Average loss: 0.6648, Accuracy: 751/947 (79.303%)\n","\n","************************************************************\n","Total removed parameters: 44229.0\n","Take 1.2525551513380242 % of active parameters\n","Total redistribution parameters: 3487202.0\n","Take: 7884.424246535079 % of removed parameters\n","Pruning rate: 0.012775667620663723\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.16 seconds.\n","\n","Total nonzero parameters:  3550302\n","Take 15.050034777459864 %\n","------------------------------------------------------------\n","[93,     1] loss: 0.7541865706443787, time: 0.5777170658111572\n","[93,     2] loss: 0.845697820186615, time: 1.1258175373077393\n","[93,     3] loss: 0.9905694127082825, time: 1.6866178512573242\n","[93,     4] loss: 1.1690975427627563, time: 2.2564003467559814\n","[93,     5] loss: 0.7856557369232178, time: 2.828195095062256\n","[93,     6] loss: 0.7607442736625671, time: 3.3681814670562744\n","[93,     7] loss: 0.890140175819397, time: 3.9132587909698486\n","[93,     8] loss: 1.0068373680114746, time: 4.465332269668579\n","[93,     9] loss: 1.1099170446395874, time: 5.02684473991394\n","[93,    10] loss: 0.9564064741134644, time: 5.566534042358398\n","[93,    11] loss: 0.869597315788269, time: 6.091105937957764\n","[93,    12] loss: 1.0717532634735107, time: 6.6474223136901855\n","[93,    13] loss: 0.9653764963150024, time: 7.198576211929321\n","[93,    14] loss: 0.9144259691238403, time: 7.743869304656982\n","[93,    15] loss: 0.7078596949577332, time: 8.306073188781738\n","[93,    16] loss: 0.7257617712020874, time: 8.848670959472656\n","[93,    17] loss: 0.8255245089530945, time: 9.410869359970093\n","[93,    18] loss: 0.9743436574935913, time: 9.9749755859375\n","[93,    19] loss: 0.846994161605835, time: 10.544547080993652\n","[93,    20] loss: 0.9853469729423523, time: 11.090071439743042\n","[93,    21] loss: 1.0085419416427612, time: 11.63338828086853\n","[93,    22] loss: 0.9163405895233154, time: 12.167568922042847\n","[93,    23] loss: 0.9277467727661133, time: 12.714651107788086\n","[93,    24] loss: 0.7659663558006287, time: 13.252409219741821\n","[93,    25] loss: 0.9753302931785583, time: 13.805777311325073\n","[93,    26] loss: 0.7706663012504578, time: 14.3767991065979\n","[93,    27] loss: 0.8880858421325684, time: 14.940966129302979\n","[93,    28] loss: 0.5845845937728882, time: 15.519741773605347\n","[93,    29] loss: 0.7148518562316895, time: 16.109314918518066\n","[93,    30] loss: 0.7939106822013855, time: 16.68447494506836\n","[93,    31] loss: 0.7970495820045471, time: 17.234996557235718\n","[93,    32] loss: 1.0857141017913818, time: 17.784153699874878\n","[93,    33] loss: 0.7041802406311035, time: 18.326547145843506\n","[93,    34] loss: 0.8377438187599182, time: 18.87053108215332\n","[93,    35] loss: 0.9116355180740356, time: 19.41020393371582\n","[93,    36] loss: 0.7065884470939636, time: 19.936559200286865\n","[93,    37] loss: 1.0163936614990234, time: 20.49433207511902\n","[93,    38] loss: 0.7834242582321167, time: 21.04413676261902\n","[93,    39] loss: 0.7729768753051758, time: 21.584909439086914\n","[93,    40] loss: 0.9671915173530579, time: 22.108794689178467\n","[93,    41] loss: 0.8838139176368713, time: 22.66185235977173\n","[93,    42] loss: 1.1396543979644775, time: 23.19246220588684\n","[93,    43] loss: 0.6174925565719604, time: 23.72893261909485\n","[93,    44] loss: 0.6290197968482971, time: 24.275684356689453\n","[93,    45] loss: 0.8534302115440369, time: 24.824729919433594\n","[93,    46] loss: 1.0768921375274658, time: 25.359569311141968\n","[93,    47] loss: 0.6989167928695679, time: 25.909568786621094\n","[93,    48] loss: 0.782222330570221, time: 26.44314432144165\n","[93,    49] loss: 1.1619378328323364, time: 27.00397300720215\n","[93,    50] loss: 1.1718717813491821, time: 27.178734064102173\n","\n","Evaluation: Average loss: 1.0629, Accuracy: 667/947 (70.433%)\n","\n","************************************************************\n","Total removed parameters: 37973.0\n","Take 1.0752864773515325 % of active parameters\n","Total redistribution parameters: 3494035.0\n","Take: 9201.366760593053 % of removed parameters\n","Pruning rate: 0.010960601420159956\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.60 seconds.\n","\n","Total nonzero parameters:  3555076\n","Take 15.070272173046941 %\n","------------------------------------------------------------\n","[94,     1] loss: 0.6747249960899353, time: 0.5551254749298096\n","[94,     2] loss: 0.9634823203086853, time: 1.100630521774292\n","[94,     3] loss: 1.2016581296920776, time: 1.6532225608825684\n","[94,     4] loss: 1.1369880437850952, time: 2.2079555988311768\n","[94,     5] loss: 1.0689237117767334, time: 2.7504208087921143\n","[94,     6] loss: 1.0697393417358398, time: 3.305755853652954\n","[94,     7] loss: 0.8399357199668884, time: 3.8733997344970703\n","[94,     8] loss: 0.893792450428009, time: 4.403777122497559\n","[94,     9] loss: 0.8859907984733582, time: 4.954310894012451\n","[94,    10] loss: 1.0231013298034668, time: 5.504600286483765\n","[94,    11] loss: 1.1164473295211792, time: 6.049593925476074\n","[94,    12] loss: 0.8980551958084106, time: 6.587460994720459\n","[94,    13] loss: 1.0155985355377197, time: 7.1331093311309814\n","[94,    14] loss: 0.8031585812568665, time: 7.6697797775268555\n","[94,    15] loss: 0.8046873211860657, time: 8.201802968978882\n","[94,    16] loss: 0.631571888923645, time: 8.749009132385254\n","[94,    17] loss: 0.9949096441268921, time: 9.304407119750977\n","[94,    18] loss: 0.8394448161125183, time: 9.834595918655396\n","[94,    19] loss: 1.0379579067230225, time: 10.367928504943848\n","[94,    20] loss: 0.8696975708007812, time: 10.934262752532959\n","[94,    21] loss: 0.8335896134376526, time: 11.4942147731781\n","[94,    22] loss: 0.8953043222427368, time: 12.047675848007202\n","[94,    23] loss: 1.3187029361724854, time: 12.609816312789917\n","[94,    24] loss: 1.037218689918518, time: 13.136943340301514\n","[94,    25] loss: 0.7644074559211731, time: 13.672654390335083\n","[94,    26] loss: 0.9097873568534851, time: 14.2181077003479\n","[94,    27] loss: 0.7772148251533508, time: 14.742380380630493\n","[94,    28] loss: 0.9118725061416626, time: 15.308805465698242\n","[94,    29] loss: 1.1252518892288208, time: 15.844189643859863\n","[94,    30] loss: 0.8147346377372742, time: 16.39087462425232\n","[94,    31] loss: 1.2473430633544922, time: 16.94047236442566\n","[94,    32] loss: 0.9598387479782104, time: 17.496418714523315\n","[94,    33] loss: 0.8969784379005432, time: 18.042025089263916\n","[94,    34] loss: 0.7440555095672607, time: 18.555018186569214\n","[94,    35] loss: 0.8883374929428101, time: 19.08960795402527\n","[94,    36] loss: 0.7458385825157166, time: 19.63857865333557\n","[94,    37] loss: 0.9590089917182922, time: 20.185839414596558\n","[94,    38] loss: 0.6092240214347839, time: 20.731454849243164\n","[94,    39] loss: 1.0363223552703857, time: 21.284175157546997\n","[94,    40] loss: 0.9515916109085083, time: 21.823331594467163\n","[94,    41] loss: 0.7787257432937622, time: 22.37059450149536\n","[94,    42] loss: 0.9629791975021362, time: 22.929369926452637\n","[94,    43] loss: 0.9318810105323792, time: 23.47999668121338\n","[94,    44] loss: 0.9842969179153442, time: 24.030568599700928\n","[94,    45] loss: 1.0209523439407349, time: 24.56148076057434\n","[94,    46] loss: 0.8068015575408936, time: 25.103453636169434\n","[94,    47] loss: 0.6618321537971497, time: 25.626272439956665\n","[94,    48] loss: 0.7822710275650024, time: 26.17827033996582\n","[94,    49] loss: 0.9231706261634827, time: 26.724053621292114\n","[94,    50] loss: 1.2919632196426392, time: 26.89896059036255\n","\n","Evaluation: Average loss: 0.9703, Accuracy: 703/947 (74.234%)\n","\n","************************************************************\n","Total removed parameters: 32591.0\n","Take 0.9227329043422325 % of active parameters\n","Total redistribution parameters: 3499023.0\n","Take: 10736.163357982265 % of removed parameters\n","Pruning rate: 0.0093839054446495\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.29 seconds.\n","\n","Total nonzero parameters:  3559558\n","Take 15.089271755581773 %\n","------------------------------------------------------------\n","[95,     1] loss: 0.7230368852615356, time: 0.55552077293396\n","[95,     2] loss: 0.7128005027770996, time: 1.0996720790863037\n","[95,     3] loss: 0.9735514521598816, time: 1.6428399085998535\n","[95,     4] loss: 0.7795453071594238, time: 2.217651128768921\n","[95,     5] loss: 0.7110841870307922, time: 2.7750418186187744\n","[95,     6] loss: 0.9903602600097656, time: 3.3333239555358887\n","[95,     7] loss: 0.8732514977455139, time: 3.8616466522216797\n","[95,     8] loss: 0.4771145284175873, time: 4.42077374458313\n","[95,     9] loss: 1.0385743379592896, time: 4.952849864959717\n","[95,    10] loss: 1.1567262411117554, time: 5.508387088775635\n","[95,    11] loss: 0.9710808992385864, time: 6.049022674560547\n","[95,    12] loss: 0.7915889620780945, time: 6.590803861618042\n","[95,    13] loss: 0.7995851039886475, time: 7.117387533187866\n","[95,    14] loss: 0.7595158219337463, time: 7.687314510345459\n","[95,    15] loss: 0.8466717004776001, time: 8.236236810684204\n","[95,    16] loss: 1.1767507791519165, time: 8.776772737503052\n","[95,    17] loss: 1.0778785943984985, time: 9.329380750656128\n","[95,    18] loss: 0.9382691979408264, time: 9.87298583984375\n","[95,    19] loss: 1.0249744653701782, time: 10.436319351196289\n","[95,    20] loss: 1.1528222560882568, time: 10.989988327026367\n","[95,    21] loss: 1.1175264120101929, time: 11.544829368591309\n","[95,    22] loss: 0.6693739295005798, time: 12.111923217773438\n","[95,    23] loss: 0.6568670272827148, time: 12.634895324707031\n","[95,    24] loss: 0.9097349047660828, time: 13.167137861251831\n","[95,    25] loss: 0.780329704284668, time: 13.71397852897644\n","[95,    26] loss: 0.8488397002220154, time: 14.25999140739441\n","[95,    27] loss: 1.0197166204452515, time: 14.81426215171814\n","[95,    28] loss: 1.1966062784194946, time: 15.366153001785278\n","[95,    29] loss: 0.8230174779891968, time: 15.886629819869995\n","[95,    30] loss: 0.7802563905715942, time: 16.416441679000854\n","[95,    31] loss: 1.1843146085739136, time: 16.945873737335205\n","[95,    32] loss: 0.8187140822410583, time: 17.483103036880493\n","[95,    33] loss: 0.7848930358886719, time: 18.032057762145996\n","[95,    34] loss: 0.6541823148727417, time: 18.57417893409729\n","[95,    35] loss: 1.0114319324493408, time: 19.137781620025635\n","[95,    36] loss: 0.9117292761802673, time: 19.68958616256714\n","[95,    37] loss: 0.8465306162834167, time: 20.225921154022217\n","[95,    38] loss: 0.5924491286277771, time: 20.763079404830933\n","[95,    39] loss: 1.1123472452163696, time: 21.319779872894287\n","[95,    40] loss: 1.022395372390747, time: 21.868550539016724\n","[95,    41] loss: 1.19580078125, time: 22.39160656929016\n","[95,    42] loss: 0.9428218007087708, time: 22.913517475128174\n","[95,    43] loss: 1.2159974575042725, time: 23.435447692871094\n","[95,    44] loss: 0.6953034996986389, time: 23.95544457435608\n","[95,    45] loss: 0.7510570883750916, time: 24.499531507492065\n","[95,    46] loss: 0.9776253700256348, time: 25.03952717781067\n","[95,    47] loss: 0.7092363834381104, time: 25.565434217453003\n","[95,    48] loss: 1.018831491470337, time: 26.115452527999878\n","[95,    49] loss: 1.176358699798584, time: 26.656640768051147\n","[95,    50] loss: 1.2772283554077148, time: 26.8357150554657\n","\n","Evaluation: Average loss: 0.7465, Accuracy: 723/947 (76.346%)\n","\n","************************************************************\n","Total removed parameters: 28027.0\n","Take 0.7936031514202855 % of active parameters\n","Total redistribution parameters: 3504456.0\n","Take: 12503.856995040496 % of removed parameters\n","Pruning rate: 0.008047135702703382\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.33 seconds.\n","\n","Total nonzero parameters:  3562414\n","Take 15.10137858461334 %\n","------------------------------------------------------------\n","[96,     1] loss: 0.8191387057304382, time: 0.5572795867919922\n","[96,     2] loss: 0.956665575504303, time: 1.0978994369506836\n","[96,     3] loss: 0.850067138671875, time: 1.644334316253662\n","[96,     4] loss: 0.916014552116394, time: 2.189403533935547\n","[96,     5] loss: 0.9404399991035461, time: 2.74434757232666\n","[96,     6] loss: 1.0167158842086792, time: 3.2989985942840576\n","[96,     7] loss: 0.8875604271888733, time: 3.8216800689697266\n","[96,     8] loss: 0.6070923805236816, time: 4.353480577468872\n","[96,     9] loss: 0.898949146270752, time: 4.894430160522461\n","[96,    10] loss: 1.2031660079956055, time: 5.445542812347412\n","[96,    11] loss: 0.6351069808006287, time: 5.973391056060791\n","[96,    12] loss: 0.9263076186180115, time: 6.521440267562866\n","[96,    13] loss: 0.7509877681732178, time: 7.066071510314941\n","[96,    14] loss: 0.8374229073524475, time: 7.614864110946655\n","[96,    15] loss: 0.9645634293556213, time: 8.158382177352905\n","[96,    16] loss: 0.9668794870376587, time: 8.709978818893433\n","[96,    17] loss: 0.6731366515159607, time: 9.235437154769897\n","[96,    18] loss: 1.0466783046722412, time: 9.775639772415161\n","[96,    19] loss: 0.822655200958252, time: 10.30730676651001\n","[96,    20] loss: 0.9883266687393188, time: 10.840222835540771\n","[96,    21] loss: 0.9388501644134521, time: 11.369628667831421\n","[96,    22] loss: 0.9957306385040283, time: 11.913068532943726\n","[96,    23] loss: 0.7930550575256348, time: 12.432371854782104\n","[96,    24] loss: 0.8658527135848999, time: 12.981454849243164\n","[96,    25] loss: 0.7856959104537964, time: 13.528011560440063\n","[96,    26] loss: 0.669104814529419, time: 14.086658000946045\n","[96,    27] loss: 0.7365921139717102, time: 14.651388168334961\n","[96,    28] loss: 0.6159970164299011, time: 15.189834356307983\n","[96,    29] loss: 0.5541529655456543, time: 15.754960060119629\n","[96,    30] loss: 1.0716975927352905, time: 16.28788471221924\n","[96,    31] loss: 0.5863125324249268, time: 16.842369318008423\n","[96,    32] loss: 0.8678402304649353, time: 17.397557973861694\n","[96,    33] loss: 0.8767183423042297, time: 17.943830490112305\n","[96,    34] loss: 0.7497637271881104, time: 18.48311686515808\n","[96,    35] loss: 0.9111023545265198, time: 19.021634340286255\n","[96,    36] loss: 0.7171778678894043, time: 19.55838179588318\n","[96,    37] loss: 0.7771463990211487, time: 20.09205651283264\n","[96,    38] loss: 0.8244251012802124, time: 20.670883417129517\n","[96,    39] loss: 0.6883562803268433, time: 21.217411279678345\n","[96,    40] loss: 0.7717100381851196, time: 21.744447469711304\n","[96,    41] loss: 0.5977049469947815, time: 22.278425216674805\n","[96,    42] loss: 0.9672471284866333, time: 22.8299777507782\n","[96,    43] loss: 0.8907799124717712, time: 23.40719437599182\n","[96,    44] loss: 0.6563947200775146, time: 23.954160928726196\n","[96,    45] loss: 0.8585947155952454, time: 24.495684385299683\n","[96,    46] loss: 0.6773912310600281, time: 25.04371953010559\n","[96,    47] loss: 1.117321491241455, time: 25.58317255973816\n","[96,    48] loss: 0.7533577680587769, time: 26.1698055267334\n","[96,    49] loss: 0.6487071514129639, time: 26.714229106903076\n","[96,    50] loss: 0.7188451886177063, time: 26.89265751838684\n","\n","Evaluation: Average loss: 0.3858, Accuracy: 834/947 (88.068%)\n","\n","************************************************************\n","Total removed parameters: 24289.0\n","Take 0.6875900039717106 % of active parameters\n","Total redistribution parameters: 3508833.0\n","Take: 14446.181398987195 % of removed parameters\n","Pruning rate: 0.006951611424666724\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.36 seconds.\n","\n","Total nonzero parameters:  3566417\n","Take 15.118347645052191 %\n","------------------------------------------------------------\n","[97,     1] loss: 0.8864928483963013, time: 0.5630390644073486\n","[97,     2] loss: 0.7327277660369873, time: 1.0917985439300537\n","[97,     3] loss: 0.6168316602706909, time: 1.668971061706543\n","[97,     4] loss: 0.6565607190132141, time: 2.2066171169281006\n","[97,     5] loss: 0.7940139770507812, time: 2.756049156188965\n","[97,     6] loss: 0.8265993595123291, time: 3.2868738174438477\n","[97,     7] loss: 1.2262468338012695, time: 3.8460099697113037\n","[97,     8] loss: 0.8614402413368225, time: 4.403648614883423\n","[97,     9] loss: 0.9968487024307251, time: 4.944620370864868\n","[97,    10] loss: 0.8728867769241333, time: 5.500439405441284\n","[97,    11] loss: 0.8480761647224426, time: 6.046435356140137\n","[97,    12] loss: 0.8190400004386902, time: 6.604503393173218\n","[97,    13] loss: 1.0364816188812256, time: 7.146358013153076\n","[97,    14] loss: 1.1730238199234009, time: 7.689716339111328\n","[97,    15] loss: 0.7640563249588013, time: 8.22683334350586\n","[97,    16] loss: 1.1853506565093994, time: 8.77643632888794\n","[97,    17] loss: 0.814507007598877, time: 9.327596187591553\n","[97,    18] loss: 1.049873948097229, time: 9.873767375946045\n","[97,    19] loss: 1.0379847288131714, time: 10.406049489974976\n","[97,    20] loss: 0.7548074126243591, time: 10.958004474639893\n","[97,    21] loss: 0.8902696967124939, time: 11.50794529914856\n","[97,    22] loss: 0.7308991551399231, time: 12.063531160354614\n","[97,    23] loss: 0.84718918800354, time: 12.5982027053833\n","[97,    24] loss: 0.6978228688240051, time: 13.15234375\n","[97,    25] loss: 1.0476759672164917, time: 13.678622484207153\n","[97,    26] loss: 1.099854826927185, time: 14.213755130767822\n","[97,    27] loss: 0.899509847164154, time: 14.744024515151978\n","[97,    28] loss: 1.0294026136398315, time: 15.30012822151184\n","[97,    29] loss: 0.9696617126464844, time: 15.849048137664795\n","[97,    30] loss: 0.7853257060050964, time: 16.397752285003662\n","[97,    31] loss: 0.8888081312179565, time: 16.941883087158203\n","[97,    32] loss: 0.7782093286514282, time: 17.47051763534546\n","[97,    33] loss: 0.8982012867927551, time: 17.986807584762573\n","[97,    34] loss: 0.7075187563896179, time: 18.518767833709717\n","[97,    35] loss: 1.2896629571914673, time: 19.05188798904419\n","[97,    36] loss: 0.9065870642662048, time: 19.592133045196533\n","[97,    37] loss: 1.019874930381775, time: 20.139369010925293\n","[97,    38] loss: 0.9224326610565186, time: 20.671647787094116\n","[97,    39] loss: 1.008561372756958, time: 21.237313985824585\n","[97,    40] loss: 0.8508126735687256, time: 21.791359663009644\n","[97,    41] loss: 0.9065151810646057, time: 22.325507640838623\n","[97,    42] loss: 0.7583791613578796, time: 22.867010831832886\n","[97,    43] loss: 1.0772417783737183, time: 23.410562992095947\n","[97,    44] loss: 0.7035900354385376, time: 23.963545083999634\n","[97,    45] loss: 0.8362659811973572, time: 24.514814138412476\n","[97,    46] loss: 0.8241223096847534, time: 25.0682213306427\n","[97,    47] loss: 0.9322655200958252, time: 25.608999490737915\n","[97,    48] loss: 0.7241731286048889, time: 26.17129397392273\n","[97,    49] loss: 0.7036364078521729, time: 26.718278884887695\n","[97,    50] loss: 0.6199816465377808, time: 26.894385814666748\n","\n","Evaluation: Average loss: 0.5718, Accuracy: 776/947 (81.943%)\n","\n","************************************************************\n","Total removed parameters: 21351.0\n","Take 0.6043097294687249 % of active parameters\n","Total redistribution parameters: 3512392.0\n","Take: 16450.714252259848 % of removed parameters\n","Pruning rate: 0.006098413760737683\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.37 seconds.\n","\n","Total nonzero parameters:  3569085\n","Take 15.129657525954226 %\n","------------------------------------------------------------\n","[98,     1] loss: 1.0684682130813599, time: 0.535179853439331\n","[98,     2] loss: 1.1477380990982056, time: 1.0841939449310303\n","[98,     3] loss: 1.1030272245407104, time: 1.630983591079712\n","[98,     4] loss: 0.696451723575592, time: 2.188075542449951\n","[98,     5] loss: 0.8695023059844971, time: 2.7365810871124268\n","[98,     6] loss: 1.1344642639160156, time: 3.29436993598938\n","[98,     7] loss: 0.994337797164917, time: 3.850031614303589\n","[98,     8] loss: 0.7211323976516724, time: 4.414062261581421\n","[98,     9] loss: 1.1554821729660034, time: 4.984723806381226\n","[98,    10] loss: 0.7767112255096436, time: 5.529289722442627\n","[98,    11] loss: 1.0475865602493286, time: 6.1027936935424805\n","[98,    12] loss: 0.7051770091056824, time: 6.650477409362793\n","[98,    13] loss: 0.9963493943214417, time: 7.189718246459961\n","[98,    14] loss: 0.9753907322883606, time: 7.72180700302124\n","[98,    15] loss: 0.7417992353439331, time: 8.251147270202637\n","[98,    16] loss: 0.7778717875480652, time: 8.79720664024353\n","[98,    17] loss: 0.6172346472740173, time: 9.352015018463135\n","[98,    18] loss: 0.8552890419960022, time: 9.884069204330444\n","[98,    19] loss: 0.8570080399513245, time: 10.425811290740967\n","[98,    20] loss: 0.7822274565696716, time: 10.947570562362671\n","[98,    21] loss: 0.5521384477615356, time: 11.532387018203735\n","[98,    22] loss: 1.042257308959961, time: 12.069588661193848\n","[98,    23] loss: 0.7053008675575256, time: 12.62743330001831\n","[98,    24] loss: 0.8462223410606384, time: 13.190656900405884\n","[98,    25] loss: 0.9683446288108826, time: 13.733917236328125\n","[98,    26] loss: 0.8738275170326233, time: 14.294814586639404\n","[98,    27] loss: 0.9264402389526367, time: 14.850115060806274\n","[98,    28] loss: 0.8231084942817688, time: 15.382622718811035\n","[98,    29] loss: 0.8050894141197205, time: 15.922767877578735\n","[98,    30] loss: 1.0258655548095703, time: 16.449782133102417\n","[98,    31] loss: 1.085655689239502, time: 16.992948532104492\n","[98,    32] loss: 1.3589524030685425, time: 17.536463260650635\n","[98,    33] loss: 1.067597508430481, time: 18.06575894355774\n","[98,    34] loss: 0.842368483543396, time: 18.603163957595825\n","[98,    35] loss: 1.0455365180969238, time: 19.132059335708618\n","[98,    36] loss: 0.7445065379142761, time: 19.657917022705078\n","[98,    37] loss: 0.914633572101593, time: 20.19173312187195\n","[98,    38] loss: 0.9332373738288879, time: 20.736060619354248\n","[98,    39] loss: 0.910864531993866, time: 21.299322843551636\n","[98,    40] loss: 0.7144213914871216, time: 21.830331325531006\n","[98,    41] loss: 0.7288894653320312, time: 22.366180658340454\n","[98,    42] loss: 0.8321384787559509, time: 22.921896934509277\n","[98,    43] loss: 0.9407541155815125, time: 23.45941710472107\n","[98,    44] loss: 1.13663911819458, time: 23.99512505531311\n","[98,    45] loss: 0.9908577799797058, time: 24.549559354782104\n","[98,    46] loss: 0.7429977059364319, time: 25.090262413024902\n","[98,    47] loss: 0.7527494430541992, time: 25.636975288391113\n","[98,    48] loss: 0.9427775144577026, time: 26.18161678314209\n","[98,    49] loss: 0.8839585781097412, time: 26.73551654815674\n","[98,    50] loss: 1.3560391664505005, time: 26.91606855392456\n","\n","Evaluation: Average loss: 0.7154, Accuracy: 742/947 (78.353%)\n","\n","************************************************************\n","Total removed parameters: 19010.0\n","Take 0.5379564954214271 % of active parameters\n","Total redistribution parameters: 3514832.0\n","Take: 18489.38453445555 % of removed parameters\n","Pruning rate: 0.005488384714002783\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.47 seconds.\n","\n","Total nonzero parameters:  3571401\n","Take 15.139475248656295 %\n","------------------------------------------------------------\n","[99,     1] loss: 1.27401602268219, time: 0.5624761581420898\n","[99,     2] loss: 1.0486528873443604, time: 1.1035916805267334\n","[99,     3] loss: 0.6082210540771484, time: 1.6191847324371338\n","[99,     4] loss: 0.8666665554046631, time: 2.154019594192505\n","[99,     5] loss: 0.8680703639984131, time: 2.6965599060058594\n","[99,     6] loss: 0.8459034562110901, time: 3.2496728897094727\n","[99,     7] loss: 0.7987287640571594, time: 3.7934982776641846\n","[99,     8] loss: 1.08363938331604, time: 4.349167346954346\n","[99,     9] loss: 1.1658366918563843, time: 4.90073561668396\n","[99,    10] loss: 0.8387570381164551, time: 5.434707880020142\n","[99,    11] loss: 1.0890532732009888, time: 5.986079216003418\n","[99,    12] loss: 1.0225473642349243, time: 6.527976989746094\n","[99,    13] loss: 0.7946855425834656, time: 7.066924810409546\n","[99,    14] loss: 0.7960651516914368, time: 7.602070093154907\n","[99,    15] loss: 1.112076759338379, time: 8.127169132232666\n","[99,    16] loss: 1.0469435453414917, time: 8.680975198745728\n","[99,    17] loss: 1.0124552249908447, time: 9.232107639312744\n","[99,    18] loss: 0.6597044467926025, time: 9.779516696929932\n","[99,    19] loss: 0.828596830368042, time: 10.293381214141846\n","[99,    20] loss: 0.8746216893196106, time: 10.803151845932007\n","[99,    21] loss: 0.8842055201530457, time: 11.325323104858398\n","[99,    22] loss: 0.7834985852241516, time: 11.846131086349487\n","[99,    23] loss: 0.9098119735717773, time: 12.372361421585083\n","[99,    24] loss: 0.782306969165802, time: 12.903546571731567\n","[99,    25] loss: 0.6671428680419922, time: 13.434931755065918\n","[99,    26] loss: 0.7025879621505737, time: 13.983808279037476\n","[99,    27] loss: 1.0332783460617065, time: 14.53510570526123\n","[99,    28] loss: 0.5879034399986267, time: 15.075469732284546\n","[99,    29] loss: 0.9639773368835449, time: 15.605108976364136\n","[99,    30] loss: 0.4693399667739868, time: 16.133533239364624\n","[99,    31] loss: 0.8637017011642456, time: 16.660491943359375\n","[99,    32] loss: 0.840286135673523, time: 17.208394527435303\n","[99,    33] loss: 0.9688125252723694, time: 17.758649826049805\n","[99,    34] loss: 0.7505655884742737, time: 18.274923086166382\n","[99,    35] loss: 0.8733924031257629, time: 18.796563625335693\n","[99,    36] loss: 0.8318793773651123, time: 19.336597442626953\n","[99,    37] loss: 0.8923995494842529, time: 19.86759090423584\n","[99,    38] loss: 0.767758309841156, time: 20.39494776725769\n","[99,    39] loss: 0.94989413022995, time: 20.945819854736328\n","[99,    40] loss: 0.91660475730896, time: 21.480895280838013\n","[99,    41] loss: 1.0910122394561768, time: 22.02396273612976\n","[99,    42] loss: 0.874993085861206, time: 22.55157470703125\n","[99,    43] loss: 0.7783656716346741, time: 23.086753845214844\n","[99,    44] loss: 0.9866267442703247, time: 23.618258476257324\n","[99,    45] loss: 0.9138162732124329, time: 24.155857801437378\n","[99,    46] loss: 0.6609925627708435, time: 24.70305585861206\n","[99,    47] loss: 1.053067684173584, time: 25.25090479850769\n","[99,    48] loss: 0.6394474506378174, time: 25.787278652191162\n","[99,    49] loss: 0.8554484844207764, time: 26.322726488113403\n","[99,    50] loss: 1.072796106338501, time: 26.50265669822693\n","\n","Evaluation: Average loss: 0.8712, Accuracy: 704/947 (74.340%)\n","\n","************************************************************\n","Total removed parameters: 17971.0\n","Take 0.5085399969777936 % of active parameters\n","Total redistribution parameters: 3515506.0\n","Take: 19562.105614601303 % of removed parameters\n","Pruning rate: 0.005122126309481426\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.28 seconds.\n","\n","Total nonzero parameters:  3572412\n","Take 15.143760964395408 %\n","------------------------------------------------------------\n","[100,     1] loss: 0.7414824366569519, time: 0.5529017448425293\n","[100,     2] loss: 0.7275312542915344, time: 1.0951933860778809\n","[100,     3] loss: 0.7870253324508667, time: 1.6228296756744385\n","[100,     4] loss: 1.0233726501464844, time: 2.179476261138916\n","[100,     5] loss: 1.0044718980789185, time: 2.728684186935425\n","[100,     6] loss: 1.0325510501861572, time: 3.277653932571411\n","[100,     7] loss: 1.047389030456543, time: 3.815563678741455\n","[100,     8] loss: 0.771592915058136, time: 4.344811201095581\n","[100,     9] loss: 0.904000461101532, time: 4.882636308670044\n","[100,    10] loss: 0.8201928734779358, time: 5.433165550231934\n","[100,    11] loss: 1.1375609636306763, time: 5.96024489402771\n","[100,    12] loss: 1.1000937223434448, time: 6.494521141052246\n","[100,    13] loss: 1.1594789028167725, time: 7.036918878555298\n","[100,    14] loss: 1.0516026020050049, time: 7.572131872177124\n","[100,    15] loss: 1.0353575944900513, time: 8.10223388671875\n","[100,    16] loss: 0.7518004775047302, time: 8.645152568817139\n","[100,    17] loss: 0.7891532182693481, time: 9.184824228286743\n","[100,    18] loss: 1.0398533344268799, time: 9.721094846725464\n","[100,    19] loss: 0.7816224694252014, time: 10.234580993652344\n","[100,    20] loss: 0.631209135055542, time: 10.777859449386597\n","[100,    21] loss: 0.6984342336654663, time: 11.318157434463501\n","[100,    22] loss: 0.8464277386665344, time: 11.876837730407715\n","[100,    23] loss: 0.5401687622070312, time: 12.423246622085571\n","[100,    24] loss: 0.8214053511619568, time: 12.967051267623901\n","[100,    25] loss: 0.7404633164405823, time: 13.512322664260864\n","[100,    26] loss: 0.883185863494873, time: 14.057742595672607\n","[100,    27] loss: 0.7032779455184937, time: 14.602336883544922\n","[100,    28] loss: 0.8328943252563477, time: 15.138025045394897\n","[100,    29] loss: 0.7032332420349121, time: 15.677661418914795\n","[100,    30] loss: 1.1501437425613403, time: 16.20718264579773\n","[100,    31] loss: 0.7732917666435242, time: 16.756909608840942\n","[100,    32] loss: 0.7619675397872925, time: 17.299449682235718\n","[100,    33] loss: 1.0597020387649536, time: 17.862812042236328\n","[100,    34] loss: 0.894559383392334, time: 18.40100860595703\n","[100,    35] loss: 0.8224786520004272, time: 18.951998233795166\n","[100,    36] loss: 0.773720920085907, time: 19.49431872367859\n","[100,    37] loss: 0.7318504452705383, time: 20.05451726913452\n","[100,    38] loss: 1.2526179552078247, time: 20.582392930984497\n","[100,    39] loss: 1.1459847688674927, time: 21.142927885055542\n","[100,    40] loss: 0.7526789903640747, time: 21.694304704666138\n","[100,    41] loss: 0.6365335583686829, time: 22.234118461608887\n","[100,    42] loss: 0.8920005559921265, time: 22.775237321853638\n","[100,    43] loss: 0.7887220978736877, time: 23.30659317970276\n","[100,    44] loss: 0.8695186972618103, time: 23.858782052993774\n","[100,    45] loss: 0.8232408761978149, time: 24.40976095199585\n","[100,    46] loss: 0.8252439498901367, time: 24.94161558151245\n","[100,    47] loss: 0.6779795289039612, time: 25.463881015777588\n","[100,    48] loss: 0.7804380059242249, time: 25.99418807029724\n","[100,    49] loss: 0.8913612961769104, time: 26.537734508514404\n","[100,    50] loss: 0.850757896900177, time: 26.710545301437378\n","\n","Evaluation: Average loss: 0.6124, Accuracy: 788/947 (83.210%)\n","\n","************************************************************\n","Total removed parameters: 17467.0\n","Take 0.49432895700184265 % of active parameters\n","Total redistribution parameters: 3516010.0\n","Take: 20129.444094578346 % of removed parameters\n","Pruning rate: 0.005\n","************************************************************\n","------------------------------------------------------------\n","Current learning rate: 0.1. Time taken for epoch: 32.32 seconds.\n","\n","Total nonzero parameters:  3572399\n","Take 15.143705856280071 %\n","------------------------------------------------------------\n","\n","Test evaluation: Average loss: 0.6218, Accuracy: 322/406 (79.310%)\n","\n","Total time:  3241.738289833069\n","\n","Iteration end: 1/1\n","\n"]}]},{"cell_type":"code","source":["!python '/content/drive/MyDrive/Projects/sparse_learning-d0-densenet121/mnist_cifar/main.py' --data cifar --model wrn-28-2"],"metadata":{"id":"E8fYeC_7W1-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python '/content/drive/MyDrive/Projects/sparse_learning-d0-widerestnet502/mnist_cifar/main.py' --data cifar --model wrn-28-2"],"metadata":{"id":"p2y72cT8W6Iz"},"execution_count":null,"outputs":[]}]}